{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:2.0.0\n"
     ]
    }
   ],
   "source": [
    "print( 'Tensorflow Version:{}'.format(tf.__version__) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:/tensorflow2.0_日月光华/日月光华-tensorflow资料/数据集/Income1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.658839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.401338</td>\n",
       "      <td>27.306435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.842809</td>\n",
       "      <td>22.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.244147</td>\n",
       "      <td>21.169841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11.645485</td>\n",
       "      <td>15.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12.086957</td>\n",
       "      <td>26.398951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12.488294</td>\n",
       "      <td>17.435307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>12.889632</td>\n",
       "      <td>25.507885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>13.290970</td>\n",
       "      <td>36.884595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13.732441</td>\n",
       "      <td>39.666109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>14.133779</td>\n",
       "      <td>34.396281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>14.535117</td>\n",
       "      <td>41.497994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>14.976589</td>\n",
       "      <td>44.981575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15.377926</td>\n",
       "      <td>47.039595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15.779264</td>\n",
       "      <td>48.252578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>16.220736</td>\n",
       "      <td>57.034251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>16.622074</td>\n",
       "      <td>51.490919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>17.023411</td>\n",
       "      <td>61.336621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>17.464883</td>\n",
       "      <td>57.581988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>17.866221</td>\n",
       "      <td>68.553714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>18.267559</td>\n",
       "      <td>64.310925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>18.709030</td>\n",
       "      <td>68.959009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>19.110368</td>\n",
       "      <td>74.614639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>19.511706</td>\n",
       "      <td>71.867195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>19.913043</td>\n",
       "      <td>76.098135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>20.354515</td>\n",
       "      <td>75.775218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>20.755853</td>\n",
       "      <td>72.486055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>21.157191</td>\n",
       "      <td>77.355021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>21.598662</td>\n",
       "      <td>72.118790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>80.260571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Education     Income\n",
       "0            1  10.000000  26.658839\n",
       "1            2  10.401338  27.306435\n",
       "2            3  10.842809  22.132410\n",
       "3            4  11.244147  21.169841\n",
       "4            5  11.645485  15.192634\n",
       "5            6  12.086957  26.398951\n",
       "6            7  12.488294  17.435307\n",
       "7            8  12.889632  25.507885\n",
       "8            9  13.290970  36.884595\n",
       "9           10  13.732441  39.666109\n",
       "10          11  14.133779  34.396281\n",
       "11          12  14.535117  41.497994\n",
       "12          13  14.976589  44.981575\n",
       "13          14  15.377926  47.039595\n",
       "14          15  15.779264  48.252578\n",
       "15          16  16.220736  57.034251\n",
       "16          17  16.622074  51.490919\n",
       "17          18  17.023411  61.336621\n",
       "18          19  17.464883  57.581988\n",
       "19          20  17.866221  68.553714\n",
       "20          21  18.267559  64.310925\n",
       "21          22  18.709030  68.959009\n",
       "22          23  19.110368  74.614639\n",
       "23          24  19.511706  71.867195\n",
       "24          25  19.913043  76.098135\n",
       "25          26  20.354515  75.775218\n",
       "26          27  20.755853  72.486055\n",
       "27          28  21.157191  77.355021\n",
       "28          29  21.598662  72.118790\n",
       "29          30  22.000000  80.260571"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c508b6e208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.Education, data.Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.Education\n",
    "y = data.Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用keras进行模型搭建：\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( tf.keras.layers.Dense(1, input_shape = (1,)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = 'adam',\n",
    "               loss = 'mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.series.Series'>, <class 'NoneType'>\n",
      "Train on 30 samples\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 1s 17ms/sample - loss: 4977.0059\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4974.5845\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4972.1636\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4969.7437\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4967.3237\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4964.9058\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4962.4873\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 65us/sample - loss: 4960.0703\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4957.6538\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4955.2373\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4952.8223\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4950.4072\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4947.9937\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4945.5806\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4943.1685\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4940.7563\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4938.3457\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4935.9355\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4933.5259\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4931.1177\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4928.7095\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4926.3027\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 4923.8970\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4921.4907\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4919.0864\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 4916.6821\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4914.2793\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4911.8770\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 4909.4761\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4907.0752\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4904.6753\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4902.2764\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 4899.8784\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4897.4814\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4895.0850\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4892.6895\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4890.2949\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4887.9009\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4885.5083\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4883.1162\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4880.7256\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4878.3345\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4875.9458\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4873.5566\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4871.1694\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4868.7822\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4866.3965\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4864.0112\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 4861.6270\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4859.2437\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4856.8613\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4854.4795\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4852.0996\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4849.7197\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4847.3408\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4844.9624\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4842.5854\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4840.2095\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4837.8340\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4835.4595\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4833.0859\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4830.7129\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4828.3418\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4825.9707\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4823.6001\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4821.2314\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4818.8628\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4816.4956\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 68us/sample - loss: 4814.1294\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4811.7637\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4809.3989\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4807.0347\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4804.6719\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4802.3105\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4799.9487\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4797.5884\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4795.2290\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4792.8706\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4790.5137\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4788.1567\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4785.8013\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4783.4458\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4781.0918\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4778.7388\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4776.3862\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4774.0356\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4771.6846\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4769.3345\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4766.9854\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4764.6382\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4762.2905\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4759.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4757.6001\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4755.2554\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4752.9121\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4750.5693\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4748.2275\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4745.8872\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4743.5469\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4741.2085\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4738.8696\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4736.5327\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4734.1963\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 4731.8604\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4729.5259\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4727.1919\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4724.8594\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4722.5269\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4720.1958\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4717.8657\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4715.5366\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4713.2080\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4710.8804\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4708.5537\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4706.2280\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4703.9033\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4701.5791\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4699.2554\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 4696.9331\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4694.6113\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4692.2910\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4689.9712\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4687.6519\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4685.3345\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4683.0176\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4680.7012\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4678.3853\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4676.0713\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4673.7573\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4671.4448\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4669.1328\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4666.8218\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4664.5112\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4662.2021\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4659.8936\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4657.5864\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4655.2798\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4652.9741\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4650.6699\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4648.3657\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4646.0625\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4643.7598\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4641.4585\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4639.1582\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4636.8584\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4634.5596\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4632.2612\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4629.9644\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4627.6685\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4625.3730\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4623.0786\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4620.7847\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4618.4917\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4616.2002\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4613.9092\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4611.6191\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4609.3301\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4607.0410\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4604.7534\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 4602.4673\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4600.1812\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4597.8960\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4595.6118\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4593.3286\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4591.0464\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4588.7651\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 4586.4844\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4584.2041\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4581.9248\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4579.6475\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4577.3696\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4575.0938\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4572.8184\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4570.5439\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4568.2700\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4565.9971\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4563.7251\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4561.4541\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4559.1841\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4556.9146\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4554.6460\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4552.3779\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4550.1113\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4547.8452\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4545.5801\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 4543.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4541.0522\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4538.7900\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4536.5283\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4534.2671\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4532.0073\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4529.7480\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4527.4897\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4525.2329\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4522.9761\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4520.7202\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 4518.4658\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4516.2114\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4513.9585\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 4511.7056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c50f5bd508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
