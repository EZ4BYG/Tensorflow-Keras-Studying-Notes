{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路和7.2中是一样的：都是用文件编写器，把不断变化的指标值写到指定的文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集：只用训练集即可\n",
    "(train_image, train_label), (test_image, test_label) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 维度拓展，从数组转为图像尺寸\n",
    "train_image = tf.expand_dims(train_image, -1)\n",
    "test_image = tf.expand_dims(test_image, -1)\n",
    "train_image.shape\n",
    "\n",
    "# 转换数据类型：\n",
    "train_image = tf.cast( train_image/255, tf.float32 )  # 归一化后，转为float32\n",
    "train_label = tf.cast( train_label, tf.int32 )\n",
    "\n",
    "test_image = tf.cast( test_image/255, tf.float32 )\n",
    "test_label = tf.cast( test_label, tf.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data进行数据集输入：\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices( (train_image,train_label) )\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices( (test_image,test_label) )\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集乱序、分批次：因为后面用tf.keras直接搭网络，所以训练数据一般要.repeat()\n",
    "train_dataset = train_dataset.shuffle(60000).repeat().batch(64)\n",
    "test_dataset = test_dataset.shuffle(10000).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential( [\n",
    "    tf.keras.layers.Conv2D( 16, [3,3], activation = 'relu', input_shape = (None, None, 1) ),\n",
    "    tf.keras.layers.Conv2D( 32, [3,3], activation = 'relu' ),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),  # 换一个Max池化看看（不是重点）\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下是自定义训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义优化器对象：\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# 自定义损失函数对象：\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义指标计算“对象”：\n",
    "train_loss = tf.keras.metrics.Mean('train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_acc')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个batch的训练函数：\n",
    "def train_step(model, images, labels_real):\n",
    "    \n",
    "    with tf.GradientTape() as t:  # 定义t要跟踪哪些函数的梯度变化！\n",
    "        labels_predict = model(images)                      # 当前model对图像的预测\n",
    "        loss_step = loss_func(labels_real, labels_predict)  # 直接用\n",
    "        \n",
    "    # 梯度优化：\n",
    "    grads = t.gradient( loss_step, model.trainable_variables )  # 求目标函数关于“各个”可训练参数的梯度值！\n",
    "    # 用上一步得到“各个”可训练参数梯度值，修改“各个”可训练参数，即也就修改了model\n",
    "    optimizer.apply_gradients( zip(grads, model.trainable_variables) )  \n",
    "    \n",
    "    # 每个batch指标计算：64张训练图片的评价loss和acc —— 公用可调用对象，一直在变！★★★\n",
    "    train_loss( loss_step )\n",
    "    train_accuracy( labels_real, labels_predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般每次epoch测试一次就行了，不用每个batch那么频繁！\n",
    "def test_step(model, images, labels_real):\n",
    "    labels_predict = model(images)\n",
    "    loss_step = loss_func(labels_real, labels_predict)\n",
    "    \n",
    "    # 每个batch指标计算：64张测试图片的评价loss和acc —— 公用可调用对象，一直在变！★★★\n",
    "    test_loss( loss_step )\n",
    "    test_accuracy( labels_real, labels_predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文件编写器：\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # 创建一个时间戳\n",
    "\n",
    "# 文件要写到的磁盘地址：\n",
    "train_log_dir = 'gradient_tape' + current_time + '/train'\n",
    "test_log_dir = 'gradient_tape' + current_time + '/test'\n",
    "\n",
    "# 文件编写器：\n",
    "train_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总体训练的执行函数：注函数！\n",
    "def train():\n",
    "    \n",
    "    # 每个epoch大循环：\n",
    "    for epoch in range(10):\n",
    "        # 每个batch小循环：\n",
    "        for (batch, (images, labels_real)) in enumerate(train_dataset):  # 每次拿一个单位（batch）出来，带上编号\n",
    "            train_step( model, images, labels_real )  # 每个batch的训练！\n",
    "            # 在for循环内，也就是每个batch都在打印！\n",
    "            print( 'Epoch{}_batch{}：train_loss：{}，train_acc：{}'.format(epoch+1, \n",
    "                                                                           batch, \n",
    "                                                                           train_loss.result().numpy(), \n",
    "                                                                           train_accuracy.result().numpy()) )            \n",
    "        # 一直在累积：内部for循环每完毕一次，就是一个epoch完成，打印\n",
    "        print('Epoch{}：train_loss：{}，train_acc：{}'.format(epoch+1,\n",
    "                                                              train_loss.result().numpy(), \n",
    "                                                              train_accuracy.result().numpy()) )\n",
    "        \n",
    "        # 把每个epoch中的train训练的loss和accuracy写入磁盘：此时train_writer是默认的文件编写器！\n",
    "        with train_writer.as_default():\n",
    "            tf.summary.scalar('train_loss', train_loss.result(), step = epoch)\n",
    "            tf.summary.scalar('train_acc', train_accuracy.result(), step = epoch)\n",
    "        \n",
    "        # 每个epoch测试一下当前模型“预测”能力：\n",
    "        for (batch, (images, labels_real)) in enumerate(test_dataset):\n",
    "            test_step( model, images, labels_real )\n",
    "        print('Epoch{}：test_loss：{}，test_acc：{}'.format(epoch+1,\n",
    "                                                            test_loss.result().numpy(),\n",
    "                                                            test_accuracy.result().numpy()) )\n",
    "        \n",
    "        # 把每个epoch中的test测试的loss和accuracy写入磁盘：此时test_writer是默认的文件编写器！\n",
    "        with test_writer.as_default():\n",
    "            tf.summary.scalar('test_loss', test_loss.result(), step = epoch)  # 在tensorboard中显示的标签是test_loss\n",
    "            tf.summary.scalar('test_acc', test_accuracy.result(), step = epoch)\n",
    "        \n",
    "        \n",
    "        # 每个epoch所有训练集完毕，需要把对象重置：\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
