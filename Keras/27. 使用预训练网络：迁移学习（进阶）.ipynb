{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“卷积计算”要比“全连接”的复杂大的多！因此就需要非常长的时间。\n",
    "\n",
    "有一个问题：我们只使用VGG16的卷积基的“层结构”和“权重参数”，并且我们冻结了卷积部分的权重参数让它不随进一步的训练而变化。—— \n",
    "\n",
    "那么：既然卷积基的参数都不变，不参与训练只负责提前特征，那它应该只用运行一次就够了！把特征提取出来并传入Dense全连接层后，往后就可以完全去掉这个卷积部分，剩下只用训练Dense全连接层的权重参数即可。—— \n",
    "\n",
    "因此：每张图片，只需进入一次卷积部分即可，这样就可大大避免“**重复的卷积特征提取操作**”，从而进一步提高速度！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil    # os和shutil用来处理文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始数据太多了，现在专门创建一个文件夹来存储一部分要用的训练集 + 测试集\n",
    "base_dir = 'E:/Python_code/keras_total/日月光华-keras课程资料/dc/try'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_dir_dog = os.path.join(train_dir , 'dog')\n",
    "train_dir_cat = os.path.join(train_dir , 'cat')\n",
    "\n",
    "test_dir = os.path.join(base_dir , 'test')\n",
    "test_dir_dog = os.path.join(test_dir , 'dog')\n",
    "test_dir_cat = os.path.join(test_dir , 'cat')\n",
    "\n",
    "dc_dir = 'E:/Python_code/keras_total/日月光华-keras课程资料/dc/train' # 原始数据所在路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集猫狗各1000张，测试集猫狗各500张。\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(train_dir_dog)\n",
    "    os.mkdir(train_dir_cat)\n",
    "    os.mkdir(test_dir)\n",
    "    os.mkdir(test_dir_dog)\n",
    "    os.mkdir(test_dir_cat)\n",
    "\n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "    for fname in fnames:\n",
    "        s = os.path.join(dc_dir, fname) \n",
    "        d = os.path.join(train_dir_cat, fname)\n",
    "        shutil.copyfile(s, d)   #  把s拷贝到d \n",
    "\n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "    for fname in fnames:\n",
    "        s = os.path.join(dc_dir, fname)\n",
    "        d = os.path.join(test_dir_cat, fname)\n",
    "        shutil.copyfile(s, d)\n",
    "\n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "    for fname in fnames:\n",
    "        s = os.path.join(dc_dir, fname)\n",
    "        d = os.path.join(train_dir_dog, fname)\n",
    "        shutil.copyfile(s, d)\n",
    "\n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "    for fname in fnames:\n",
    "        s = os.path.join(dc_dir, fname)\n",
    "        d = os.path.join(test_dir_dog, fname)\n",
    "        shutil.copyfile(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 创建图片的迭代器，并且设定它的归一化\n",
    "train_datagen = ImageDataGenerator(1/255)\n",
    "test_datagen = ImageDataGenerator(1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 正式创建图片的生成器：train\n",
    "train_generator = train_datagen.flow_from_directory( train_dir,                  # 待读取文件的目录\n",
    "                                                     target_size = (200,200),    # 图片的统一大小 \n",
    "                                                     batch_size = 20,            # 每次读入20张\n",
    "                                                     class_mode = 'binary'       # 该文件夹下分两类：因为我已经正好在该文件夹下分了两个文件夹\n",
    ")\n",
    "\n",
    "# 正式创建图片的生成器：test\n",
    "test_generator = test_datagen.flow_from_directory( test_dir,                  # 待读取文件的目录\n",
    "                                                    target_size = (200,200),    # 图片的统一大小 \n",
    "                                                    batch_size = 20,            # 每次读入20张\n",
    "                                                    class_mode = 'binary'       # 该文件夹下分两类：因为我已经正好在该文件夹下分了两个文件夹\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用keras内置VGG16网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\pycharm\\python374\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_base = keras.applications.VGG16( weights = 'imagenet', include_top = False, input_shape = (200,200,3))  # 每张图进入都是(200,200,3)\n",
    "\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个：其作用是用卷积基来处理每张图片，获得它们对应的特征提取图，然后把特征提取图存起来\n",
    "batch_size = 20\n",
    "\n",
    "# data_generator是生成器，sample_count是样本总数\n",
    "def extract_features(data_generator, sample_count):\n",
    "    i = 0\n",
    "    features = np.zeros( shape=(sample_count, 6, 6, 512) )  # 处理后的结果记录：把每张图变成(6,6,512)的特征提取图 —— 总数(2000,6,6,512)\n",
    "    labels = np.zeros( shape=(sample_count) )\n",
    "    # 特征提取 + 存储部分：20张一批一起做 —— (20, 6, 6, 512)\n",
    "    for inputs_batch, labels_batch in data_generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)    # 每一张图，经过卷积层处理后，返回其对应的特征提取后的图！ √\n",
    "        features[ i * batch_size : (i + 1) * batch_size ] = features_batch  # 把特征图存入\n",
    "        labels[ i * batch_size : (i + 1) * batch_size ] = labels_batch      # 把标签存入\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    return features, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pycharm\\python374\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "# 对训练、测试数据进行特征提取：比较慢！！！s\n",
    "train_features, train_labels = extract_features(train_generator, 2000)\n",
    "test_features, test_labels = extract_features(test_generator, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型搭建： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不再需要加入那个卷积基了Sequentialquentialquentialquentialquenlayersl接把它特征提取的结果所“对应的尺寸”作为输入即可：\n",
    "from keras import layers\n",
    "model = keras.Sequential()\n",
    "model.add( layers.GlobalAveragePooling2D(input_shape=(6, 6, 512)) )  # 这里输入是特征提取后的尺寸大小。\n",
    "model.add( layers.Dense(512, activation='relu') )\n",
    "model.add( layers.Dropout(0.5) )\n",
    "model.add( layers.Dense(1, activation='sigmoid') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 263,169\n",
      "Trainable params: 263,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\pycharm\\python374\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile( optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 864us/step - loss: 0.7175 - acc: 0.8940 - val_loss: 0.1800 - val_acc: 0.9550\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.2144 - acc: 0.9610 - val_loss: 0.2918 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "1500/2000 [=====================>........] - ETA: 0s - loss: 0.1516 - acc: 0.9673"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7bea8facec0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\pycharm\\python374\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32me:\\pycharm\\python374\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\pycharm\\python374\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32me:\\pycharm\\python374\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 速度会快非常多！因为只用训练Dense层的参数！！\n",
    "history = model.fit( train_features, train_labels, epochs=10, batch_size=50, validation_data=(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
