{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/leaf/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "\n",
       "    margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1  0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2  0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3  0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4  0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990 entries, 0 to 989\n",
      "Columns: 194 entries, id to texture64\n",
      "dtypes: float64(192), int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Acer_Opalus', 'Pterocarya_Stenoptera', 'Quercus_Hartwissiana',\n",
       "       'Tilia_Tomentosa', 'Quercus_Variabilis', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Canariensis', 'Quercus_Rubra', 'Quercus_Brantii',\n",
       "       'Salix_Fragilis', 'Zelkova_Serrata', 'Betula_Austrosinensis',\n",
       "       'Quercus_Pontica', 'Quercus_Afares', 'Quercus_Coccifera',\n",
       "       'Fagus_Sylvatica', 'Phildelphus', 'Acer_Palmatum',\n",
       "       'Quercus_Pubescens', 'Populus_Adenopoda', 'Quercus_Trojana',\n",
       "       'Alnus_Sieboldiana', 'Quercus_Ilex', 'Arundinaria_Simonii',\n",
       "       'Acer_Platanoids', 'Quercus_Phillyraeoides', 'Cornus_Chinensis',\n",
       "       'Liriodendron_Tulipifera', 'Cytisus_Battandieri',\n",
       "       'Rhododendron_x_Russellianum', 'Alnus_Rubra',\n",
       "       'Eucalyptus_Glaucescens', 'Cercis_Siliquastrum',\n",
       "       'Cotinus_Coggygria', 'Celtis_Koraiensis', 'Quercus_Crassifolia',\n",
       "       'Quercus_Kewensis', 'Cornus_Controversa', 'Quercus_Pyrenaica',\n",
       "       'Callicarpa_Bodinieri', 'Quercus_Alnifolia', 'Acer_Saccharinum',\n",
       "       'Prunus_X_Shmittii', 'Prunus_Avium', 'Quercus_Greggii',\n",
       "       'Quercus_Suber', 'Quercus_Dolicholepis', 'Ilex_Cornuta',\n",
       "       'Tilia_Oliveri', 'Quercus_Semecarpifolia', 'Quercus_Texana',\n",
       "       'Ginkgo_Biloba', 'Liquidambar_Styraciflua', 'Quercus_Phellos',\n",
       "       'Quercus_Palustris', 'Alnus_Maximowiczii', 'Quercus_Agrifolia',\n",
       "       'Acer_Pictum', 'Acer_Rufinerve', 'Lithocarpus_Cleistocarpus',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Ilex_Aquifolium',\n",
       "       'Acer_Circinatum', 'Quercus_Coccinea', 'Quercus_Cerris',\n",
       "       'Quercus_Chrysolepis', 'Eucalyptus_Neglecta', 'Tilia_Platyphyllos',\n",
       "       'Alnus_Cordata', 'Populus_Nigra', 'Acer_Capillipes',\n",
       "       'Magnolia_Heptapeta', 'Acer_Mono', 'Cornus_Macrophylla',\n",
       "       'Crataegus_Monogyna', 'Quercus_x_Turneri', 'Quercus_Castaneifolia',\n",
       "       'Lithocarpus_Edulis', 'Populus_Grandidentata', 'Acer_Rubrum',\n",
       "       'Quercus_Imbricaria', 'Eucalyptus_Urnigera', 'Quercus_Crassipes',\n",
       "       'Viburnum_Tinus', 'Morus_Nigra', 'Quercus_Vulcanica',\n",
       "       'Alnus_Viridis', 'Betula_Pendula', 'Olea_Europaea',\n",
       "       'Quercus_Ellipsoidalis', 'Quercus_x_Hispanica', 'Quercus_Shumardii',\n",
       "       'Quercus_Rhysophylla', 'Castanea_Sativa', 'Ulmus_Bergmanniana',\n",
       "       'Quercus_Nigra', 'Salix_Intergra', 'Quercus_Infectoria_sub',\n",
       "       'Sorbus_Aria'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.species.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.factorize(data.pop('species'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((742, 192), (248, 192))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_x.mean(axis=0)\n",
    "std = train_x.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_norm = (train_x - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_norm = (test_x - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_norm = np.expand_dims(train_x_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 192, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_norm = np.expand_dims(test_x_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 192, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建：初级模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 192, 32)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 64, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 99)                3267      \n",
      "=================================================================\n",
      "Total params: 10,723\n",
      "Trainable params: 10,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 192, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 1s 2ms/step - loss: 4.6008 - acc: 0.0067 - val_loss: 4.5969 - val_acc: 0.0040\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 4.5876 - acc: 0.0135 - val_loss: 4.5945 - val_acc: 0.0323\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 4.5768 - acc: 0.0202 - val_loss: 4.5885 - val_acc: 0.0282\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 4.5639 - acc: 0.0202 - val_loss: 4.5799 - val_acc: 0.0202\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 4.5473 - acc: 0.0202 - val_loss: 4.5684 - val_acc: 0.0202\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 4.5245 - acc: 0.0202 - val_loss: 4.5522 - val_acc: 0.0202\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 4.4956 - acc: 0.0202 - val_loss: 4.5299 - val_acc: 0.0202\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 0s 99us/step - loss: 4.4611 - acc: 0.0202 - val_loss: 4.5048 - val_acc: 0.0202\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 4.4233 - acc: 0.0202 - val_loss: 4.4725 - val_acc: 0.0202\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 4.3848 - acc: 0.0202 - val_loss: 4.4424 - val_acc: 0.0202\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 4.3408 - acc: 0.0189 - val_loss: 4.4158 - val_acc: 0.0202\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 4.3011 - acc: 0.0229 - val_loss: 4.3819 - val_acc: 0.0202\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 4.2597 - acc: 0.0216 - val_loss: 4.3523 - val_acc: 0.0323\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 4.2196 - acc: 0.0270 - val_loss: 4.3229 - val_acc: 0.0323\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 4.1781 - acc: 0.0310 - val_loss: 4.2954 - val_acc: 0.0323\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 4.1389 - acc: 0.0229 - val_loss: 4.2593 - val_acc: 0.0323\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 4.0996 - acc: 0.0229 - val_loss: 4.2232 - val_acc: 0.0323\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 4.0609 - acc: 0.0243 - val_loss: 4.1935 - val_acc: 0.0282\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 4.0214 - acc: 0.0296 - val_loss: 4.1575 - val_acc: 0.0242\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.9843 - acc: 0.0310 - val_loss: 4.1177 - val_acc: 0.0363\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.9459 - acc: 0.0323 - val_loss: 4.0784 - val_acc: 0.0363\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.9109 - acc: 0.0323 - val_loss: 4.0487 - val_acc: 0.0242\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.8749 - acc: 0.0350 - val_loss: 4.0155 - val_acc: 0.0282\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.8409 - acc: 0.0458 - val_loss: 3.9767 - val_acc: 0.0323\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.8066 - acc: 0.0526 - val_loss: 3.9411 - val_acc: 0.0242\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 3.7761 - acc: 0.0633 - val_loss: 3.9022 - val_acc: 0.0282\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.7403 - acc: 0.0741 - val_loss: 3.8684 - val_acc: 0.0444\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.7160 - acc: 0.0701 - val_loss: 3.8355 - val_acc: 0.0403\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.6877 - acc: 0.0849 - val_loss: 3.8211 - val_acc: 0.0444\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.6619 - acc: 0.0755 - val_loss: 3.7870 - val_acc: 0.0363\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 3.6374 - acc: 0.0714 - val_loss: 3.7530 - val_acc: 0.0484\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.6116 - acc: 0.0984 - val_loss: 3.7343 - val_acc: 0.0565\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.5894 - acc: 0.0849 - val_loss: 3.7107 - val_acc: 0.0605\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.5656 - acc: 0.0916 - val_loss: 3.6738 - val_acc: 0.0645\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.5453 - acc: 0.0849 - val_loss: 3.6641 - val_acc: 0.0726\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.5205 - acc: 0.1132 - val_loss: 3.6525 - val_acc: 0.0524\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.4987 - acc: 0.1105 - val_loss: 3.6264 - val_acc: 0.0323\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.4842 - acc: 0.1038 - val_loss: 3.6088 - val_acc: 0.0645\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.4623 - acc: 0.1024 - val_loss: 3.5819 - val_acc: 0.0927\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.4370 - acc: 0.1240 - val_loss: 3.5718 - val_acc: 0.0605\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.4189 - acc: 0.1186 - val_loss: 3.5474 - val_acc: 0.0645\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.4109 - acc: 0.1307 - val_loss: 3.5360 - val_acc: 0.0766\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.3856 - acc: 0.1132 - val_loss: 3.5370 - val_acc: 0.0887\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 3.3660 - acc: 0.1348 - val_loss: 3.5094 - val_acc: 0.0887\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.3505 - acc: 0.1375 - val_loss: 3.4773 - val_acc: 0.0766\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.3389 - acc: 0.1321 - val_loss: 3.4819 - val_acc: 0.0887\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 3.3293 - acc: 0.1240 - val_loss: 3.4715 - val_acc: 0.0927\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.3048 - acc: 0.1536 - val_loss: 3.4626 - val_acc: 0.0726\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.2838 - acc: 0.1456 - val_loss: 3.4336 - val_acc: 0.0968\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.2757 - acc: 0.1240 - val_loss: 3.4280 - val_acc: 0.0968\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 3.2594 - acc: 0.1321 - val_loss: 3.4168 - val_acc: 0.1129\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.2413 - acc: 0.1402 - val_loss: 3.3885 - val_acc: 0.1008\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.2264 - acc: 0.1536 - val_loss: 3.3813 - val_acc: 0.1048\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.2167 - acc: 0.1523 - val_loss: 3.3681 - val_acc: 0.1290\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 3.2129 - acc: 0.1779 - val_loss: 3.3638 - val_acc: 0.0806\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 3.1898 - acc: 0.1550 - val_loss: 3.3652 - val_acc: 0.1089\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.1738 - acc: 0.1712 - val_loss: 3.3534 - val_acc: 0.1169\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.1635 - acc: 0.1604 - val_loss: 3.3322 - val_acc: 0.1048\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.1438 - acc: 0.1577 - val_loss: 3.3385 - val_acc: 0.1331\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.1328 - acc: 0.1765 - val_loss: 3.3222 - val_acc: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.1252 - acc: 0.1725 - val_loss: 3.3256 - val_acc: 0.1129\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 3.1201 - acc: 0.1658 - val_loss: 3.2875 - val_acc: 0.1290\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.1065 - acc: 0.1563 - val_loss: 3.2743 - val_acc: 0.1371\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.0881 - acc: 0.1752 - val_loss: 3.2775 - val_acc: 0.1452\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 3.0776 - acc: 0.1914 - val_loss: 3.2854 - val_acc: 0.0887\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.0650 - acc: 0.1712 - val_loss: 3.2521 - val_acc: 0.1169\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.0606 - acc: 0.1698 - val_loss: 3.2544 - val_acc: 0.1048\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.0449 - acc: 0.1725 - val_loss: 3.2455 - val_acc: 0.1573\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 3.0291 - acc: 0.1968 - val_loss: 3.2335 - val_acc: 0.1089\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.0247 - acc: 0.1900 - val_loss: 3.2173 - val_acc: 0.1210\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.0093 - acc: 0.1941 - val_loss: 3.2242 - val_acc: 0.1331\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.9925 - acc: 0.1995 - val_loss: 3.2005 - val_acc: 0.1331\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.9848 - acc: 0.2116 - val_loss: 3.1899 - val_acc: 0.1331\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.9814 - acc: 0.2049 - val_loss: 3.2134 - val_acc: 0.1250\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.9651 - acc: 0.1954 - val_loss: 3.1703 - val_acc: 0.1290\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.9397 - acc: 0.2170 - val_loss: 3.1762 - val_acc: 0.1169\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.9516 - acc: 0.1860 - val_loss: 3.1927 - val_acc: 0.1210\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.9334 - acc: 0.1914 - val_loss: 3.1427 - val_acc: 0.1532\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.9331 - acc: 0.2237 - val_loss: 3.1467 - val_acc: 0.1089\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.9092 - acc: 0.2183 - val_loss: 3.1276 - val_acc: 0.1573\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.9077 - acc: 0.2291 - val_loss: 3.1709 - val_acc: 0.1411\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.8833 - acc: 0.2291 - val_loss: 3.1097 - val_acc: 0.1653\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.8947 - acc: 0.2143 - val_loss: 3.1104 - val_acc: 0.1613\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.8622 - acc: 0.2332 - val_loss: 3.1201 - val_acc: 0.1532\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.8688 - acc: 0.2197 - val_loss: 3.0961 - val_acc: 0.1492\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.8463 - acc: 0.2129 - val_loss: 3.1355 - val_acc: 0.1613\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.8518 - acc: 0.2197 - val_loss: 3.1099 - val_acc: 0.1855\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.8351 - acc: 0.2345 - val_loss: 3.0697 - val_acc: 0.1532\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.8236 - acc: 0.2547 - val_loss: 3.0879 - val_acc: 0.1492\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.8246 - acc: 0.2264 - val_loss: 3.0575 - val_acc: 0.1532\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7944 - acc: 0.2588 - val_loss: 3.0537 - val_acc: 0.2097\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.8059 - acc: 0.2520 - val_loss: 3.0274 - val_acc: 0.1895\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7907 - acc: 0.2453 - val_loss: 3.0123 - val_acc: 0.1855\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7774 - acc: 0.2385 - val_loss: 3.0554 - val_acc: 0.1613\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7791 - acc: 0.2412 - val_loss: 3.0054 - val_acc: 0.1815\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.7588 - acc: 0.2305 - val_loss: 3.0618 - val_acc: 0.1573\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.7470 - acc: 0.2574 - val_loss: 3.0023 - val_acc: 0.1895\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7341 - acc: 0.2790 - val_loss: 3.0029 - val_acc: 0.2016\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.7460 - acc: 0.2466 - val_loss: 2.9752 - val_acc: 0.1976\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.7070 - acc: 0.2763 - val_loss: 2.9764 - val_acc: 0.2218\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.7223 - acc: 0.2736 - val_loss: 2.9446 - val_acc: 0.2177\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.7014 - acc: 0.2911 - val_loss: 2.9905 - val_acc: 0.1694\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.7020 - acc: 0.2547 - val_loss: 2.9783 - val_acc: 0.1694\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.6928 - acc: 0.2642 - val_loss: 3.0402 - val_acc: 0.1815\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.6899 - acc: 0.2749 - val_loss: 2.9657 - val_acc: 0.1895\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.6489 - acc: 0.2978 - val_loss: 2.9942 - val_acc: 0.1976\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.6688 - acc: 0.2871 - val_loss: 2.9396 - val_acc: 0.2056\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.6444 - acc: 0.3046 - val_loss: 2.9314 - val_acc: 0.2056\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.6416 - acc: 0.2722 - val_loss: 2.9598 - val_acc: 0.2056\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.6411 - acc: 0.2830 - val_loss: 2.9242 - val_acc: 0.2218\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 2.6233 - acc: 0.3059 - val_loss: 2.9088 - val_acc: 0.2379\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.6079 - acc: 0.3032 - val_loss: 2.9312 - val_acc: 0.2056\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.6057 - acc: 0.3059 - val_loss: 2.8922 - val_acc: 0.1976\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 2.6051 - acc: 0.3059 - val_loss: 2.9251 - val_acc: 0.2016\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.5940 - acc: 0.3086 - val_loss: 2.9350 - val_acc: 0.2097\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.5952 - acc: 0.2803 - val_loss: 2.8765 - val_acc: 0.2177\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.5734 - acc: 0.3059 - val_loss: 2.9034 - val_acc: 0.1613\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.5521 - acc: 0.3329 - val_loss: 2.9362 - val_acc: 0.2298\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.5699 - acc: 0.3127 - val_loss: 2.8927 - val_acc: 0.1895\n",
      "Epoch 120/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.5524 - acc: 0.3113 - val_loss: 2.8771 - val_acc: 0.2258\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 93us/step - loss: 2.5345 - acc: 0.3221 - val_loss: 2.8804 - val_acc: 0.2016\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.5560 - acc: 0.3019 - val_loss: 2.8511 - val_acc: 0.2581\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.5181 - acc: 0.3248 - val_loss: 2.8445 - val_acc: 0.2581\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.5104 - acc: 0.3113 - val_loss: 2.8833 - val_acc: 0.2298\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.5229 - acc: 0.3369 - val_loss: 2.8409 - val_acc: 0.2621\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.5024 - acc: 0.3248 - val_loss: 2.8532 - val_acc: 0.2339\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.4825 - acc: 0.3154 - val_loss: 2.8307 - val_acc: 0.2379\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.4910 - acc: 0.3329 - val_loss: 2.8472 - val_acc: 0.1976\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.4687 - acc: 0.3504 - val_loss: 2.7928 - val_acc: 0.2702\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.4622 - acc: 0.3315 - val_loss: 2.8080 - val_acc: 0.2581\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.4655 - acc: 0.3571 - val_loss: 2.8141 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.4557 - acc: 0.3383 - val_loss: 2.7898 - val_acc: 0.2258\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.4306 - acc: 0.3598 - val_loss: 2.8052 - val_acc: 0.2460\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.4248 - acc: 0.3477 - val_loss: 2.7692 - val_acc: 0.2581\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 2.4310 - acc: 0.3235 - val_loss: 2.8456 - val_acc: 0.2419\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.4200 - acc: 0.3450 - val_loss: 2.7737 - val_acc: 0.2621\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.4125 - acc: 0.3464 - val_loss: 2.7261 - val_acc: 0.2863\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.4096 - acc: 0.3612 - val_loss: 2.8095 - val_acc: 0.2298\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.3940 - acc: 0.3679 - val_loss: 2.7879 - val_acc: 0.2500\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.3857 - acc: 0.3531 - val_loss: 2.7473 - val_acc: 0.2621\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.3928 - acc: 0.3639 - val_loss: 2.7969 - val_acc: 0.2339\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.3811 - acc: 0.3437 - val_loss: 2.7431 - val_acc: 0.2702\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 2.3647 - acc: 0.3491 - val_loss: 2.7321 - val_acc: 0.2661\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 2.3558 - acc: 0.3841 - val_loss: 2.7473 - val_acc: 0.2621\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.3597 - acc: 0.3558 - val_loss: 2.7708 - val_acc: 0.2581\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.3524 - acc: 0.3437 - val_loss: 2.7579 - val_acc: 0.2742\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.3520 - acc: 0.3504 - val_loss: 2.7095 - val_acc: 0.2903\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.3377 - acc: 0.3854 - val_loss: 2.7321 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.3203 - acc: 0.3814 - val_loss: 2.7220 - val_acc: 0.2621\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.3111 - acc: 0.3693 - val_loss: 2.7109 - val_acc: 0.2581\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.3138 - acc: 0.3693 - val_loss: 2.6693 - val_acc: 0.2661\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.3054 - acc: 0.3868 - val_loss: 2.7362 - val_acc: 0.2339\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.2969 - acc: 0.3747 - val_loss: 2.6840 - val_acc: 0.2419\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.2884 - acc: 0.3935 - val_loss: 2.6820 - val_acc: 0.2702\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.2682 - acc: 0.4003 - val_loss: 2.7137 - val_acc: 0.2863\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.2854 - acc: 0.3841 - val_loss: 2.7112 - val_acc: 0.2419\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 2.2780 - acc: 0.3827 - val_loss: 2.6688 - val_acc: 0.2661\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.2629 - acc: 0.3976 - val_loss: 2.6649 - val_acc: 0.2944\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.2492 - acc: 0.3949 - val_loss: 2.6429 - val_acc: 0.2621\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.2342 - acc: 0.3989 - val_loss: 2.6849 - val_acc: 0.2823\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.2427 - acc: 0.4070 - val_loss: 2.6444 - val_acc: 0.2782\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.2241 - acc: 0.4124 - val_loss: 2.6626 - val_acc: 0.3024\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.2312 - acc: 0.4097 - val_loss: 2.6515 - val_acc: 0.2863\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.2167 - acc: 0.4043 - val_loss: 2.6170 - val_acc: 0.3105\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.2131 - acc: 0.3935 - val_loss: 2.6191 - val_acc: 0.2863\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.2022 - acc: 0.4084 - val_loss: 2.6215 - val_acc: 0.2742\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.2084 - acc: 0.4259 - val_loss: 2.6558 - val_acc: 0.2984\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.1868 - acc: 0.4097 - val_loss: 2.6158 - val_acc: 0.2823\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.1894 - acc: 0.4097 - val_loss: 2.6562 - val_acc: 0.2661\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.1974 - acc: 0.4218 - val_loss: 2.6071 - val_acc: 0.2782\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.1737 - acc: 0.4151 - val_loss: 2.5617 - val_acc: 0.3306\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 2.1659 - acc: 0.4070 - val_loss: 2.6316 - val_acc: 0.2903\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.1655 - acc: 0.4259 - val_loss: 2.6209 - val_acc: 0.3065\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.1605 - acc: 0.4084 - val_loss: 2.6249 - val_acc: 0.2863\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.1515 - acc: 0.4353 - val_loss: 2.5285 - val_acc: 0.3105\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.1269 - acc: 0.4367 - val_loss: 2.6195 - val_acc: 0.3024\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.1360 - acc: 0.4164 - val_loss: 2.5719 - val_acc: 0.3306\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 2.1395 - acc: 0.4164 - val_loss: 2.5732 - val_acc: 0.3226\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.1089 - acc: 0.4232 - val_loss: 2.5725 - val_acc: 0.2823\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.1063 - acc: 0.4380 - val_loss: 2.5968 - val_acc: 0.3105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 2.1262 - acc: 0.4232 - val_loss: 2.5492 - val_acc: 0.3105\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.0956 - acc: 0.4313 - val_loss: 2.5536 - val_acc: 0.2702\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.0954 - acc: 0.4380 - val_loss: 2.5873 - val_acc: 0.2984\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.0980 - acc: 0.4447 - val_loss: 2.5355 - val_acc: 0.3266\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.0675 - acc: 0.4663 - val_loss: 2.5333 - val_acc: 0.2984\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.0708 - acc: 0.4420 - val_loss: 2.4789 - val_acc: 0.3065\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.0868 - acc: 0.4191 - val_loss: 2.5355 - val_acc: 0.3185\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.0710 - acc: 0.4353 - val_loss: 2.4940 - val_acc: 0.3710\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.0868 - acc: 0.4272 - val_loss: 2.4800 - val_acc: 0.3306\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.0328 - acc: 0.4677 - val_loss: 2.5036 - val_acc: 0.3185\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.0690 - acc: 0.4340 - val_loss: 2.5062 - val_acc: 0.3065\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.0478 - acc: 0.4569 - val_loss: 2.5093 - val_acc: 0.3065\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.0473 - acc: 0.4407 - val_loss: 2.4876 - val_acc: 0.3185\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.0384 - acc: 0.4488 - val_loss: 2.5039 - val_acc: 0.3185\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.0105 - acc: 0.4838 - val_loss: 2.5365 - val_acc: 0.2903\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.0283 - acc: 0.4555 - val_loss: 2.5348 - val_acc: 0.3226\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 2.0291 - acc: 0.4663 - val_loss: 2.4681 - val_acc: 0.3226\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.9979 - acc: 0.4933 - val_loss: 2.4946 - val_acc: 0.3145\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 2.0027 - acc: 0.4663 - val_loss: 2.4884 - val_acc: 0.3347\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.0064 - acc: 0.4461 - val_loss: 2.4300 - val_acc: 0.3508\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 2.0079 - acc: 0.4501 - val_loss: 2.4615 - val_acc: 0.3266\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.9966 - acc: 0.4663 - val_loss: 2.4711 - val_acc: 0.3185\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.9744 - acc: 0.4744 - val_loss: 2.5085 - val_acc: 0.3145\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.9767 - acc: 0.4663 - val_loss: 2.5216 - val_acc: 0.2984\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.9713 - acc: 0.4623 - val_loss: 2.4080 - val_acc: 0.3629\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.9644 - acc: 0.4811 - val_loss: 2.4581 - val_acc: 0.3185\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.9762 - acc: 0.4582 - val_loss: 2.4726 - val_acc: 0.3347\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.9491 - acc: 0.4757 - val_loss: 2.4084 - val_acc: 0.3589\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.9575 - acc: 0.4690 - val_loss: 2.4184 - val_acc: 0.3347\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.9593 - acc: 0.4811 - val_loss: 2.4525 - val_acc: 0.3145\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.9386 - acc: 0.4892 - val_loss: 2.4548 - val_acc: 0.3226\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.9335 - acc: 0.4663 - val_loss: 2.4111 - val_acc: 0.3427\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.9284 - acc: 0.4825 - val_loss: 2.4581 - val_acc: 0.3508\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.9368 - acc: 0.4677 - val_loss: 2.4255 - val_acc: 0.3347\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.9169 - acc: 0.4838 - val_loss: 2.3948 - val_acc: 0.3347\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.9192 - acc: 0.4852 - val_loss: 2.4086 - val_acc: 0.3468\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.8920 - acc: 0.4906 - val_loss: 2.4423 - val_acc: 0.3468\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.8981 - acc: 0.4919 - val_loss: 2.4513 - val_acc: 0.3387\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.8871 - acc: 0.5108 - val_loss: 2.3763 - val_acc: 0.3306\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.8847 - acc: 0.4933 - val_loss: 2.3813 - val_acc: 0.3911\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.9251 - acc: 0.4650 - val_loss: 2.4034 - val_acc: 0.3508\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.8784 - acc: 0.5000 - val_loss: 2.3976 - val_acc: 0.3468\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 0s 99us/step - loss: 1.8860 - acc: 0.4825 - val_loss: 2.3635 - val_acc: 0.3669\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.8719 - acc: 0.5027 - val_loss: 2.3205 - val_acc: 0.3508\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 1.8775 - acc: 0.4892 - val_loss: 2.3792 - val_acc: 0.3629\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.8660 - acc: 0.4838 - val_loss: 2.3073 - val_acc: 0.3790\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.8455 - acc: 0.5121 - val_loss: 2.3496 - val_acc: 0.3669\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 0s 99us/step - loss: 1.8326 - acc: 0.5108 - val_loss: 2.3599 - val_acc: 0.4032\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.8565 - acc: 0.4973 - val_loss: 2.3578 - val_acc: 0.3387\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.8376 - acc: 0.5202 - val_loss: 2.3760 - val_acc: 0.3387\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.8448 - acc: 0.4973 - val_loss: 2.4366 - val_acc: 0.3347\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.8407 - acc: 0.4919 - val_loss: 2.4030 - val_acc: 0.3387\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.8336 - acc: 0.5175 - val_loss: 2.3761 - val_acc: 0.3669\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.8256 - acc: 0.5081 - val_loss: 2.3894 - val_acc: 0.3105\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.7958 - acc: 0.5323 - val_loss: 2.3334 - val_acc: 0.3508\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.8174 - acc: 0.4933 - val_loss: 2.2850 - val_acc: 0.3992\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.8062 - acc: 0.5296 - val_loss: 2.3255 - val_acc: 0.3629\n",
      "Epoch 238/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.7904 - acc: 0.5121 - val_loss: 2.3598 - val_acc: 0.3508\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.8094 - acc: 0.5135 - val_loss: 2.3515 - val_acc: 0.3427\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.8135 - acc: 0.5121 - val_loss: 2.3086 - val_acc: 0.3468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.7832 - acc: 0.5121 - val_loss: 2.3012 - val_acc: 0.3710\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.7849 - acc: 0.5256 - val_loss: 2.3190 - val_acc: 0.3669\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.7829 - acc: 0.5189 - val_loss: 2.3063 - val_acc: 0.3145\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.7737 - acc: 0.5296 - val_loss: 2.3356 - val_acc: 0.3669\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.7734 - acc: 0.5135 - val_loss: 2.3435 - val_acc: 0.3508\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.7700 - acc: 0.5270 - val_loss: 2.2673 - val_acc: 0.3952\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.7612 - acc: 0.5445 - val_loss: 2.2626 - val_acc: 0.3911\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.7566 - acc: 0.5418 - val_loss: 2.2834 - val_acc: 0.3710\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.7494 - acc: 0.5445 - val_loss: 2.2473 - val_acc: 0.3992\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.7648 - acc: 0.5310 - val_loss: 2.2765 - val_acc: 0.3710\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.7385 - acc: 0.5512 - val_loss: 2.2918 - val_acc: 0.3710\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.7305 - acc: 0.5391 - val_loss: 2.2079 - val_acc: 0.3790\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.7154 - acc: 0.5526 - val_loss: 2.3431 - val_acc: 0.3589\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.7320 - acc: 0.5350 - val_loss: 2.2493 - val_acc: 0.3952\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.7122 - acc: 0.5499 - val_loss: 2.2281 - val_acc: 0.3669\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.7112 - acc: 0.5364 - val_loss: 2.2415 - val_acc: 0.3831\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.7060 - acc: 0.5458 - val_loss: 2.4042 - val_acc: 0.3145\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.6982 - acc: 0.5472 - val_loss: 2.3553 - val_acc: 0.3347\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.7398 - acc: 0.5108 - val_loss: 2.2706 - val_acc: 0.3468\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.6912 - acc: 0.5674 - val_loss: 2.2674 - val_acc: 0.3790\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.7117 - acc: 0.5499 - val_loss: 2.2153 - val_acc: 0.4073\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.6934 - acc: 0.5566 - val_loss: 2.1674 - val_acc: 0.4516\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.6666 - acc: 0.5539 - val_loss: 2.2909 - val_acc: 0.3871\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.6778 - acc: 0.5472 - val_loss: 2.3067 - val_acc: 0.3710\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.6964 - acc: 0.5270 - val_loss: 2.2636 - val_acc: 0.3871\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.6800 - acc: 0.5539 - val_loss: 2.1958 - val_acc: 0.4032\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.6556 - acc: 0.5633 - val_loss: 2.1874 - val_acc: 0.3911\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.6644 - acc: 0.5445 - val_loss: 2.2327 - val_acc: 0.4032\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.6569 - acc: 0.5485 - val_loss: 2.2151 - val_acc: 0.4315\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.6401 - acc: 0.5647 - val_loss: 2.1897 - val_acc: 0.4274\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.6512 - acc: 0.5660 - val_loss: 2.2067 - val_acc: 0.3871\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.6779 - acc: 0.5310 - val_loss: 2.2004 - val_acc: 0.3911\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.6434 - acc: 0.5687 - val_loss: 2.1780 - val_acc: 0.4113\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.6342 - acc: 0.5741 - val_loss: 2.2078 - val_acc: 0.3831\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.6206 - acc: 0.5768 - val_loss: 2.1865 - val_acc: 0.4073\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.6314 - acc: 0.5593 - val_loss: 2.1907 - val_acc: 0.4274\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.6225 - acc: 0.5714 - val_loss: 2.2325 - val_acc: 0.4113\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.6165 - acc: 0.5566 - val_loss: 2.1739 - val_acc: 0.4113\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.6003 - acc: 0.5836 - val_loss: 2.2042 - val_acc: 0.3831\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.6087 - acc: 0.5687 - val_loss: 2.2280 - val_acc: 0.3790\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.6285 - acc: 0.5458 - val_loss: 2.1489 - val_acc: 0.4315\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.6157 - acc: 0.5849 - val_loss: 2.1224 - val_acc: 0.4395\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.6105 - acc: 0.5606 - val_loss: 2.1153 - val_acc: 0.4355\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.6041 - acc: 0.5795 - val_loss: 2.1203 - val_acc: 0.4032\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.5811 - acc: 0.5755 - val_loss: 2.1159 - val_acc: 0.4194\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.5804 - acc: 0.5957 - val_loss: 2.1976 - val_acc: 0.3952\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.5928 - acc: 0.5755 - val_loss: 2.1251 - val_acc: 0.4073\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5786 - acc: 0.5943 - val_loss: 2.1811 - val_acc: 0.4274\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5819 - acc: 0.5633 - val_loss: 2.2253 - val_acc: 0.3992\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.5736 - acc: 0.5822 - val_loss: 2.1793 - val_acc: 0.3992\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.5809 - acc: 0.5822 - val_loss: 2.1868 - val_acc: 0.4194\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.5585 - acc: 0.5741 - val_loss: 2.1156 - val_acc: 0.4355\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.5516 - acc: 0.5903 - val_loss: 2.1170 - val_acc: 0.4234\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.5842 - acc: 0.5606 - val_loss: 2.0929 - val_acc: 0.4113\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5577 - acc: 0.5714 - val_loss: 2.0693 - val_acc: 0.4355\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.5523 - acc: 0.6024 - val_loss: 2.1692 - val_acc: 0.3911\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.5379 - acc: 0.5957 - val_loss: 2.1535 - val_acc: 0.4274\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.5429 - acc: 0.5997 - val_loss: 2.0905 - val_acc: 0.4355\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.5306 - acc: 0.5782 - val_loss: 2.2130 - val_acc: 0.3911\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.5604 - acc: 0.5768 - val_loss: 2.1234 - val_acc: 0.4234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5181 - acc: 0.6186 - val_loss: 2.1766 - val_acc: 0.4355\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.5312 - acc: 0.5849 - val_loss: 2.0506 - val_acc: 0.4435\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.5164 - acc: 0.5970 - val_loss: 2.0897 - val_acc: 0.4435\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.5168 - acc: 0.5970 - val_loss: 2.1170 - val_acc: 0.3992\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.5290 - acc: 0.6038 - val_loss: 2.0939 - val_acc: 0.4073\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5030 - acc: 0.5849 - val_loss: 2.0641 - val_acc: 0.4758\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4972 - acc: 0.6186 - val_loss: 2.1445 - val_acc: 0.4597\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.5145 - acc: 0.5943 - val_loss: 2.0837 - val_acc: 0.4637\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4958 - acc: 0.6240 - val_loss: 2.0724 - val_acc: 0.4274\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.4755 - acc: 0.6065 - val_loss: 1.9849 - val_acc: 0.4516\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4803 - acc: 0.6119 - val_loss: 2.0615 - val_acc: 0.4274\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.4863 - acc: 0.6105 - val_loss: 2.1204 - val_acc: 0.4032\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.4771 - acc: 0.5957 - val_loss: 2.1049 - val_acc: 0.4315\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.5145 - acc: 0.5714 - val_loss: 2.0618 - val_acc: 0.4677\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.4696 - acc: 0.6456 - val_loss: 2.0641 - val_acc: 0.4637\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.4682 - acc: 0.6199 - val_loss: 1.9814 - val_acc: 0.4718\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4751 - acc: 0.6024 - val_loss: 2.1081 - val_acc: 0.4113\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4914 - acc: 0.5916 - val_loss: 1.9821 - val_acc: 0.4839\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4548 - acc: 0.6253 - val_loss: 1.9805 - val_acc: 0.4516\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4311 - acc: 0.6361 - val_loss: 2.1183 - val_acc: 0.3871\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4561 - acc: 0.6146 - val_loss: 2.0700 - val_acc: 0.4113\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.4683 - acc: 0.5984 - val_loss: 2.0972 - val_acc: 0.4315\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.4567 - acc: 0.6146 - val_loss: 2.1046 - val_acc: 0.4274\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.4269 - acc: 0.6334 - val_loss: 2.0134 - val_acc: 0.4435\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.4497 - acc: 0.6267 - val_loss: 2.0169 - val_acc: 0.4476\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4224 - acc: 0.6280 - val_loss: 1.9738 - val_acc: 0.4395\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4156 - acc: 0.6361 - val_loss: 2.0869 - val_acc: 0.4274\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.4289 - acc: 0.6240 - val_loss: 2.0136 - val_acc: 0.4476\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4183 - acc: 0.6199 - val_loss: 1.9619 - val_acc: 0.4677\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4118 - acc: 0.6307 - val_loss: 2.0558 - val_acc: 0.4274\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.4019 - acc: 0.6469 - val_loss: 2.0825 - val_acc: 0.4395\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.4283 - acc: 0.5984 - val_loss: 2.0136 - val_acc: 0.4315\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.4091 - acc: 0.6294 - val_loss: 1.9981 - val_acc: 0.4637\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.4004 - acc: 0.6536 - val_loss: 2.0471 - val_acc: 0.4234\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4025 - acc: 0.6307 - val_loss: 1.9923 - val_acc: 0.4274\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4160 - acc: 0.6119 - val_loss: 1.9706 - val_acc: 0.4879\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.3868 - acc: 0.6469 - val_loss: 1.9846 - val_acc: 0.4516\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3902 - acc: 0.6456 - val_loss: 1.9221 - val_acc: 0.4879\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3734 - acc: 0.6442 - val_loss: 1.9793 - val_acc: 0.4355\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.3585 - acc: 0.6604 - val_loss: 2.0122 - val_acc: 0.4194\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3693 - acc: 0.6671 - val_loss: 1.9447 - val_acc: 0.4798\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3890 - acc: 0.6240 - val_loss: 1.9382 - val_acc: 0.4919\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.3825 - acc: 0.6173 - val_loss: 1.9381 - val_acc: 0.4718\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.3718 - acc: 0.6361 - val_loss: 2.0337 - val_acc: 0.4677\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.3578 - acc: 0.6442 - val_loss: 1.9743 - val_acc: 0.4315\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3469 - acc: 0.6496 - val_loss: 1.9783 - val_acc: 0.4395\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3587 - acc: 0.6536 - val_loss: 1.9155 - val_acc: 0.4879\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.3599 - acc: 0.6402 - val_loss: 2.0340 - val_acc: 0.4315\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.3345 - acc: 0.6604 - val_loss: 1.9144 - val_acc: 0.4879\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.3396 - acc: 0.6388 - val_loss: 1.9755 - val_acc: 0.4274\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3496 - acc: 0.6550 - val_loss: 1.9113 - val_acc: 0.4798\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3298 - acc: 0.6577 - val_loss: 1.9283 - val_acc: 0.4637\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 1.3590 - acc: 0.6590 - val_loss: 1.9604 - val_acc: 0.4476\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.3254 - acc: 0.6415 - val_loss: 1.9114 - val_acc: 0.4919\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.2988 - acc: 0.6712 - val_loss: 2.0054 - val_acc: 0.4315\n",
      "Epoch 356/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.3548 - acc: 0.6334 - val_loss: 1.9571 - val_acc: 0.4677\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3175 - acc: 0.6429 - val_loss: 2.0031 - val_acc: 0.4435\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2992 - acc: 0.6604 - val_loss: 1.9859 - val_acc: 0.4597\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.3092 - acc: 0.6550 - val_loss: 1.9003 - val_acc: 0.4476\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3212 - acc: 0.6415 - val_loss: 1.9676 - val_acc: 0.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.3001 - acc: 0.6482 - val_loss: 1.9621 - val_acc: 0.4677\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.3168 - acc: 0.6456 - val_loss: 1.9750 - val_acc: 0.4798\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.2901 - acc: 0.6469 - val_loss: 1.9569 - val_acc: 0.4234\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2943 - acc: 0.6563 - val_loss: 1.9743 - val_acc: 0.4597\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2893 - acc: 0.6752 - val_loss: 1.9424 - val_acc: 0.4758\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2901 - acc: 0.6671 - val_loss: 1.9543 - val_acc: 0.4677\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2885 - acc: 0.6550 - val_loss: 1.9478 - val_acc: 0.4879\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2736 - acc: 0.6631 - val_loss: 1.9960 - val_acc: 0.4395\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2742 - acc: 0.6496 - val_loss: 1.9385 - val_acc: 0.4476\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2695 - acc: 0.6658 - val_loss: 1.8675 - val_acc: 0.4597\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2859 - acc: 0.6361 - val_loss: 1.8975 - val_acc: 0.4798\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2722 - acc: 0.6550 - val_loss: 1.9132 - val_acc: 0.4718\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2694 - acc: 0.6604 - val_loss: 1.9536 - val_acc: 0.4315\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2818 - acc: 0.6496 - val_loss: 1.9169 - val_acc: 0.5000\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.2635 - acc: 0.6765 - val_loss: 1.9048 - val_acc: 0.5040\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2388 - acc: 0.6752 - val_loss: 1.8148 - val_acc: 0.5121\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2544 - acc: 0.6577 - val_loss: 1.9433 - val_acc: 0.4637\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2508 - acc: 0.6658 - val_loss: 1.8882 - val_acc: 0.4556\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2447 - acc: 0.6604 - val_loss: 1.8654 - val_acc: 0.4879\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2273 - acc: 0.6792 - val_loss: 1.9167 - val_acc: 0.4758\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2161 - acc: 0.6954 - val_loss: 1.9057 - val_acc: 0.4879\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2298 - acc: 0.6671 - val_loss: 1.9677 - val_acc: 0.4556\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2391 - acc: 0.6671 - val_loss: 1.8891 - val_acc: 0.5081\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2275 - acc: 0.6833 - val_loss: 1.8780 - val_acc: 0.4879\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2313 - acc: 0.6698 - val_loss: 1.8692 - val_acc: 0.5161\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2089 - acc: 0.6779 - val_loss: 1.8646 - val_acc: 0.5202\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2278 - acc: 0.6685 - val_loss: 1.8586 - val_acc: 0.5202\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2129 - acc: 0.6927 - val_loss: 1.8186 - val_acc: 0.5242\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.1932 - acc: 0.6941 - val_loss: 1.9491 - val_acc: 0.4718\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.2185 - acc: 0.6671 - val_loss: 1.9047 - val_acc: 0.4798\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1918 - acc: 0.6685 - val_loss: 1.8220 - val_acc: 0.4960\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2020 - acc: 0.6739 - val_loss: 1.8556 - val_acc: 0.5121\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2159 - acc: 0.6752 - val_loss: 1.8818 - val_acc: 0.4798\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1919 - acc: 0.6941 - val_loss: 1.9220 - val_acc: 0.4315\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.1760 - acc: 0.6806 - val_loss: 1.9204 - val_acc: 0.4516\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.2035 - acc: 0.6658 - val_loss: 1.8530 - val_acc: 0.4677\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.1763 - acc: 0.6860 - val_loss: 1.8808 - val_acc: 0.5000\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1745 - acc: 0.6968 - val_loss: 1.8401 - val_acc: 0.4839\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.1801 - acc: 0.6941 - val_loss: 1.7930 - val_acc: 0.5040\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1574 - acc: 0.6995 - val_loss: 1.8514 - val_acc: 0.4919\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1812 - acc: 0.6900 - val_loss: 1.7966 - val_acc: 0.4879\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1674 - acc: 0.6900 - val_loss: 1.8632 - val_acc: 0.4677\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.1616 - acc: 0.6873 - val_loss: 1.8121 - val_acc: 0.4879\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.1601 - acc: 0.6914 - val_loss: 1.7794 - val_acc: 0.5161\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1589 - acc: 0.6954 - val_loss: 1.7676 - val_acc: 0.5444\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1401 - acc: 0.7102 - val_loss: 1.8146 - val_acc: 0.4879\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.1502 - acc: 0.7049 - val_loss: 1.8853 - val_acc: 0.4919\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1315 - acc: 0.7089 - val_loss: 1.8663 - val_acc: 0.4879\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.1376 - acc: 0.7075 - val_loss: 1.8649 - val_acc: 0.5040\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.1353 - acc: 0.7022 - val_loss: 1.8075 - val_acc: 0.5161\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1412 - acc: 0.7049 - val_loss: 1.8152 - val_acc: 0.5242\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.1516 - acc: 0.6927 - val_loss: 1.8242 - val_acc: 0.5040\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1367 - acc: 0.7035 - val_loss: 1.8258 - val_acc: 0.5121\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.1227 - acc: 0.7075 - val_loss: 1.7705 - val_acc: 0.5161\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.1280 - acc: 0.6846 - val_loss: 1.8039 - val_acc: 0.5040\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1231 - acc: 0.6995 - val_loss: 1.7324 - val_acc: 0.5161\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.1179 - acc: 0.7075 - val_loss: 1.8293 - val_acc: 0.5081\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.1236 - acc: 0.7062 - val_loss: 1.8431 - val_acc: 0.4960\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.1154 - acc: 0.7116 - val_loss: 1.7655 - val_acc: 0.5323\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.1105 - acc: 0.7022 - val_loss: 1.7897 - val_acc: 0.5202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.1119 - acc: 0.7183 - val_loss: 1.7737 - val_acc: 0.5040\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0764 - acc: 0.7197 - val_loss: 1.7805 - val_acc: 0.5000\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.1249 - acc: 0.7075 - val_loss: 1.7948 - val_acc: 0.5121\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.1035 - acc: 0.7129 - val_loss: 1.7301 - val_acc: 0.5242\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.0866 - acc: 0.7143 - val_loss: 1.7054 - val_acc: 0.5323\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.0942 - acc: 0.7143 - val_loss: 1.7501 - val_acc: 0.5121\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.0798 - acc: 0.7049 - val_loss: 1.8149 - val_acc: 0.5161\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0762 - acc: 0.7102 - val_loss: 1.8226 - val_acc: 0.5323\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.0654 - acc: 0.7237 - val_loss: 1.8152 - val_acc: 0.4960\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0934 - acc: 0.7102 - val_loss: 1.7133 - val_acc: 0.5323\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0640 - acc: 0.7264 - val_loss: 1.7712 - val_acc: 0.5202\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0650 - acc: 0.7251 - val_loss: 1.7818 - val_acc: 0.5202\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0757 - acc: 0.7278 - val_loss: 1.6978 - val_acc: 0.5363\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0549 - acc: 0.7291 - val_loss: 1.7942 - val_acc: 0.4960\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.0572 - acc: 0.7358 - val_loss: 1.8089 - val_acc: 0.4919\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0664 - acc: 0.7264 - val_loss: 1.7166 - val_acc: 0.4919\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0753 - acc: 0.7062 - val_loss: 1.6995 - val_acc: 0.5363\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.0462 - acc: 0.7385 - val_loss: 1.7294 - val_acc: 0.5645\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.0426 - acc: 0.7264 - val_loss: 1.8019 - val_acc: 0.5000\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.0354 - acc: 0.7237 - val_loss: 1.7698 - val_acc: 0.5000\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0560 - acc: 0.7170 - val_loss: 1.6823 - val_acc: 0.5685\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0351 - acc: 0.7291 - val_loss: 1.7069 - val_acc: 0.5565\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.0404 - acc: 0.7278 - val_loss: 1.6563 - val_acc: 0.5403\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.0412 - acc: 0.7345 - val_loss: 1.7636 - val_acc: 0.5040\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.0394 - acc: 0.7345 - val_loss: 1.7482 - val_acc: 0.5282\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.0211 - acc: 0.7237 - val_loss: 1.6931 - val_acc: 0.5403\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0293 - acc: 0.7318 - val_loss: 1.6794 - val_acc: 0.5282\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 1.0342 - acc: 0.7264 - val_loss: 1.7824 - val_acc: 0.5323\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.0239 - acc: 0.7305 - val_loss: 1.7027 - val_acc: 0.5242\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0200 - acc: 0.7197 - val_loss: 1.6865 - val_acc: 0.5323\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.9976 - acc: 0.7453 - val_loss: 1.6468 - val_acc: 0.5524\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.0129 - acc: 0.7345 - val_loss: 1.6409 - val_acc: 0.5766\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0147 - acc: 0.7480 - val_loss: 1.7868 - val_acc: 0.4919\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.0186 - acc: 0.7197 - val_loss: 1.6889 - val_acc: 0.5282\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.9980 - acc: 0.7412 - val_loss: 1.6916 - val_acc: 0.5202\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.9841 - acc: 0.7439 - val_loss: 1.6852 - val_acc: 0.5121\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9897 - acc: 0.7224 - val_loss: 1.7142 - val_acc: 0.5242\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9898 - acc: 0.7251 - val_loss: 1.6641 - val_acc: 0.5484\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9872 - acc: 0.7439 - val_loss: 1.7158 - val_acc: 0.5161\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9891 - acc: 0.7561 - val_loss: 1.7026 - val_acc: 0.4919\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.9773 - acc: 0.7507 - val_loss: 1.6749 - val_acc: 0.5363\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.9900 - acc: 0.7385 - val_loss: 1.6548 - val_acc: 0.5887\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9751 - acc: 0.7507 - val_loss: 1.6133 - val_acc: 0.5403\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.9955 - acc: 0.7291 - val_loss: 1.6896 - val_acc: 0.5242\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9744 - acc: 0.7588 - val_loss: 1.6351 - val_acc: 0.5524\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.9851 - acc: 0.7305 - val_loss: 1.6726 - val_acc: 0.5645\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.9711 - acc: 0.7534 - val_loss: 1.6321 - val_acc: 0.5121\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.9606 - acc: 0.7412 - val_loss: 1.6199 - val_acc: 0.5685\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9418 - acc: 0.7642 - val_loss: 1.6661 - val_acc: 0.5282\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.9594 - acc: 0.7493 - val_loss: 1.6691 - val_acc: 0.5323\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.9678 - acc: 0.7480 - val_loss: 1.6047 - val_acc: 0.5605\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9417 - acc: 0.7534 - val_loss: 1.6304 - val_acc: 0.5685\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9567 - acc: 0.7601 - val_loss: 1.6686 - val_acc: 0.5282\n",
      "Epoch 474/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.9497 - acc: 0.7534 - val_loss: 1.5798 - val_acc: 0.5685\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.9267 - acc: 0.7520 - val_loss: 1.6440 - val_acc: 0.5323\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9410 - acc: 0.7372 - val_loss: 1.6960 - val_acc: 0.5363\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.9442 - acc: 0.7480 - val_loss: 1.6728 - val_acc: 0.5323\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.9351 - acc: 0.7520 - val_loss: 1.6420 - val_acc: 0.5484\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.9111 - acc: 0.7547 - val_loss: 1.5793 - val_acc: 0.5847\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9395 - acc: 0.7601 - val_loss: 1.6792 - val_acc: 0.5282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9227 - acc: 0.7574 - val_loss: 1.6034 - val_acc: 0.5968\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.9262 - acc: 0.7588 - val_loss: 1.6734 - val_acc: 0.5202\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.9394 - acc: 0.7507 - val_loss: 1.6139 - val_acc: 0.6008\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9162 - acc: 0.7749 - val_loss: 1.5317 - val_acc: 0.5685\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.9000 - acc: 0.7803 - val_loss: 1.6174 - val_acc: 0.5363\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.9261 - acc: 0.7480 - val_loss: 1.6036 - val_acc: 0.5645\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.9071 - acc: 0.7601 - val_loss: 1.6308 - val_acc: 0.5121\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.9174 - acc: 0.7399 - val_loss: 1.6296 - val_acc: 0.5524\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.9041 - acc: 0.7695 - val_loss: 1.6189 - val_acc: 0.5565\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.9028 - acc: 0.7682 - val_loss: 1.6151 - val_acc: 0.5766\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8972 - acc: 0.7574 - val_loss: 1.5376 - val_acc: 0.5444\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.8871 - acc: 0.7722 - val_loss: 1.6007 - val_acc: 0.5161\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8938 - acc: 0.7601 - val_loss: 1.5322 - val_acc: 0.6129\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8831 - acc: 0.7722 - val_loss: 1.5530 - val_acc: 0.5565\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8961 - acc: 0.7790 - val_loss: 1.6130 - val_acc: 0.5524\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.8877 - acc: 0.7668 - val_loss: 1.6030 - val_acc: 0.5645\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.8766 - acc: 0.7682 - val_loss: 1.5662 - val_acc: 0.5766\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8870 - acc: 0.7709 - val_loss: 1.5338 - val_acc: 0.5565\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.8950 - acc: 0.7534 - val_loss: 1.6160 - val_acc: 0.5524\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.8732 - acc: 0.7790 - val_loss: 1.5523 - val_acc: 0.5847\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.8697 - acc: 0.7682 - val_loss: 1.5980 - val_acc: 0.5323\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8712 - acc: 0.7628 - val_loss: 1.5752 - val_acc: 0.5444\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.8694 - acc: 0.7642 - val_loss: 1.5846 - val_acc: 0.5766\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8478 - acc: 0.7911 - val_loss: 1.5698 - val_acc: 0.5605\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8671 - acc: 0.7722 - val_loss: 1.6106 - val_acc: 0.5323\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8575 - acc: 0.7790 - val_loss: 1.6503 - val_acc: 0.5363\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8527 - acc: 0.7951 - val_loss: 1.5440 - val_acc: 0.5403\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8439 - acc: 0.7925 - val_loss: 1.5877 - val_acc: 0.5685\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.8491 - acc: 0.7736 - val_loss: 1.5476 - val_acc: 0.5645\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.8599 - acc: 0.7884 - val_loss: 1.5770 - val_acc: 0.5766\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.8432 - acc: 0.7588 - val_loss: 1.5996 - val_acc: 0.5645\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8541 - acc: 0.7817 - val_loss: 1.5054 - val_acc: 0.6008\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.8365 - acc: 0.7776 - val_loss: 1.5604 - val_acc: 0.5847\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.8550 - acc: 0.7844 - val_loss: 1.5707 - val_acc: 0.5685\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8296 - acc: 0.7749 - val_loss: 1.5467 - val_acc: 0.5847\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8330 - acc: 0.7925 - val_loss: 1.5447 - val_acc: 0.5887\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8446 - acc: 0.7749 - val_loss: 1.5806 - val_acc: 0.5806\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.8262 - acc: 0.7830 - val_loss: 1.5914 - val_acc: 0.5726\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8337 - acc: 0.7817 - val_loss: 1.4913 - val_acc: 0.5887\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8249 - acc: 0.7776 - val_loss: 1.5997 - val_acc: 0.5484\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8015 - acc: 0.7992 - val_loss: 1.5598 - val_acc: 0.5605\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.8327 - acc: 0.7844 - val_loss: 1.5676 - val_acc: 0.5847\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7889 - acc: 0.8059 - val_loss: 1.5079 - val_acc: 0.5847\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8169 - acc: 0.7817 - val_loss: 1.5257 - val_acc: 0.5605\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7959 - acc: 0.7965 - val_loss: 1.4934 - val_acc: 0.6089\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.7872 - acc: 0.7992 - val_loss: 1.4936 - val_acc: 0.5766\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.8077 - acc: 0.7857 - val_loss: 1.5007 - val_acc: 0.6129\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.8014 - acc: 0.7978 - val_loss: 1.4858 - val_acc: 0.6210\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.8164 - acc: 0.7830 - val_loss: 1.5027 - val_acc: 0.5806\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7784 - acc: 0.8005 - val_loss: 1.5265 - val_acc: 0.5847\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7839 - acc: 0.7803 - val_loss: 1.5540 - val_acc: 0.5766\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7956 - acc: 0.7830 - val_loss: 1.4890 - val_acc: 0.5806\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.7829 - acc: 0.8059 - val_loss: 1.5358 - val_acc: 0.5645\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7929 - acc: 0.8059 - val_loss: 1.5480 - val_acc: 0.5968\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7999 - acc: 0.8032 - val_loss: 1.4930 - val_acc: 0.6129\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7898 - acc: 0.7938 - val_loss: 1.5317 - val_acc: 0.5887\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7867 - acc: 0.7978 - val_loss: 1.5475 - val_acc: 0.6089\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.7968 - acc: 0.7857 - val_loss: 1.4869 - val_acc: 0.6048\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.7768 - acc: 0.7938 - val_loss: 1.4433 - val_acc: 0.5927\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7677 - acc: 0.8073 - val_loss: 1.5288 - val_acc: 0.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7691 - acc: 0.8059 - val_loss: 1.4541 - val_acc: 0.6371\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 0.7704 - acc: 0.8005 - val_loss: 1.5526 - val_acc: 0.5847\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7506 - acc: 0.8059 - val_loss: 1.5028 - val_acc: 0.6008\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7622 - acc: 0.8086 - val_loss: 1.4565 - val_acc: 0.5806\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7644 - acc: 0.8086 - val_loss: 1.4898 - val_acc: 0.5766\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.7500 - acc: 0.7992 - val_loss: 1.4641 - val_acc: 0.5645\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7416 - acc: 0.8208 - val_loss: 1.4874 - val_acc: 0.5927\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7665 - acc: 0.8059 - val_loss: 1.4179 - val_acc: 0.6008\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7501 - acc: 0.8032 - val_loss: 1.5437 - val_acc: 0.5726\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.7516 - acc: 0.7992 - val_loss: 1.4552 - val_acc: 0.6169\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7479 - acc: 0.8059 - val_loss: 1.4167 - val_acc: 0.6210\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7495 - acc: 0.8113 - val_loss: 1.4314 - val_acc: 0.6371\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7282 - acc: 0.8194 - val_loss: 1.5141 - val_acc: 0.5645\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.7453 - acc: 0.7938 - val_loss: 1.4789 - val_acc: 0.5968\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7202 - acc: 0.8342 - val_loss: 1.4696 - val_acc: 0.6048\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7390 - acc: 0.8181 - val_loss: 1.4251 - val_acc: 0.5887\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7317 - acc: 0.8221 - val_loss: 1.4116 - val_acc: 0.6089\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7401 - acc: 0.8059 - val_loss: 1.4985 - val_acc: 0.5847\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7303 - acc: 0.8113 - val_loss: 1.4675 - val_acc: 0.5887\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7140 - acc: 0.8275 - val_loss: 1.4957 - val_acc: 0.5887\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.7314 - acc: 0.8154 - val_loss: 1.4153 - val_acc: 0.6089\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.6982 - acc: 0.8302 - val_loss: 1.4300 - val_acc: 0.6250\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7148 - acc: 0.8113 - val_loss: 1.4473 - val_acc: 0.5685\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7138 - acc: 0.8059 - val_loss: 1.4622 - val_acc: 0.6250\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7162 - acc: 0.8248 - val_loss: 1.3885 - val_acc: 0.6250\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.7031 - acc: 0.8356 - val_loss: 1.4543 - val_acc: 0.6008\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7108 - acc: 0.8208 - val_loss: 1.4017 - val_acc: 0.6048\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.7070 - acc: 0.8073 - val_loss: 1.4170 - val_acc: 0.6129\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.7080 - acc: 0.8288 - val_loss: 1.4881 - val_acc: 0.6169\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7019 - acc: 0.8127 - val_loss: 1.4045 - val_acc: 0.6129\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7030 - acc: 0.8140 - val_loss: 1.4537 - val_acc: 0.6048\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.6978 - acc: 0.8208 - val_loss: 1.4872 - val_acc: 0.5766\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6867 - acc: 0.8302 - val_loss: 1.4077 - val_acc: 0.6129\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.7043 - acc: 0.8127 - val_loss: 1.4386 - val_acc: 0.6331\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6881 - acc: 0.8356 - val_loss: 1.3809 - val_acc: 0.6210\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6801 - acc: 0.8288 - val_loss: 1.4511 - val_acc: 0.6048\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.7041 - acc: 0.8167 - val_loss: 1.4268 - val_acc: 0.6129\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6893 - acc: 0.8113 - val_loss: 1.3596 - val_acc: 0.6250\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6800 - acc: 0.8181 - val_loss: 1.4216 - val_acc: 0.6169\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6835 - acc: 0.8261 - val_loss: 1.3987 - val_acc: 0.6371\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6752 - acc: 0.8208 - val_loss: 1.3688 - val_acc: 0.6169\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.6722 - acc: 0.8235 - val_loss: 1.3854 - val_acc: 0.5806\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.6824 - acc: 0.8235 - val_loss: 1.3702 - val_acc: 0.6492\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.6624 - acc: 0.8342 - val_loss: 1.4203 - val_acc: 0.6250\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.6618 - acc: 0.8221 - val_loss: 1.3751 - val_acc: 0.6492\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6743 - acc: 0.8288 - val_loss: 1.3632 - val_acc: 0.6331\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6598 - acc: 0.8235 - val_loss: 1.4058 - val_acc: 0.6492\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.6660 - acc: 0.8288 - val_loss: 1.4063 - val_acc: 0.6169\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6539 - acc: 0.8315 - val_loss: 1.4207 - val_acc: 0.6089\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6638 - acc: 0.8181 - val_loss: 1.3338 - val_acc: 0.6492\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6542 - acc: 0.8383 - val_loss: 1.3978 - val_acc: 0.6290\n",
      "Epoch 592/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6419 - acc: 0.8369 - val_loss: 1.3628 - val_acc: 0.6048\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.6475 - acc: 0.8288 - val_loss: 1.3837 - val_acc: 0.6210\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.6571 - acc: 0.8181 - val_loss: 1.3450 - val_acc: 0.6452\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6348 - acc: 0.8356 - val_loss: 1.3906 - val_acc: 0.6290\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.6429 - acc: 0.8356 - val_loss: 1.3703 - val_acc: 0.6250\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.6516 - acc: 0.8329 - val_loss: 1.4370 - val_acc: 0.6129\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6233 - acc: 0.8396 - val_loss: 1.3682 - val_acc: 0.6210\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.6267 - acc: 0.8261 - val_loss: 1.3483 - val_acc: 0.6210\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.6405 - acc: 0.8396 - val_loss: 1.3999 - val_acc: 0.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6293 - acc: 0.8410 - val_loss: 1.4004 - val_acc: 0.6452\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.6355 - acc: 0.8396 - val_loss: 1.3296 - val_acc: 0.6532\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6505 - acc: 0.8100 - val_loss: 1.3908 - val_acc: 0.6290\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.6441 - acc: 0.8437 - val_loss: 1.3042 - val_acc: 0.6734\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6312 - acc: 0.8383 - val_loss: 1.3032 - val_acc: 0.6331\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6236 - acc: 0.8450 - val_loss: 1.3665 - val_acc: 0.6411\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6312 - acc: 0.8369 - val_loss: 1.3155 - val_acc: 0.6653\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.6006 - acc: 0.8477 - val_loss: 1.3482 - val_acc: 0.6210\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.6159 - acc: 0.8329 - val_loss: 1.3817 - val_acc: 0.6210\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.6179 - acc: 0.8288 - val_loss: 1.4723 - val_acc: 0.6048\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.6181 - acc: 0.8369 - val_loss: 1.3137 - val_acc: 0.6492\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.6064 - acc: 0.8383 - val_loss: 1.4253 - val_acc: 0.6169\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.6232 - acc: 0.8248 - val_loss: 1.3115 - val_acc: 0.6492\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.6058 - acc: 0.8504 - val_loss: 1.3194 - val_acc: 0.6653\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6017 - acc: 0.8518 - val_loss: 1.3003 - val_acc: 0.6169\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.5941 - acc: 0.8504 - val_loss: 1.3375 - val_acc: 0.6492\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.6107 - acc: 0.8356 - val_loss: 1.3197 - val_acc: 0.6492\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6060 - acc: 0.8396 - val_loss: 1.3195 - val_acc: 0.6573\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.6117 - acc: 0.8423 - val_loss: 1.3490 - val_acc: 0.6411\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.6012 - acc: 0.8315 - val_loss: 1.3610 - val_acc: 0.6129\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5902 - acc: 0.8423 - val_loss: 1.3824 - val_acc: 0.6411\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5892 - acc: 0.8598 - val_loss: 1.3575 - val_acc: 0.6492\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5930 - acc: 0.8544 - val_loss: 1.3445 - val_acc: 0.6492\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.5922 - acc: 0.8491 - val_loss: 1.3701 - val_acc: 0.6210\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5888 - acc: 0.8491 - val_loss: 1.2803 - val_acc: 0.6774\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5926 - acc: 0.8410 - val_loss: 1.3784 - val_acc: 0.6169\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5951 - acc: 0.8423 - val_loss: 1.3546 - val_acc: 0.6371\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5898 - acc: 0.8585 - val_loss: 1.3246 - val_acc: 0.6573\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5747 - acc: 0.8585 - val_loss: 1.2953 - val_acc: 0.6653\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5880 - acc: 0.8437 - val_loss: 1.3273 - val_acc: 0.6452\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5778 - acc: 0.8396 - val_loss: 1.3158 - val_acc: 0.6411\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5704 - acc: 0.8544 - val_loss: 1.3584 - val_acc: 0.6290\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5702 - acc: 0.8585 - val_loss: 1.3276 - val_acc: 0.6210\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5934 - acc: 0.8302 - val_loss: 1.3361 - val_acc: 0.6371\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.5690 - acc: 0.8450 - val_loss: 1.2936 - val_acc: 0.6331\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5562 - acc: 0.8518 - val_loss: 1.2532 - val_acc: 0.6694\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.5647 - acc: 0.8585 - val_loss: 1.3051 - val_acc: 0.6331\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.5527 - acc: 0.8558 - val_loss: 1.2873 - val_acc: 0.6653\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5747 - acc: 0.8544 - val_loss: 1.3870 - val_acc: 0.6452\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5571 - acc: 0.8531 - val_loss: 1.2712 - val_acc: 0.6411\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5469 - acc: 0.8625 - val_loss: 1.3832 - val_acc: 0.6331\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5637 - acc: 0.8437 - val_loss: 1.3180 - val_acc: 0.6290\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.5589 - acc: 0.8571 - val_loss: 1.2506 - val_acc: 0.6895\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5581 - acc: 0.8612 - val_loss: 1.3279 - val_acc: 0.6331\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5449 - acc: 0.8652 - val_loss: 1.3247 - val_acc: 0.6452\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5578 - acc: 0.8598 - val_loss: 1.2640 - val_acc: 0.6532\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5508 - acc: 0.8639 - val_loss: 1.3184 - val_acc: 0.6371\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5434 - acc: 0.8612 - val_loss: 1.2946 - val_acc: 0.6210\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5436 - acc: 0.8652 - val_loss: 1.3382 - val_acc: 0.6411\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5483 - acc: 0.8450 - val_loss: 1.3285 - val_acc: 0.6694\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5431 - acc: 0.8625 - val_loss: 1.2765 - val_acc: 0.6774\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.5558 - acc: 0.8477 - val_loss: 1.2808 - val_acc: 0.6371\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5351 - acc: 0.8720 - val_loss: 1.2176 - val_acc: 0.6895\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.5313 - acc: 0.8639 - val_loss: 1.3304 - val_acc: 0.6371\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5380 - acc: 0.8544 - val_loss: 1.3461 - val_acc: 0.6290\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.5234 - acc: 0.8679 - val_loss: 1.2979 - val_acc: 0.6492\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5412 - acc: 0.8598 - val_loss: 1.2805 - val_acc: 0.6653\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5243 - acc: 0.8598 - val_loss: 1.2643 - val_acc: 0.6492\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5193 - acc: 0.8612 - val_loss: 1.2608 - val_acc: 0.6532\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.5207 - acc: 0.8679 - val_loss: 1.3607 - val_acc: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5097 - acc: 0.8787 - val_loss: 1.3034 - val_acc: 0.6411\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5241 - acc: 0.8585 - val_loss: 1.3109 - val_acc: 0.6573\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.5435 - acc: 0.8491 - val_loss: 1.2977 - val_acc: 0.6532\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5365 - acc: 0.8585 - val_loss: 1.2564 - val_acc: 0.6774\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.5069 - acc: 0.8760 - val_loss: 1.2779 - val_acc: 0.6371\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5145 - acc: 0.8666 - val_loss: 1.3077 - val_acc: 0.6694\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.5208 - acc: 0.8625 - val_loss: 1.2925 - val_acc: 0.6774\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5076 - acc: 0.8760 - val_loss: 1.2288 - val_acc: 0.6815\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.5088 - acc: 0.8639 - val_loss: 1.2930 - val_acc: 0.6331\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.5008 - acc: 0.8814 - val_loss: 1.2466 - val_acc: 0.6573\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 0.5010 - acc: 0.8760 - val_loss: 1.3315 - val_acc: 0.6250\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.5081 - acc: 0.8679 - val_loss: 1.3462 - val_acc: 0.6250\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.5035 - acc: 0.8679 - val_loss: 1.2434 - val_acc: 0.6573\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.5006 - acc: 0.8679 - val_loss: 1.2507 - val_acc: 0.6532\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.5011 - acc: 0.8679 - val_loss: 1.2641 - val_acc: 0.6371\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.5050 - acc: 0.8733 - val_loss: 1.2600 - val_acc: 0.6774\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4962 - acc: 0.8774 - val_loss: 1.2504 - val_acc: 0.6613\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.5164 - acc: 0.8733 - val_loss: 1.2645 - val_acc: 0.6492\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4831 - acc: 0.8720 - val_loss: 1.2028 - val_acc: 0.7016\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4980 - acc: 0.8720 - val_loss: 1.2904 - val_acc: 0.6694\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4911 - acc: 0.8720 - val_loss: 1.2827 - val_acc: 0.6573\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4902 - acc: 0.8868 - val_loss: 1.2635 - val_acc: 0.6774\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4989 - acc: 0.8706 - val_loss: 1.3090 - val_acc: 0.6532\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4900 - acc: 0.8787 - val_loss: 1.3391 - val_acc: 0.6452\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4703 - acc: 0.8787 - val_loss: 1.2652 - val_acc: 0.6532\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4785 - acc: 0.8881 - val_loss: 1.2581 - val_acc: 0.6694\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4768 - acc: 0.8827 - val_loss: 1.2636 - val_acc: 0.6532\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4718 - acc: 0.8895 - val_loss: 1.2354 - val_acc: 0.6532\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4805 - acc: 0.8774 - val_loss: 1.1899 - val_acc: 0.6935\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4920 - acc: 0.8585 - val_loss: 1.2227 - val_acc: 0.6613\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.4720 - acc: 0.8787 - val_loss: 1.2734 - val_acc: 0.6573\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4702 - acc: 0.8908 - val_loss: 1.3392 - val_acc: 0.6411\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4773 - acc: 0.8733 - val_loss: 1.2440 - val_acc: 0.6815\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.4790 - acc: 0.8922 - val_loss: 1.2341 - val_acc: 0.6734\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4737 - acc: 0.8801 - val_loss: 1.2131 - val_acc: 0.6694\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.4665 - acc: 0.8814 - val_loss: 1.2087 - val_acc: 0.6976\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4664 - acc: 0.8801 - val_loss: 1.2494 - val_acc: 0.6613\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4573 - acc: 0.8720 - val_loss: 1.1771 - val_acc: 0.6895\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4568 - acc: 0.8854 - val_loss: 1.3276 - val_acc: 0.6210\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4635 - acc: 0.8787 - val_loss: 1.2301 - val_acc: 0.6694\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4562 - acc: 0.8895 - val_loss: 1.2516 - val_acc: 0.6573\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4550 - acc: 0.8801 - val_loss: 1.3075 - val_acc: 0.6290\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4685 - acc: 0.8760 - val_loss: 1.3017 - val_acc: 0.6290\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4600 - acc: 0.8868 - val_loss: 1.2058 - val_acc: 0.6532\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4625 - acc: 0.8949 - val_loss: 1.2862 - val_acc: 0.6452\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4476 - acc: 0.8841 - val_loss: 1.2103 - val_acc: 0.6935\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4534 - acc: 0.8868 - val_loss: 1.2312 - val_acc: 0.6653\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.4371 - acc: 0.9030 - val_loss: 1.2959 - val_acc: 0.6532\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4494 - acc: 0.8801 - val_loss: 1.2756 - val_acc: 0.6734\n",
      "Epoch 710/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.4312 - acc: 0.8949 - val_loss: 1.1821 - val_acc: 0.6976\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4434 - acc: 0.8881 - val_loss: 1.2756 - val_acc: 0.6573\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4541 - acc: 0.8801 - val_loss: 1.1614 - val_acc: 0.7177\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4544 - acc: 0.8760 - val_loss: 1.2544 - val_acc: 0.6492\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4371 - acc: 0.8881 - val_loss: 1.1925 - val_acc: 0.6694\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4237 - acc: 0.8922 - val_loss: 1.2200 - val_acc: 0.6573\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4393 - acc: 0.8868 - val_loss: 1.2482 - val_acc: 0.6855\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.4389 - acc: 0.8827 - val_loss: 1.1767 - val_acc: 0.6855\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4467 - acc: 0.8854 - val_loss: 1.2246 - val_acc: 0.6613\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4158 - acc: 0.9070 - val_loss: 1.2344 - val_acc: 0.6694\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.4185 - acc: 0.8949 - val_loss: 1.2675 - val_acc: 0.6371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4419 - acc: 0.8976 - val_loss: 1.2211 - val_acc: 0.6694\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.4234 - acc: 0.8962 - val_loss: 1.1471 - val_acc: 0.6734\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4301 - acc: 0.8962 - val_loss: 1.2412 - val_acc: 0.6694\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4264 - acc: 0.8827 - val_loss: 1.2452 - val_acc: 0.6774\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4380 - acc: 0.8841 - val_loss: 1.2183 - val_acc: 0.6734\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4249 - acc: 0.8922 - val_loss: 1.1528 - val_acc: 0.7097\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4224 - acc: 0.8895 - val_loss: 1.2420 - val_acc: 0.6734\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4137 - acc: 0.9151 - val_loss: 1.2492 - val_acc: 0.6815\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.4147 - acc: 0.9003 - val_loss: 1.2685 - val_acc: 0.6452\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4038 - acc: 0.8976 - val_loss: 1.1597 - val_acc: 0.7137\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.4134 - acc: 0.9003 - val_loss: 1.2091 - val_acc: 0.6935\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4192 - acc: 0.9016 - val_loss: 1.2521 - val_acc: 0.6532\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4182 - acc: 0.8881 - val_loss: 1.2283 - val_acc: 0.6492\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.4057 - acc: 0.9030 - val_loss: 1.1841 - val_acc: 0.7056\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.4114 - acc: 0.8976 - val_loss: 1.1995 - val_acc: 0.6774\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4203 - acc: 0.8949 - val_loss: 1.1956 - val_acc: 0.6815\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3853 - acc: 0.9191 - val_loss: 1.2613 - val_acc: 0.6452\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4032 - acc: 0.9030 - val_loss: 1.1957 - val_acc: 0.7056\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3995 - acc: 0.9016 - val_loss: 1.2653 - val_acc: 0.6855\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.4292 - acc: 0.8841 - val_loss: 1.2317 - val_acc: 0.6855\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3983 - acc: 0.9016 - val_loss: 1.2518 - val_acc: 0.6895\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3954 - acc: 0.8922 - val_loss: 1.2347 - val_acc: 0.6976\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3945 - acc: 0.9057 - val_loss: 1.2422 - val_acc: 0.6855\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3967 - acc: 0.9084 - val_loss: 1.2276 - val_acc: 0.6815\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3895 - acc: 0.9151 - val_loss: 1.2493 - val_acc: 0.6613\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.4059 - acc: 0.9043 - val_loss: 1.1693 - val_acc: 0.6815\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3922 - acc: 0.9003 - val_loss: 1.1588 - val_acc: 0.7218\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3816 - acc: 0.9043 - val_loss: 1.1778 - val_acc: 0.7137\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.4000 - acc: 0.8989 - val_loss: 1.1966 - val_acc: 0.7016\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3782 - acc: 0.9111 - val_loss: 1.2227 - val_acc: 0.6815\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3853 - acc: 0.9097 - val_loss: 1.1964 - val_acc: 0.6976\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3910 - acc: 0.9003 - val_loss: 1.2186 - val_acc: 0.6815\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3866 - acc: 0.9016 - val_loss: 1.2062 - val_acc: 0.6815\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3862 - acc: 0.9057 - val_loss: 1.2205 - val_acc: 0.6935\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3862 - acc: 0.9111 - val_loss: 1.2200 - val_acc: 0.6774\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.3889 - acc: 0.9030 - val_loss: 1.1396 - val_acc: 0.7177\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.3716 - acc: 0.9137 - val_loss: 1.2192 - val_acc: 0.6492\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3722 - acc: 0.9137 - val_loss: 1.1761 - val_acc: 0.6734\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.4086 - acc: 0.8827 - val_loss: 1.1780 - val_acc: 0.6976\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.3628 - acc: 0.9164 - val_loss: 1.1965 - val_acc: 0.6694\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3839 - acc: 0.9097 - val_loss: 1.1307 - val_acc: 0.6774\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.3800 - acc: 0.8989 - val_loss: 1.2138 - val_acc: 0.6774\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3727 - acc: 0.9111 - val_loss: 1.2514 - val_acc: 0.6411\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3597 - acc: 0.9205 - val_loss: 1.1926 - val_acc: 0.6653\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.3829 - acc: 0.9030 - val_loss: 1.1310 - val_acc: 0.7016\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3741 - acc: 0.9030 - val_loss: 1.2252 - val_acc: 0.6774\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3806 - acc: 0.9124 - val_loss: 1.1588 - val_acc: 0.7298\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.3650 - acc: 0.9218 - val_loss: 1.2674 - val_acc: 0.6492\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3981 - acc: 0.8908 - val_loss: 1.1793 - val_acc: 0.7137\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3545 - acc: 0.9164 - val_loss: 1.1264 - val_acc: 0.7016\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3473 - acc: 0.9245 - val_loss: 1.1790 - val_acc: 0.6774\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.3557 - acc: 0.9272 - val_loss: 1.1457 - val_acc: 0.7258\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3452 - acc: 0.9259 - val_loss: 1.2558 - val_acc: 0.6492\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.3663 - acc: 0.9097 - val_loss: 1.2716 - val_acc: 0.6613\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3576 - acc: 0.9178 - val_loss: 1.2600 - val_acc: 0.6573\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3825 - acc: 0.8935 - val_loss: 1.2151 - val_acc: 0.6653\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 0.3448 - acc: 0.9097 - val_loss: 1.1237 - val_acc: 0.7137\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3534 - acc: 0.9151 - val_loss: 1.1411 - val_acc: 0.7258\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3543 - acc: 0.9151 - val_loss: 1.1779 - val_acc: 0.6976\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.3742 - acc: 0.9057 - val_loss: 1.2410 - val_acc: 0.6815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3544 - acc: 0.9178 - val_loss: 1.2022 - val_acc: 0.6532\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.3488 - acc: 0.9151 - val_loss: 1.2461 - val_acc: 0.6573\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.3485 - acc: 0.9205 - val_loss: 1.1969 - val_acc: 0.7016\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3456 - acc: 0.9205 - val_loss: 1.1700 - val_acc: 0.6694\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3466 - acc: 0.9218 - val_loss: 1.1948 - val_acc: 0.6653\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3569 - acc: 0.9124 - val_loss: 1.2423 - val_acc: 0.6653\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3428 - acc: 0.9218 - val_loss: 1.2136 - val_acc: 0.6855\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3433 - acc: 0.9151 - val_loss: 1.1733 - val_acc: 0.7016\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3487 - acc: 0.9137 - val_loss: 1.1279 - val_acc: 0.6976\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3410 - acc: 0.9111 - val_loss: 1.1643 - val_acc: 0.6653\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3383 - acc: 0.9178 - val_loss: 1.1397 - val_acc: 0.6976\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3450 - acc: 0.9191 - val_loss: 1.2440 - val_acc: 0.6815\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3492 - acc: 0.9124 - val_loss: 1.1929 - val_acc: 0.6815\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3368 - acc: 0.9218 - val_loss: 1.1708 - val_acc: 0.6935\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3359 - acc: 0.9084 - val_loss: 1.1730 - val_acc: 0.6935\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3307 - acc: 0.9151 - val_loss: 1.1098 - val_acc: 0.6935\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3358 - acc: 0.9259 - val_loss: 1.1575 - val_acc: 0.7056\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3194 - acc: 0.9232 - val_loss: 1.1644 - val_acc: 0.6815\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3411 - acc: 0.9178 - val_loss: 1.1390 - val_acc: 0.6895\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3402 - acc: 0.9191 - val_loss: 1.1405 - val_acc: 0.6855\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3291 - acc: 0.9178 - val_loss: 1.1936 - val_acc: 0.6895\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3476 - acc: 0.9097 - val_loss: 1.1556 - val_acc: 0.7177\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.3198 - acc: 0.9232 - val_loss: 1.1384 - val_acc: 0.6935\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3168 - acc: 0.9259 - val_loss: 1.2204 - val_acc: 0.6694\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.3082 - acc: 0.9326 - val_loss: 1.1613 - val_acc: 0.7016\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.3132 - acc: 0.9286 - val_loss: 1.1751 - val_acc: 0.7218\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3286 - acc: 0.9259 - val_loss: 1.1377 - val_acc: 0.6895\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3219 - acc: 0.9272 - val_loss: 1.1546 - val_acc: 0.6815\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3207 - acc: 0.9232 - val_loss: 1.2069 - val_acc: 0.6573\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3133 - acc: 0.9232 - val_loss: 1.1993 - val_acc: 0.6935\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3159 - acc: 0.9340 - val_loss: 1.1908 - val_acc: 0.6935\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3245 - acc: 0.9191 - val_loss: 1.1880 - val_acc: 0.6895\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3236 - acc: 0.9259 - val_loss: 1.1268 - val_acc: 0.6935\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3183 - acc: 0.9205 - val_loss: 1.1502 - val_acc: 0.7177\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.3022 - acc: 0.9353 - val_loss: 1.1543 - val_acc: 0.7218\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.3068 - acc: 0.9326 - val_loss: 1.1616 - val_acc: 0.6895\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3152 - acc: 0.9313 - val_loss: 1.1000 - val_acc: 0.7137\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3066 - acc: 0.9272 - val_loss: 1.1490 - val_acc: 0.6935\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3034 - acc: 0.9259 - val_loss: 1.2337 - val_acc: 0.6774\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.3241 - acc: 0.9218 - val_loss: 1.1421 - val_acc: 0.6694\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3012 - acc: 0.9272 - val_loss: 1.1411 - val_acc: 0.7016\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.3087 - acc: 0.9164 - val_loss: 1.1789 - val_acc: 0.6734\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.2943 - acc: 0.9367 - val_loss: 1.1971 - val_acc: 0.6855\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3071 - acc: 0.9340 - val_loss: 1.1843 - val_acc: 0.6855\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.3063 - acc: 0.9272 - val_loss: 1.2046 - val_acc: 0.6855\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2949 - acc: 0.9326 - val_loss: 1.1284 - val_acc: 0.7097\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.3027 - acc: 0.9299 - val_loss: 1.1692 - val_acc: 0.6774\n",
      "Epoch 828/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.3098 - acc: 0.9232 - val_loss: 1.1189 - val_acc: 0.7056\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3039 - acc: 0.9299 - val_loss: 1.0693 - val_acc: 0.7298\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2913 - acc: 0.9326 - val_loss: 1.1990 - val_acc: 0.7137\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2933 - acc: 0.9340 - val_loss: 1.1295 - val_acc: 0.7177\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2893 - acc: 0.9340 - val_loss: 1.1021 - val_acc: 0.7016\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2959 - acc: 0.9380 - val_loss: 1.1603 - val_acc: 0.6895\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2946 - acc: 0.9313 - val_loss: 1.1347 - val_acc: 0.7056\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2925 - acc: 0.9272 - val_loss: 1.2052 - val_acc: 0.6935\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2929 - acc: 0.9299 - val_loss: 1.1404 - val_acc: 0.7097\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2808 - acc: 0.9394 - val_loss: 1.2596 - val_acc: 0.6815\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 0.2941 - acc: 0.9380 - val_loss: 1.1745 - val_acc: 0.6815\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.3043 - acc: 0.9313 - val_loss: 1.0825 - val_acc: 0.7298\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2751 - acc: 0.9367 - val_loss: 1.1381 - val_acc: 0.6976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2854 - acc: 0.9313 - val_loss: 1.1940 - val_acc: 0.6976\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2848 - acc: 0.9326 - val_loss: 1.1375 - val_acc: 0.6815\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2722 - acc: 0.9394 - val_loss: 1.1786 - val_acc: 0.7056\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2817 - acc: 0.9326 - val_loss: 1.0966 - val_acc: 0.7298\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2827 - acc: 0.9367 - val_loss: 1.1805 - val_acc: 0.7056\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2742 - acc: 0.9501 - val_loss: 1.1677 - val_acc: 0.6976\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2924 - acc: 0.9340 - val_loss: 1.1654 - val_acc: 0.6935\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2693 - acc: 0.9447 - val_loss: 1.1003 - val_acc: 0.7298\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2657 - acc: 0.9434 - val_loss: 1.1737 - val_acc: 0.6976\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2668 - acc: 0.9367 - val_loss: 1.1975 - val_acc: 0.6935\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2732 - acc: 0.9380 - val_loss: 1.1850 - val_acc: 0.6976\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2737 - acc: 0.9299 - val_loss: 1.1363 - val_acc: 0.7177\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2666 - acc: 0.9407 - val_loss: 1.2042 - val_acc: 0.6694\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2862 - acc: 0.9340 - val_loss: 1.1834 - val_acc: 0.6935\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2773 - acc: 0.9299 - val_loss: 1.1411 - val_acc: 0.7097\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2863 - acc: 0.9326 - val_loss: 1.1290 - val_acc: 0.7218\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2718 - acc: 0.9380 - val_loss: 1.0771 - val_acc: 0.7419\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.2463 - acc: 0.9501 - val_loss: 1.0528 - val_acc: 0.7339\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2701 - acc: 0.9394 - val_loss: 1.1165 - val_acc: 0.6815\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2694 - acc: 0.9447 - val_loss: 1.1783 - val_acc: 0.7056\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2694 - acc: 0.9299 - val_loss: 1.1619 - val_acc: 0.7097\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2714 - acc: 0.9380 - val_loss: 1.0659 - val_acc: 0.7419\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2525 - acc: 0.9488 - val_loss: 1.1524 - val_acc: 0.7177\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2712 - acc: 0.9326 - val_loss: 1.1275 - val_acc: 0.7137\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2661 - acc: 0.9515 - val_loss: 1.2095 - val_acc: 0.6774\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2631 - acc: 0.9326 - val_loss: 1.1628 - val_acc: 0.6815\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2756 - acc: 0.9380 - val_loss: 1.1558 - val_acc: 0.6976\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2544 - acc: 0.9434 - val_loss: 1.1233 - val_acc: 0.7056\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.2572 - acc: 0.9488 - val_loss: 1.1042 - val_acc: 0.7137\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2537 - acc: 0.9420 - val_loss: 1.1421 - val_acc: 0.6815\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.2665 - acc: 0.9380 - val_loss: 1.0780 - val_acc: 0.7177\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2609 - acc: 0.9380 - val_loss: 1.1699 - val_acc: 0.7097\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2513 - acc: 0.9434 - val_loss: 1.1681 - val_acc: 0.7137\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2515 - acc: 0.9555 - val_loss: 1.1417 - val_acc: 0.7258\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2468 - acc: 0.9420 - val_loss: 1.1541 - val_acc: 0.7016\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2557 - acc: 0.9407 - val_loss: 1.1396 - val_acc: 0.7016\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2414 - acc: 0.9488 - val_loss: 1.2028 - val_acc: 0.6774\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2551 - acc: 0.9394 - val_loss: 1.2490 - val_acc: 0.6613\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2489 - acc: 0.9407 - val_loss: 1.1193 - val_acc: 0.7016\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2545 - acc: 0.9367 - val_loss: 1.2015 - val_acc: 0.6895\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2506 - acc: 0.9447 - val_loss: 1.1097 - val_acc: 0.7097\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2429 - acc: 0.9488 - val_loss: 1.1412 - val_acc: 0.6855\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2521 - acc: 0.9380 - val_loss: 1.1854 - val_acc: 0.6855\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2415 - acc: 0.9528 - val_loss: 1.0990 - val_acc: 0.7218\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 0.2504 - acc: 0.9326 - val_loss: 1.2301 - val_acc: 0.6774\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 0.2606 - acc: 0.9367 - val_loss: 1.1117 - val_acc: 0.7218\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2482 - acc: 0.9420 - val_loss: 1.1383 - val_acc: 0.7177\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.2235 - acc: 0.9609 - val_loss: 1.1192 - val_acc: 0.7177\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2544 - acc: 0.9313 - val_loss: 1.0904 - val_acc: 0.7218\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.2360 - acc: 0.9394 - val_loss: 1.1132 - val_acc: 0.7379\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2363 - acc: 0.9515 - val_loss: 1.0791 - val_acc: 0.7137\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2413 - acc: 0.9434 - val_loss: 1.1585 - val_acc: 0.6855\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2328 - acc: 0.9515 - val_loss: 1.1129 - val_acc: 0.7016\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2305 - acc: 0.9542 - val_loss: 1.1140 - val_acc: 0.7137\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2307 - acc: 0.9474 - val_loss: 1.1321 - val_acc: 0.6976\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2388 - acc: 0.9515 - val_loss: 1.1612 - val_acc: 0.7016\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2476 - acc: 0.9474 - val_loss: 1.0699 - val_acc: 0.7056\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2220 - acc: 0.9677 - val_loss: 1.1301 - val_acc: 0.7137\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2181 - acc: 0.9609 - val_loss: 1.1446 - val_acc: 0.7097\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2306 - acc: 0.9420 - val_loss: 1.1308 - val_acc: 0.6935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.2380 - acc: 0.9394 - val_loss: 1.1450 - val_acc: 0.7016\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 0.2266 - acc: 0.9501 - val_loss: 1.0811 - val_acc: 0.7298\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2311 - acc: 0.9488 - val_loss: 1.0971 - val_acc: 0.7177\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2294 - acc: 0.9488 - val_loss: 1.1583 - val_acc: 0.7016\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2217 - acc: 0.9474 - val_loss: 1.1639 - val_acc: 0.7097\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2233 - acc: 0.9461 - val_loss: 1.0740 - val_acc: 0.7379\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2236 - acc: 0.9501 - val_loss: 1.1051 - val_acc: 0.7177\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2296 - acc: 0.9474 - val_loss: 1.1205 - val_acc: 0.7258\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2251 - acc: 0.9488 - val_loss: 1.1239 - val_acc: 0.7258\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2417 - acc: 0.9340 - val_loss: 1.0871 - val_acc: 0.7137\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2188 - acc: 0.9528 - val_loss: 1.2251 - val_acc: 0.6694\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2109 - acc: 0.9623 - val_loss: 1.1283 - val_acc: 0.7339\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2212 - acc: 0.9501 - val_loss: 1.1673 - val_acc: 0.7137\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2158 - acc: 0.9528 - val_loss: 1.1700 - val_acc: 0.7056\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.2242 - acc: 0.9474 - val_loss: 1.1693 - val_acc: 0.6976\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2265 - acc: 0.9501 - val_loss: 1.1211 - val_acc: 0.6935\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2159 - acc: 0.9609 - val_loss: 1.1876 - val_acc: 0.6855\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2242 - acc: 0.9407 - val_loss: 1.1648 - val_acc: 0.6895\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2066 - acc: 0.9569 - val_loss: 1.1328 - val_acc: 0.7218\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2245 - acc: 0.9515 - val_loss: 1.1188 - val_acc: 0.7097\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2207 - acc: 0.9501 - val_loss: 1.1928 - val_acc: 0.6895\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.2112 - acc: 0.9555 - val_loss: 1.1063 - val_acc: 0.7218\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2195 - acc: 0.9488 - val_loss: 1.1799 - val_acc: 0.7016\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2171 - acc: 0.9515 - val_loss: 1.1478 - val_acc: 0.7016\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1944 - acc: 0.9609 - val_loss: 1.2620 - val_acc: 0.6815\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.2184 - acc: 0.9555 - val_loss: 1.1042 - val_acc: 0.7177\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2082 - acc: 0.9569 - val_loss: 1.1301 - val_acc: 0.7218\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2121 - acc: 0.9555 - val_loss: 1.0463 - val_acc: 0.7339\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2023 - acc: 0.9582 - val_loss: 1.1776 - val_acc: 0.7056\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2135 - acc: 0.9488 - val_loss: 1.0884 - val_acc: 0.7258\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2047 - acc: 0.9596 - val_loss: 1.1540 - val_acc: 0.7056\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2124 - acc: 0.9569 - val_loss: 1.1287 - val_acc: 0.6855\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1996 - acc: 0.9582 - val_loss: 1.0522 - val_acc: 0.7339\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.2145 - acc: 0.9474 - val_loss: 1.1167 - val_acc: 0.7016\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2084 - acc: 0.9501 - val_loss: 1.1569 - val_acc: 0.6895\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1948 - acc: 0.9596 - val_loss: 1.0815 - val_acc: 0.7339\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2103 - acc: 0.9555 - val_loss: 1.2045 - val_acc: 0.7258\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.2041 - acc: 0.9488 - val_loss: 1.1655 - val_acc: 0.7097\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.2092 - acc: 0.9501 - val_loss: 1.0341 - val_acc: 0.7379\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2132 - acc: 0.9447 - val_loss: 1.1290 - val_acc: 0.7097\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1868 - acc: 0.9636 - val_loss: 1.1006 - val_acc: 0.7298\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1908 - acc: 0.9582 - val_loss: 1.2017 - val_acc: 0.6774\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1918 - acc: 0.9650 - val_loss: 1.0456 - val_acc: 0.7258\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 0s 95us/step - loss: 0.2026 - acc: 0.9609 - val_loss: 1.0778 - val_acc: 0.7500\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1997 - acc: 0.9582 - val_loss: 1.1472 - val_acc: 0.7016\n",
      "Epoch 946/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1910 - acc: 0.9609 - val_loss: 1.2405 - val_acc: 0.6815\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2050 - acc: 0.9542 - val_loss: 1.1464 - val_acc: 0.6976\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1992 - acc: 0.9542 - val_loss: 1.1436 - val_acc: 0.6976\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2031 - acc: 0.9555 - val_loss: 1.1095 - val_acc: 0.7097\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1936 - acc: 0.9623 - val_loss: 1.1720 - val_acc: 0.6935\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.1910 - acc: 0.9596 - val_loss: 1.1363 - val_acc: 0.7218\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2182 - acc: 0.9542 - val_loss: 1.1145 - val_acc: 0.6935\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.1937 - acc: 0.9636 - val_loss: 1.1477 - val_acc: 0.6935\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1771 - acc: 0.9663 - val_loss: 1.1262 - val_acc: 0.7056\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1949 - acc: 0.9501 - val_loss: 1.1307 - val_acc: 0.6935\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1910 - acc: 0.9623 - val_loss: 1.1170 - val_acc: 0.7298\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.1858 - acc: 0.9596 - val_loss: 1.1490 - val_acc: 0.7137\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1951 - acc: 0.9582 - val_loss: 1.0844 - val_acc: 0.7097\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1861 - acc: 0.9623 - val_loss: 1.1983 - val_acc: 0.6774\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1966 - acc: 0.9596 - val_loss: 1.0978 - val_acc: 0.7137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1832 - acc: 0.9623 - val_loss: 1.0832 - val_acc: 0.7218\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.1885 - acc: 0.9650 - val_loss: 1.0954 - val_acc: 0.7339\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1787 - acc: 0.9623 - val_loss: 1.1511 - val_acc: 0.7258\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1825 - acc: 0.9663 - val_loss: 1.1948 - val_acc: 0.7016\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1839 - acc: 0.9650 - val_loss: 1.1758 - val_acc: 0.7258\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1845 - acc: 0.9582 - val_loss: 1.1404 - val_acc: 0.7137\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1881 - acc: 0.9582 - val_loss: 1.1122 - val_acc: 0.7258\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1815 - acc: 0.9609 - val_loss: 1.1203 - val_acc: 0.7137\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1825 - acc: 0.9636 - val_loss: 1.0821 - val_acc: 0.7298\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1692 - acc: 0.9690 - val_loss: 1.0793 - val_acc: 0.7339\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.1763 - acc: 0.9663 - val_loss: 1.1596 - val_acc: 0.7016\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.1780 - acc: 0.9623 - val_loss: 1.1139 - val_acc: 0.7258\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.1780 - acc: 0.9636 - val_loss: 1.1214 - val_acc: 0.7339\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1845 - acc: 0.9528 - val_loss: 1.1180 - val_acc: 0.7258\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1805 - acc: 0.9569 - val_loss: 1.1951 - val_acc: 0.7016\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1782 - acc: 0.9623 - val_loss: 1.1385 - val_acc: 0.7097\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.1730 - acc: 0.9609 - val_loss: 1.0515 - val_acc: 0.7339\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 0.1802 - acc: 0.9582 - val_loss: 1.1426 - val_acc: 0.7137\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1728 - acc: 0.9609 - val_loss: 1.0777 - val_acc: 0.7379\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1738 - acc: 0.9582 - val_loss: 1.1467 - val_acc: 0.6815\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.1736 - acc: 0.9569 - val_loss: 1.1085 - val_acc: 0.7339\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1695 - acc: 0.9609 - val_loss: 1.1865 - val_acc: 0.6976\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.1865 - acc: 0.9528 - val_loss: 1.0903 - val_acc: 0.7016\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1695 - acc: 0.9650 - val_loss: 1.1290 - val_acc: 0.6815\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1716 - acc: 0.9609 - val_loss: 1.1563 - val_acc: 0.7137\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1790 - acc: 0.9650 - val_loss: 1.1261 - val_acc: 0.7137\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1709 - acc: 0.9744 - val_loss: 1.0837 - val_acc: 0.7258\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1649 - acc: 0.9663 - val_loss: 1.1274 - val_acc: 0.7218\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1758 - acc: 0.9636 - val_loss: 1.1175 - val_acc: 0.7460\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1802 - acc: 0.9582 - val_loss: 1.1169 - val_acc: 0.6935\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1569 - acc: 0.9704 - val_loss: 1.1525 - val_acc: 0.7056\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1700 - acc: 0.9690 - val_loss: 1.0583 - val_acc: 0.7460\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1677 - acc: 0.9663 - val_loss: 1.1578 - val_acc: 0.7097\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.1747 - acc: 0.9623 - val_loss: 1.1124 - val_acc: 0.7137\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.1548 - acc: 0.9771 - val_loss: 1.1904 - val_acc: 0.6935\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1655 - acc: 0.9690 - val_loss: 1.0557 - val_acc: 0.7460\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1668 - acc: 0.9636 - val_loss: 1.1413 - val_acc: 0.7258\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1633 - acc: 0.9717 - val_loss: 1.2112 - val_acc: 0.7097\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.1613 - acc: 0.9730 - val_loss: 1.1400 - val_acc: 0.7177\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1732 - acc: 0.9623 - val_loss: 1.1107 - val_acc: 0.7177\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, epochs=1000, batch_size=128, validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be429db748>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化1："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增大网络的容量提高模型的拟合精度：把层数增多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 192, 32)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 192, 32)           7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 64, 32)            7200      \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 64, 32)            7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 21, 64)            14400     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 21, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 7, 64)             28736     \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 7, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 99)                6435      \n",
      "=================================================================\n",
      "Total params: 128,899\n",
      "Trainable params: 128,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6056 - acc: 0.0108 - val_loss: 4.5960 - val_acc: 0.0040\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 0s 247us/step - loss: 4.5957 - acc: 0.0027 - val_loss: 4.5969 - val_acc: 0.0081\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 0s 239us/step - loss: 4.5939 - acc: 0.0094 - val_loss: 4.5977 - val_acc: 0.0040\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 0s 229us/step - loss: 4.5943 - acc: 0.0081 - val_loss: 4.5979 - val_acc: 0.0040\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 0s 214us/step - loss: 4.5884 - acc: 0.0135 - val_loss: 4.5910 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 4.5827 - acc: 0.0135 - val_loss: 4.5841 - val_acc: 0.0081\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 4.5580 - acc: 0.0135 - val_loss: 4.5814 - val_acc: 0.0081\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 4.5499 - acc: 0.0283 - val_loss: 4.5781 - val_acc: 0.0081\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 4.5349 - acc: 0.0148 - val_loss: 4.5466 - val_acc: 0.0161\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 4.5317 - acc: 0.0121 - val_loss: 4.5344 - val_acc: 0.0121\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 4.5079 - acc: 0.0216 - val_loss: 4.5152 - val_acc: 0.0081\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 4.4748 - acc: 0.0216 - val_loss: 4.4938 - val_acc: 0.0121\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 4.4719 - acc: 0.0270 - val_loss: 4.4873 - val_acc: 0.0081\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 4.4575 - acc: 0.0216 - val_loss: 4.4513 - val_acc: 0.0121\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 4.4629 - acc: 0.0202 - val_loss: 4.4933 - val_acc: 0.0161\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 4.4317 - acc: 0.0310 - val_loss: 4.4664 - val_acc: 0.0121\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 4.4467 - acc: 0.0229 - val_loss: 4.4437 - val_acc: 0.0242\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 4.4061 - acc: 0.0175 - val_loss: 4.3903 - val_acc: 0.0202\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 4.4150 - acc: 0.0364 - val_loss: 4.4261 - val_acc: 0.0242\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 4.3505 - acc: 0.0364 - val_loss: 4.4518 - val_acc: 0.0121\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 4.3884 - acc: 0.0270 - val_loss: 4.3662 - val_acc: 0.0282\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 4.2691 - acc: 0.0350 - val_loss: 4.3358 - val_acc: 0.0323\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 4.2490 - acc: 0.0377 - val_loss: 4.4831 - val_acc: 0.0161\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 4.2631 - acc: 0.0431 - val_loss: 4.2183 - val_acc: 0.0444\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 4.2054 - acc: 0.0404 - val_loss: 4.1747 - val_acc: 0.0484\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 4.1807 - acc: 0.0418 - val_loss: 4.3293 - val_acc: 0.0484\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 4.2001 - acc: 0.0404 - val_loss: 4.2175 - val_acc: 0.0363\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 4.1238 - acc: 0.0323 - val_loss: 4.0977 - val_acc: 0.0484\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 4.1468 - acc: 0.0472 - val_loss: 4.0712 - val_acc: 0.0524\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 4.0681 - acc: 0.0485 - val_loss: 4.0272 - val_acc: 0.0605\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 4.1224 - acc: 0.0404 - val_loss: 4.1036 - val_acc: 0.0565\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 0s 188us/step - loss: 4.0211 - acc: 0.0458 - val_loss: 4.1416 - val_acc: 0.0605\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 4.0113 - acc: 0.0512 - val_loss: 4.1512 - val_acc: 0.0484\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.9592 - acc: 0.0512 - val_loss: 4.0329 - val_acc: 0.0565\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 3.9845 - acc: 0.0499 - val_loss: 4.1278 - val_acc: 0.0605\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 3.9127 - acc: 0.0499 - val_loss: 3.9588 - val_acc: 0.0806\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.8543 - acc: 0.0795 - val_loss: 3.9437 - val_acc: 0.0685\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.9200 - acc: 0.0620 - val_loss: 3.9588 - val_acc: 0.0685\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.9223 - acc: 0.0404 - val_loss: 4.1410 - val_acc: 0.0565\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.8241 - acc: 0.0714 - val_loss: 3.7847 - val_acc: 0.0887\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.8079 - acc: 0.0674 - val_loss: 3.7354 - val_acc: 0.0847\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 3.8128 - acc: 0.0728 - val_loss: 3.7156 - val_acc: 0.0847\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.8389 - acc: 0.0687 - val_loss: 3.7823 - val_acc: 0.0968\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 3.8266 - acc: 0.0728 - val_loss: 3.7238 - val_acc: 0.0968\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.7884 - acc: 0.0674 - val_loss: 3.6670 - val_acc: 0.0968\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 3.6963 - acc: 0.1011 - val_loss: 3.6170 - val_acc: 0.1048\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 3.7462 - acc: 0.0687 - val_loss: 3.7090 - val_acc: 0.1048\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 3.6709 - acc: 0.0660 - val_loss: 3.5999 - val_acc: 0.0887\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.6980 - acc: 0.0957 - val_loss: 3.6274 - val_acc: 0.0968\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.6220 - acc: 0.0903 - val_loss: 3.7259 - val_acc: 0.1008\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.6266 - acc: 0.0916 - val_loss: 3.8186 - val_acc: 0.0887\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 3.6281 - acc: 0.0863 - val_loss: 3.5370 - val_acc: 0.1008\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 3.5982 - acc: 0.0943 - val_loss: 3.5177 - val_acc: 0.1169\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 3.5402 - acc: 0.1065 - val_loss: 3.5426 - val_acc: 0.1048\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 3.6482 - acc: 0.0984 - val_loss: 3.6383 - val_acc: 0.1169\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 3.5480 - acc: 0.1159 - val_loss: 3.7446 - val_acc: 0.0847\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 3.5147 - acc: 0.1280 - val_loss: 3.4609 - val_acc: 0.1169\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.5472 - acc: 0.1173 - val_loss: 3.4742 - val_acc: 0.1331\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.4081 - acc: 0.1213 - val_loss: 3.4323 - val_acc: 0.1089\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.5635 - acc: 0.1092 - val_loss: 3.3922 - val_acc: 0.1250\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.3956 - acc: 0.1092 - val_loss: 3.4328 - val_acc: 0.1290\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.4293 - acc: 0.1240 - val_loss: 3.6074 - val_acc: 0.1129\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.4072 - acc: 0.1065 - val_loss: 3.3709 - val_acc: 0.1089\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.3731 - acc: 0.1253 - val_loss: 3.6575 - val_acc: 0.1008\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.4474 - acc: 0.1105 - val_loss: 3.4657 - val_acc: 0.1129\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.4119 - acc: 0.1199 - val_loss: 3.4845 - val_acc: 0.1210\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.3581 - acc: 0.1348 - val_loss: 3.4153 - val_acc: 0.1452\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 3.2924 - acc: 0.1388 - val_loss: 3.3165 - val_acc: 0.1492\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.2644 - acc: 0.1280 - val_loss: 3.3048 - val_acc: 0.1371\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 3.3169 - acc: 0.1348 - val_loss: 3.1673 - val_acc: 0.1573\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.1752 - acc: 0.1509 - val_loss: 3.0960 - val_acc: 0.1734\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 3.2680 - acc: 0.1321 - val_loss: 3.1707 - val_acc: 0.1734\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 3.2170 - acc: 0.1469 - val_loss: 3.1461 - val_acc: 0.1532\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 3.2346 - acc: 0.1375 - val_loss: 3.3494 - val_acc: 0.1573\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 3.2128 - acc: 0.1590 - val_loss: 3.2601 - val_acc: 0.1613\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.2856 - acc: 0.1617 - val_loss: 3.2458 - val_acc: 0.1492\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.1011 - acc: 0.1617 - val_loss: 3.0663 - val_acc: 0.2137\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.1817 - acc: 0.1617 - val_loss: 3.1435 - val_acc: 0.2379\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 3.1141 - acc: 0.1604 - val_loss: 3.1028 - val_acc: 0.1613\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 3.1788 - acc: 0.1712 - val_loss: 3.1136 - val_acc: 0.1895\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 3.1183 - acc: 0.1590 - val_loss: 3.0063 - val_acc: 0.2137\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 3.0588 - acc: 0.1819 - val_loss: 3.0023 - val_acc: 0.2016\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.1177 - acc: 0.1590 - val_loss: 2.9539 - val_acc: 0.2218\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 3.0014 - acc: 0.1819 - val_loss: 3.2417 - val_acc: 0.1573\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 3.1998 - acc: 0.1604 - val_loss: 2.9590 - val_acc: 0.2137\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 3.0356 - acc: 0.1887 - val_loss: 2.9932 - val_acc: 0.2540\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.9453 - acc: 0.1765 - val_loss: 3.1681 - val_acc: 0.1653\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 3.0088 - acc: 0.1887 - val_loss: 2.8827 - val_acc: 0.2177\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 3.0124 - acc: 0.2008 - val_loss: 3.1336 - val_acc: 0.1855\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.9326 - acc: 0.2210 - val_loss: 2.8686 - val_acc: 0.2500\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.9150 - acc: 0.1981 - val_loss: 2.8259 - val_acc: 0.2581\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.9193 - acc: 0.1968 - val_loss: 2.8404 - val_acc: 0.2460\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.9260 - acc: 0.1927 - val_loss: 2.7442 - val_acc: 0.2621\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.9266 - acc: 0.2183 - val_loss: 2.8159 - val_acc: 0.2661\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.8143 - acc: 0.1981 - val_loss: 2.7083 - val_acc: 0.2984\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 2.8117 - acc: 0.2345 - val_loss: 2.8953 - val_acc: 0.2540\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.9380 - acc: 0.2008 - val_loss: 2.7216 - val_acc: 0.2863\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 2.7688 - acc: 0.2264 - val_loss: 2.6264 - val_acc: 0.2823\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 2.8520 - acc: 0.2022 - val_loss: 2.7502 - val_acc: 0.2782\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.7662 - acc: 0.2251 - val_loss: 2.6754 - val_acc: 0.2742\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 2.8025 - acc: 0.2224 - val_loss: 2.6902 - val_acc: 0.3105\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.8096 - acc: 0.2278 - val_loss: 2.7122 - val_acc: 0.2782\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.8639 - acc: 0.2116 - val_loss: 2.7824 - val_acc: 0.2581\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.7006 - acc: 0.2682 - val_loss: 2.7839 - val_acc: 0.2379\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 2.8224 - acc: 0.1968 - val_loss: 2.9922 - val_acc: 0.1774\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.6467 - acc: 0.2426 - val_loss: 2.6009 - val_acc: 0.3145\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.6695 - acc: 0.2224 - val_loss: 2.8331 - val_acc: 0.2218\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.7086 - acc: 0.2426 - val_loss: 2.5479 - val_acc: 0.3145\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 2.5821 - acc: 0.2628 - val_loss: 2.5885 - val_acc: 0.3065\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.5692 - acc: 0.2763 - val_loss: 2.7152 - val_acc: 0.2500\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 2.7376 - acc: 0.2453 - val_loss: 2.6490 - val_acc: 0.3024\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.5929 - acc: 0.2763 - val_loss: 2.5939 - val_acc: 0.2903\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 2.7123 - acc: 0.2682 - val_loss: 2.5255 - val_acc: 0.3427\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.6019 - acc: 0.2466 - val_loss: 2.4942 - val_acc: 0.3427\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.5780 - acc: 0.2722 - val_loss: 2.4707 - val_acc: 0.3387\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 0s 188us/step - loss: 2.5510 - acc: 0.2709 - val_loss: 2.5205 - val_acc: 0.3185\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.5769 - acc: 0.2574 - val_loss: 2.4411 - val_acc: 0.3468\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 2.5015 - acc: 0.2951 - val_loss: 2.4303 - val_acc: 0.3427\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.6375 - acc: 0.2507 - val_loss: 2.4917 - val_acc: 0.3629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 2.5453 - acc: 0.2695 - val_loss: 2.3786 - val_acc: 0.3871\n",
      "Epoch 121/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 2.4238 - acc: 0.2884 - val_loss: 2.6137 - val_acc: 0.2661\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.5402 - acc: 0.2642 - val_loss: 2.3194 - val_acc: 0.3548\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 2.4630 - acc: 0.2749 - val_loss: 2.5061 - val_acc: 0.3347\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.5079 - acc: 0.2722 - val_loss: 2.3377 - val_acc: 0.3911\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.4772 - acc: 0.2951 - val_loss: 2.3060 - val_acc: 0.4032\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.5144 - acc: 0.2601 - val_loss: 2.4137 - val_acc: 0.3911\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 2.3922 - acc: 0.3073 - val_loss: 2.3491 - val_acc: 0.3952\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.4132 - acc: 0.2978 - val_loss: 2.3632 - val_acc: 0.4032\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 2.3450 - acc: 0.3221 - val_loss: 2.5844 - val_acc: 0.2540\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.4046 - acc: 0.3005 - val_loss: 2.4158 - val_acc: 0.3387\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.4932 - acc: 0.2803 - val_loss: 2.5428 - val_acc: 0.2903\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.3474 - acc: 0.3194 - val_loss: 2.2213 - val_acc: 0.3831\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.3041 - acc: 0.3100 - val_loss: 2.4162 - val_acc: 0.3548\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.3912 - acc: 0.3113 - val_loss: 2.1712 - val_acc: 0.4073\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.3168 - acc: 0.3302 - val_loss: 2.3383 - val_acc: 0.3427\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.2889 - acc: 0.3208 - val_loss: 2.2001 - val_acc: 0.3911\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.2885 - acc: 0.3208 - val_loss: 2.2598 - val_acc: 0.3831\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.2850 - acc: 0.3221 - val_loss: 2.3267 - val_acc: 0.3185\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.3929 - acc: 0.2803 - val_loss: 2.2302 - val_acc: 0.3790\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 2.2965 - acc: 0.3113 - val_loss: 2.5478 - val_acc: 0.2460\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.3133 - acc: 0.3005 - val_loss: 2.1391 - val_acc: 0.4153\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.1908 - acc: 0.3625 - val_loss: 2.0617 - val_acc: 0.4355\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.2739 - acc: 0.3329 - val_loss: 2.4990 - val_acc: 0.2702\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 2.3038 - acc: 0.3342 - val_loss: 2.1979 - val_acc: 0.4153\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.2864 - acc: 0.3208 - val_loss: 2.3593 - val_acc: 0.3548\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.2486 - acc: 0.3261 - val_loss: 2.1411 - val_acc: 0.4355\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.3051 - acc: 0.3342 - val_loss: 2.0812 - val_acc: 0.4274\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 2.1311 - acc: 0.3585 - val_loss: 2.0961 - val_acc: 0.3952\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.1592 - acc: 0.3477 - val_loss: 2.0187 - val_acc: 0.4556\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.1735 - acc: 0.3585 - val_loss: 2.1515 - val_acc: 0.4113\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.3035 - acc: 0.3356 - val_loss: 2.0420 - val_acc: 0.4395\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 2.1791 - acc: 0.3329 - val_loss: 2.0785 - val_acc: 0.4274\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 2.2216 - acc: 0.3558 - val_loss: 2.0566 - val_acc: 0.4476\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 2.1629 - acc: 0.363 - 0s 196us/step - loss: 2.1576 - acc: 0.3598 - val_loss: 1.9886 - val_acc: 0.4435\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.1299 - acc: 0.3544 - val_loss: 1.9959 - val_acc: 0.4435\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.1313 - acc: 0.3598 - val_loss: 2.7495 - val_acc: 0.1935\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.1309 - acc: 0.3558 - val_loss: 2.0332 - val_acc: 0.4234\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.1298 - acc: 0.3625 - val_loss: 1.9953 - val_acc: 0.4597\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.0730 - acc: 0.3666 - val_loss: 2.0065 - val_acc: 0.4516\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 2.2145 - acc: 0.3437 - val_loss: 2.0414 - val_acc: 0.4234\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.0726 - acc: 0.3733 - val_loss: 2.2158 - val_acc: 0.3548\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 2.0651 - acc: 0.3733 - val_loss: 1.9935 - val_acc: 0.4395\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.1058 - acc: 0.3558 - val_loss: 1.9704 - val_acc: 0.4435\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.9730 - acc: 0.3827 - val_loss: 1.9029 - val_acc: 0.4234\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.0572 - acc: 0.3652 - val_loss: 1.9270 - val_acc: 0.4597\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 2.0455 - acc: 0.3908 - val_loss: 1.9046 - val_acc: 0.4516\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 2.0001 - acc: 0.3854 - val_loss: 1.9053 - val_acc: 0.4516\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.1579 - acc: 0.3477 - val_loss: 2.0531 - val_acc: 0.4194\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.0018 - acc: 0.3854 - val_loss: 1.9061 - val_acc: 0.4758\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.8671 - acc: 0.4353 - val_loss: 1.9477 - val_acc: 0.4395\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 2.1033 - acc: 0.3922 - val_loss: 1.9347 - val_acc: 0.4476\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.8877 - acc: 0.4124 - val_loss: 1.9220 - val_acc: 0.4395\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.9306 - acc: 0.3949 - val_loss: 2.0790 - val_acc: 0.3871\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 2.0891 - acc: 0.3976 - val_loss: 2.0342 - val_acc: 0.4435\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.9401 - acc: 0.4084 - val_loss: 1.8597 - val_acc: 0.4677\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.9876 - acc: 0.4003 - val_loss: 1.9225 - val_acc: 0.4516\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.9093 - acc: 0.3922 - val_loss: 1.9699 - val_acc: 0.4234\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.9790 - acc: 0.3922 - val_loss: 2.3208 - val_acc: 0.2984\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 194us/step - loss: 1.9138 - acc: 0.4340 - val_loss: 1.8866 - val_acc: 0.4758\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.9476 - acc: 0.3908 - val_loss: 1.8600 - val_acc: 0.4718\n",
      "Epoch 181/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.9025 - acc: 0.4030 - val_loss: 1.7997 - val_acc: 0.4960\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 2.0157 - acc: 0.4137 - val_loss: 1.9195 - val_acc: 0.4516\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.8535 - acc: 0.4111 - val_loss: 1.8484 - val_acc: 0.4476\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.9020 - acc: 0.4259 - val_loss: 2.1661 - val_acc: 0.3145\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.8486 - acc: 0.4097 - val_loss: 1.8139 - val_acc: 0.4718\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.8483 - acc: 0.4137 - val_loss: 1.8023 - val_acc: 0.4839\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 2.0092 - acc: 0.3908 - val_loss: 1.8477 - val_acc: 0.4556\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.8167 - acc: 0.4515 - val_loss: 1.8753 - val_acc: 0.4597\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.8960 - acc: 0.4286 - val_loss: 1.9075 - val_acc: 0.4677\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.8577 - acc: 0.4326 - val_loss: 2.1227 - val_acc: 0.3589\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.7938 - acc: 0.4394 - val_loss: 1.9748 - val_acc: 0.4315\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.9382 - acc: 0.4003 - val_loss: 1.7687 - val_acc: 0.5000\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.7543 - acc: 0.4515 - val_loss: 1.7275 - val_acc: 0.5323\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.9526 - acc: 0.4178 - val_loss: 1.7555 - val_acc: 0.4798\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.8340 - acc: 0.4407 - val_loss: 1.8825 - val_acc: 0.4556\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.8163 - acc: 0.4501 - val_loss: 1.7221 - val_acc: 0.4960\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.7883 - acc: 0.4367 - val_loss: 1.7357 - val_acc: 0.5081\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.7880 - acc: 0.4677 - val_loss: 1.8668 - val_acc: 0.4435\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.7880 - acc: 0.4326 - val_loss: 1.8045 - val_acc: 0.4839\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.8462 - acc: 0.4272 - val_loss: 2.2221 - val_acc: 0.2782\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.8062 - acc: 0.4016 - val_loss: 1.7275 - val_acc: 0.5202\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.7663 - acc: 0.4461 - val_loss: 1.7698 - val_acc: 0.4960\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.7359 - acc: 0.4420 - val_loss: 1.8085 - val_acc: 0.4798\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.7902 - acc: 0.4461 - val_loss: 1.8827 - val_acc: 0.4315\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.8712 - acc: 0.4164 - val_loss: 2.1263 - val_acc: 0.3387\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.7724 - acc: 0.4434 - val_loss: 1.7487 - val_acc: 0.5161\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.7100 - acc: 0.4582 - val_loss: 1.7496 - val_acc: 0.4839\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.8080 - acc: 0.4407 - val_loss: 1.7105 - val_acc: 0.5040\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.8525 - acc: 0.4380 - val_loss: 1.7331 - val_acc: 0.5040\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.7402 - acc: 0.4542 - val_loss: 1.6810 - val_acc: 0.5242\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.6919 - acc: 0.4609 - val_loss: 1.7505 - val_acc: 0.4677\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.8386 - acc: 0.4178 - val_loss: 1.7897 - val_acc: 0.4919\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.7188 - acc: 0.4488 - val_loss: 1.6740 - val_acc: 0.5282\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.6728 - acc: 0.4623 - val_loss: 1.7605 - val_acc: 0.5000\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.8866 - acc: 0.4501 - val_loss: 1.6408 - val_acc: 0.5242\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.6660 - acc: 0.4865 - val_loss: 1.7738 - val_acc: 0.4718\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.7579 - acc: 0.4380 - val_loss: 1.8623 - val_acc: 0.4758\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.6795 - acc: 0.4582 - val_loss: 1.8548 - val_acc: 0.4516\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.5822 - acc: 0.5148 - val_loss: 1.6391 - val_acc: 0.5323\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.6288 - acc: 0.4704 - val_loss: 1.7458 - val_acc: 0.4960\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.6694 - acc: 0.4447 - val_loss: 1.6419 - val_acc: 0.5403\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.6399 - acc: 0.4865 - val_loss: 1.8468 - val_acc: 0.4315\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.6274 - acc: 0.5000 - val_loss: 1.6156 - val_acc: 0.5444\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.8880 - acc: 0.4461 - val_loss: 1.8810 - val_acc: 0.4476\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.6518 - acc: 0.4919 - val_loss: 1.6828 - val_acc: 0.5000\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.6485 - acc: 0.4973 - val_loss: 1.6080 - val_acc: 0.5565\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.6768 - acc: 0.4879 - val_loss: 1.8930 - val_acc: 0.4597\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.5921 - acc: 0.5135 - val_loss: 1.8565 - val_acc: 0.4677\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.7140 - acc: 0.4717 - val_loss: 1.9227 - val_acc: 0.4234\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.6090 - acc: 0.5296 - val_loss: 1.6392 - val_acc: 0.5282\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.6100 - acc: 0.4919 - val_loss: 1.6209 - val_acc: 0.5161\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.5511 - acc: 0.5013 - val_loss: 1.6640 - val_acc: 0.5081\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.7141 - acc: 0.4528 - val_loss: 1.6953 - val_acc: 0.5323\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.5846 - acc: 0.4960 - val_loss: 1.6612 - val_acc: 0.5121\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.5461 - acc: 0.5081 - val_loss: 1.5680 - val_acc: 0.5363\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 0s 187us/step - loss: 1.5889 - acc: 0.5148 - val_loss: 1.7180 - val_acc: 0.5081\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.7266 - acc: 0.4528 - val_loss: 1.7790 - val_acc: 0.4718\n",
      "Epoch 238/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.6370 - acc: 0.4447 - val_loss: 1.6659 - val_acc: 0.5000\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.5226 - acc: 0.4946 - val_loss: 1.6393 - val_acc: 0.5161\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.6867 - acc: 0.4838 - val_loss: 1.6296 - val_acc: 0.5403\n",
      "Epoch 241/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.6566 - acc: 0.4906 - val_loss: 1.6634 - val_acc: 0.5161\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.5422 - acc: 0.5013 - val_loss: 1.5328 - val_acc: 0.5565\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.6506 - acc: 0.4757 - val_loss: 1.6441 - val_acc: 0.5202\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 1.5065 - acc: 0.5350 - val_loss: 1.6611 - val_acc: 0.5161\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5395 - acc: 0.5013 - val_loss: 1.6268 - val_acc: 0.5484\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.6736 - acc: 0.4852 - val_loss: 1.6424 - val_acc: 0.5323\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.5617 - acc: 0.5013 - val_loss: 1.5813 - val_acc: 0.5363\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.6876 - acc: 0.4838 - val_loss: 1.6735 - val_acc: 0.5323\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.4871 - acc: 0.5296 - val_loss: 1.6116 - val_acc: 0.5282\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5097 - acc: 0.5108 - val_loss: 1.6316 - val_acc: 0.4919\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5825 - acc: 0.4892 - val_loss: 1.5939 - val_acc: 0.5685\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.4548 - acc: 0.5040 - val_loss: 1.5256 - val_acc: 0.5282\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.7587 - acc: 0.4690 - val_loss: 1.6760 - val_acc: 0.5323\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.5937 - acc: 0.4987 - val_loss: 1.5849 - val_acc: 0.5685\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.5492 - acc: 0.5000 - val_loss: 1.5271 - val_acc: 0.5726\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.5435 - acc: 0.5054 - val_loss: 1.7249 - val_acc: 0.4718\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.5921 - acc: 0.4973 - val_loss: 1.5788 - val_acc: 0.5363\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.6016 - acc: 0.4879 - val_loss: 1.6603 - val_acc: 0.5202\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4285 - acc: 0.5431 - val_loss: 1.4967 - val_acc: 0.5484\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.5400 - acc: 0.5323 - val_loss: 1.6626 - val_acc: 0.5081\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.5114 - acc: 0.5337 - val_loss: 1.6246 - val_acc: 0.5323\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.5950 - acc: 0.4960 - val_loss: 1.5010 - val_acc: 0.5605\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4799 - acc: 0.5054 - val_loss: 1.5114 - val_acc: 0.5645\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5165 - acc: 0.5121 - val_loss: 1.6609 - val_acc: 0.4919\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.6303 - acc: 0.5081 - val_loss: 1.5132 - val_acc: 0.5766\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5185 - acc: 0.5323 - val_loss: 1.5947 - val_acc: 0.5121\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4918 - acc: 0.5148 - val_loss: 1.6144 - val_acc: 0.5403\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4125 - acc: 0.5391 - val_loss: 1.4951 - val_acc: 0.5605\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.6247 - acc: 0.4838 - val_loss: 1.5554 - val_acc: 0.5766\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.4852 - acc: 0.5270 - val_loss: 1.4890 - val_acc: 0.5927\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.4183 - acc: 0.5377 - val_loss: 1.5456 - val_acc: 0.5444\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.4772 - acc: 0.5283 - val_loss: 1.7332 - val_acc: 0.4677\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.5661 - acc: 0.5229 - val_loss: 1.5038 - val_acc: 0.5645\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.4142 - acc: 0.5404 - val_loss: 1.4708 - val_acc: 0.5726\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.3798 - acc: 0.5553 - val_loss: 1.4722 - val_acc: 0.5806\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.6255 - acc: 0.4973 - val_loss: 1.4674 - val_acc: 0.5887\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.3822 - acc: 0.5539 - val_loss: 1.5541 - val_acc: 0.5403\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4697 - acc: 0.5243 - val_loss: 1.5188 - val_acc: 0.5685\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.4146 - acc: 0.5512 - val_loss: 1.4620 - val_acc: 0.5726\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4516 - acc: 0.5189 - val_loss: 1.5472 - val_acc: 0.5323\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4370 - acc: 0.5296 - val_loss: 1.7814 - val_acc: 0.4798\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.5471 - acc: 0.5067 - val_loss: 1.4325 - val_acc: 0.6048\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.3314 - acc: 0.5553 - val_loss: 1.4612 - val_acc: 0.5887\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4014 - acc: 0.5323 - val_loss: 1.5040 - val_acc: 0.5605\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4452 - acc: 0.5445 - val_loss: 1.5644 - val_acc: 0.5444\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.4150 - acc: 0.5445 - val_loss: 1.8253 - val_acc: 0.5000\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.5084 - acc: 0.5377 - val_loss: 1.4879 - val_acc: 0.5806\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4185 - acc: 0.5243 - val_loss: 1.4908 - val_acc: 0.5685\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.4597 - acc: 0.5175 - val_loss: 1.4562 - val_acc: 0.5685\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3281 - acc: 0.5701 - val_loss: 1.5301 - val_acc: 0.5645\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 1.3439 - acc: 0.5633 - val_loss: 1.5267 - val_acc: 0.5403\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4173 - acc: 0.5364 - val_loss: 2.0537 - val_acc: 0.3952\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4230 - acc: 0.5593 - val_loss: 1.5223 - val_acc: 0.5766\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4085 - acc: 0.5687 - val_loss: 1.5749 - val_acc: 0.5121\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.5253 - acc: 0.5216 - val_loss: 1.5193 - val_acc: 0.5363\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.2734 - acc: 0.5970 - val_loss: 1.4218 - val_acc: 0.5887\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 195us/step - loss: 1.3024 - acc: 0.5809 - val_loss: 1.3958 - val_acc: 0.5927\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.3549 - acc: 0.5539 - val_loss: 1.7180 - val_acc: 0.4758\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4744 - acc: 0.5512 - val_loss: 1.5485 - val_acc: 0.5524\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3395 - acc: 0.5674 - val_loss: 1.3970 - val_acc: 0.6371\n",
      "Epoch 301/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3625 - acc: 0.5687 - val_loss: 1.3757 - val_acc: 0.6492\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.5872 - acc: 0.5391 - val_loss: 1.4056 - val_acc: 0.5968\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.2768 - acc: 0.5660 - val_loss: 1.4119 - val_acc: 0.6089\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4092 - acc: 0.5445 - val_loss: 1.4265 - val_acc: 0.6089\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2734 - acc: 0.5755 - val_loss: 1.3585 - val_acc: 0.6008\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.2193 - acc: 0.6051 - val_loss: 1.5662 - val_acc: 0.5887\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4924 - acc: 0.5296 - val_loss: 1.3727 - val_acc: 0.6008\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.3249 - acc: 0.5741 - val_loss: 1.3910 - val_acc: 0.6371\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3066 - acc: 0.5728 - val_loss: 1.4204 - val_acc: 0.6048\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 1.5155 - acc: 0.5283 - val_loss: 1.3598 - val_acc: 0.6089\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.3027 - acc: 0.5620 - val_loss: 1.4640 - val_acc: 0.5645\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.2749 - acc: 0.5849 - val_loss: 1.4433 - val_acc: 0.5645\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.4289 - acc: 0.5364 - val_loss: 1.4703 - val_acc: 0.5927\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.3767 - acc: 0.5404 - val_loss: 1.3755 - val_acc: 0.6210\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.2547 - acc: 0.5809 - val_loss: 1.4351 - val_acc: 0.5968\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.2753 - acc: 0.5647 - val_loss: 1.6462 - val_acc: 0.5403\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.4147 - acc: 0.5633 - val_loss: 1.4500 - val_acc: 0.6210\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.3416 - acc: 0.5768 - val_loss: 1.3442 - val_acc: 0.5887\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.3144 - acc: 0.5418 - val_loss: 1.4247 - val_acc: 0.5847\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4389 - acc: 0.5458 - val_loss: 1.3414 - val_acc: 0.6210\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2342 - acc: 0.6173 - val_loss: 1.3368 - val_acc: 0.6371\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.2393 - acc: 0.5984 - val_loss: 1.4362 - val_acc: 0.5968\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.3381 - acc: 0.5687 - val_loss: 1.4301 - val_acc: 0.6089\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.4686 - acc: 0.5553 - val_loss: 1.4169 - val_acc: 0.6008\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.2000 - acc: 0.6253 - val_loss: 1.3136 - val_acc: 0.6290\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.2910 - acc: 0.5755 - val_loss: 1.8353 - val_acc: 0.4718\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.3434 - acc: 0.5822 - val_loss: 1.3676 - val_acc: 0.5806\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2459 - acc: 0.5930 - val_loss: 1.4072 - val_acc: 0.5968\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.1987 - acc: 0.6038 - val_loss: 1.3819 - val_acc: 0.6089\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2460 - acc: 0.5526 - val_loss: 1.3976 - val_acc: 0.6008\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2755 - acc: 0.5876 - val_loss: 1.3861 - val_acc: 0.5887\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.1587 - acc: 0.6078 - val_loss: 1.4253 - val_acc: 0.6008\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.5659 - acc: 0.5256 - val_loss: 1.3609 - val_acc: 0.6008\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2354 - acc: 0.6024 - val_loss: 1.3288 - val_acc: 0.6250\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.2605 - acc: 0.5566 - val_loss: 1.3541 - val_acc: 0.6169\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2462 - acc: 0.5970 - val_loss: 1.3166 - val_acc: 0.6210\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.2765 - acc: 0.6011 - val_loss: 1.4568 - val_acc: 0.6210\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2676 - acc: 0.6119 - val_loss: 1.3254 - val_acc: 0.6129\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.2021 - acc: 0.6119 - val_loss: 1.4423 - val_acc: 0.6048\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.2542 - acc: 0.5795 - val_loss: 1.2909 - val_acc: 0.6290\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.2198 - acc: 0.5863 - val_loss: 1.3471 - val_acc: 0.6210\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.3231 - acc: 0.5701 - val_loss: 1.6006 - val_acc: 0.5202\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.3617 - acc: 0.5647 - val_loss: 1.3199 - val_acc: 0.6452\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2548 - acc: 0.5553 - val_loss: 1.3594 - val_acc: 0.6290\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2442 - acc: 0.6078 - val_loss: 1.4361 - val_acc: 0.6008\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.1535 - acc: 0.6280 - val_loss: 1.3076 - val_acc: 0.6290\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2360 - acc: 0.6038 - val_loss: 1.7677 - val_acc: 0.4919\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.2281 - acc: 0.5997 - val_loss: 1.3634 - val_acc: 0.6169\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2682 - acc: 0.5809 - val_loss: 1.4010 - val_acc: 0.6210\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.1971 - acc: 0.6011 - val_loss: 2.0082 - val_acc: 0.4476\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.3158 - acc: 0.5633 - val_loss: 1.3769 - val_acc: 0.6250\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2011 - acc: 0.6092 - val_loss: 1.3319 - val_acc: 0.6169\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.2942 - acc: 0.5836 - val_loss: 1.3535 - val_acc: 0.6210\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.1573 - acc: 0.6213 - val_loss: 1.3234 - val_acc: 0.6492\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.1873 - acc: 0.6078 - val_loss: 1.3714 - val_acc: 0.6210\n",
      "Epoch 356/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.1856 - acc: 0.6024 - val_loss: 1.4549 - val_acc: 0.6048\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2479 - acc: 0.6011 - val_loss: 1.3846 - val_acc: 0.6129\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.1377 - acc: 0.6119 - val_loss: 1.3708 - val_acc: 0.6008\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.1305 - acc: 0.6240 - val_loss: 1.4666 - val_acc: 0.5645\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.2455 - acc: 0.5984 - val_loss: 1.4267 - val_acc: 0.5726\n",
      "Epoch 361/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2042 - acc: 0.5957 - val_loss: 1.3731 - val_acc: 0.6331\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3100 - acc: 0.5809 - val_loss: 1.4603 - val_acc: 0.5847\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1938 - acc: 0.6132 - val_loss: 1.3198 - val_acc: 0.6371\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.1788 - acc: 0.6105 - val_loss: 1.3622 - val_acc: 0.5927\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.1573 - acc: 0.6105 - val_loss: 1.3802 - val_acc: 0.5645\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2496 - acc: 0.5795 - val_loss: 1.3428 - val_acc: 0.6048\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.2573 - acc: 0.5876 - val_loss: 1.4928 - val_acc: 0.6008\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.2561 - acc: 0.6146 - val_loss: 1.2991 - val_acc: 0.6371\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0770 - acc: 0.6334 - val_loss: 1.5415 - val_acc: 0.5806\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 1.2113 - acc: 0.6132 - val_loss: 1.3812 - val_acc: 0.6048\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.2233 - acc: 0.5997 - val_loss: 1.3191 - val_acc: 0.6331\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.1677 - acc: 0.6051 - val_loss: 1.2691 - val_acc: 0.6492\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0653 - acc: 0.6523 - val_loss: 1.3673 - val_acc: 0.5927\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.1835 - acc: 0.5957 - val_loss: 1.3237 - val_acc: 0.6371\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.1505 - acc: 0.6199 - val_loss: 1.2770 - val_acc: 0.6573\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 1.0993 - acc: 0.6321 - val_loss: 1.4034 - val_acc: 0.6290\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.3428 - acc: 0.5458 - val_loss: 1.2888 - val_acc: 0.6411\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0897 - acc: 0.6321 - val_loss: 1.3191 - val_acc: 0.6290\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 1.1906 - acc: 0.6213 - val_loss: 1.4265 - val_acc: 0.5887\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0512 - acc: 0.6402 - val_loss: 1.2445 - val_acc: 0.6492\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.3026 - acc: 0.5687 - val_loss: 1.2437 - val_acc: 0.6532\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.0785 - acc: 0.6496 - val_loss: 1.3293 - val_acc: 0.6331\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0990 - acc: 0.6375 - val_loss: 1.4421 - val_acc: 0.6129\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.1599 - acc: 0.6146 - val_loss: 1.6333 - val_acc: 0.5484\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0901 - acc: 0.6509 - val_loss: 1.2648 - val_acc: 0.6492\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1839 - acc: 0.6213 - val_loss: 1.2839 - val_acc: 0.6331\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.1235 - acc: 0.6280 - val_loss: 1.3588 - val_acc: 0.5806\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1445 - acc: 0.6334 - val_loss: 1.3655 - val_acc: 0.6129\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.1206 - acc: 0.6334 - val_loss: 1.2728 - val_acc: 0.6492\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3372 - acc: 0.6024 - val_loss: 1.2123 - val_acc: 0.6532\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.0852 - acc: 0.6442 - val_loss: 1.2302 - val_acc: 0.6532\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0033 - acc: 0.6482 - val_loss: 1.3049 - val_acc: 0.6411\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0771 - acc: 0.6226 - val_loss: 1.2087 - val_acc: 0.6411\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.1531 - acc: 0.6024 - val_loss: 1.2820 - val_acc: 0.6129\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 1.1056 - acc: 0.6199 - val_loss: 1.2569 - val_acc: 0.6411\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.1279 - acc: 0.6132 - val_loss: 1.3441 - val_acc: 0.6048\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2354 - acc: 0.6119 - val_loss: 1.2091 - val_acc: 0.6492\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0890 - acc: 0.6065 - val_loss: 1.2405 - val_acc: 0.6573\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1156 - acc: 0.6388 - val_loss: 1.3254 - val_acc: 0.6371\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0372 - acc: 0.6671 - val_loss: 1.2098 - val_acc: 0.6573\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0392 - acc: 0.6442 - val_loss: 1.2828 - val_acc: 0.6169\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.0965 - acc: 0.6631 - val_loss: 1.3933 - val_acc: 0.6008\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.1624 - acc: 0.6280 - val_loss: 1.3953 - val_acc: 0.6613\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1605 - acc: 0.6415 - val_loss: 1.2211 - val_acc: 0.6492\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0657 - acc: 0.6226 - val_loss: 1.2451 - val_acc: 0.6532\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.1014 - acc: 0.6334 - val_loss: 1.2708 - val_acc: 0.6452\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.0481 - acc: 0.6307 - val_loss: 1.3608 - val_acc: 0.6169\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.2102 - acc: 0.6146 - val_loss: 1.2541 - val_acc: 0.6371\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.1236 - acc: 0.6550 - val_loss: 1.3166 - val_acc: 0.6250\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 1.0727 - acc: 0.6550 - val_loss: 1.2564 - val_acc: 0.6371\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0795 - acc: 0.6375 - val_loss: 1.4564 - val_acc: 0.6331\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1627 - acc: 0.6213 - val_loss: 1.2152 - val_acc: 0.6613\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.1160 - acc: 0.6226 - val_loss: 1.2870 - val_acc: 0.6290\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.1196 - acc: 0.6186 - val_loss: 1.1653 - val_acc: 0.6935\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 193us/step - loss: 1.0859 - acc: 0.6415 - val_loss: 1.1455 - val_acc: 0.6935\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.0239 - acc: 0.6442 - val_loss: 1.2082 - val_acc: 0.6371\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.2121 - acc: 0.6253 - val_loss: 1.1415 - val_acc: 0.6774\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0061 - acc: 0.6685 - val_loss: 1.2002 - val_acc: 0.6734\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 1.0451 - acc: 0.6482 - val_loss: 1.2332 - val_acc: 0.6573\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.1153 - acc: 0.6334 - val_loss: 1.2931 - val_acc: 0.6331\n",
      "Epoch 421/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0271 - acc: 0.6442 - val_loss: 1.2041 - val_acc: 0.6734\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9667 - acc: 0.6954 - val_loss: 1.2255 - val_acc: 0.6573\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.0426 - acc: 0.6469 - val_loss: 1.2058 - val_acc: 0.6694\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.0705 - acc: 0.6590 - val_loss: 1.3147 - val_acc: 0.6573\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0925 - acc: 0.6267 - val_loss: 1.2203 - val_acc: 0.6694\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 1.0123 - acc: 0.6577 - val_loss: 1.1365 - val_acc: 0.6976\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9299 - acc: 0.6900 - val_loss: 1.2340 - val_acc: 0.6653\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.3084 - acc: 0.5768 - val_loss: 1.2221 - val_acc: 0.6532\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9676 - acc: 0.6712 - val_loss: 1.1789 - val_acc: 0.6653\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.0486 - acc: 0.6523 - val_loss: 1.2729 - val_acc: 0.6371\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0645 - acc: 0.6456 - val_loss: 1.2260 - val_acc: 0.6613\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0890 - acc: 0.6442 - val_loss: 1.1741 - val_acc: 0.6573\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.0224 - acc: 0.6631 - val_loss: 1.2498 - val_acc: 0.6734\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9857 - acc: 0.6685 - val_loss: 1.3142 - val_acc: 0.6210\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0251 - acc: 0.6523 - val_loss: 1.4119 - val_acc: 0.6290\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.0910 - acc: 0.6496 - val_loss: 1.4088 - val_acc: 0.5766\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.0368 - acc: 0.6402 - val_loss: 1.2660 - val_acc: 0.6371\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.0262 - acc: 0.6604 - val_loss: 1.1892 - val_acc: 0.6613\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0332 - acc: 0.6617 - val_loss: 1.2139 - val_acc: 0.6653\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9884 - acc: 0.6685 - val_loss: 1.1102 - val_acc: 0.6653\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.1109 - acc: 0.6294 - val_loss: 1.2180 - val_acc: 0.6492\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9652 - acc: 0.6833 - val_loss: 1.2294 - val_acc: 0.6573\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9981 - acc: 0.6819 - val_loss: 1.2347 - val_acc: 0.6371\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.9758 - acc: 0.6644 - val_loss: 1.1241 - val_acc: 0.6855\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.1800 - acc: 0.6388 - val_loss: 1.2178 - val_acc: 0.6250\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.9722 - acc: 0.6685 - val_loss: 1.2324 - val_acc: 0.6532\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9976 - acc: 0.6739 - val_loss: 1.1889 - val_acc: 0.6734\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.9801 - acc: 0.6765 - val_loss: 1.3305 - val_acc: 0.6492\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0477 - acc: 0.6482 - val_loss: 1.1482 - val_acc: 0.6694\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9742 - acc: 0.6590 - val_loss: 1.1693 - val_acc: 0.6815\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0756 - acc: 0.6577 - val_loss: 1.4037 - val_acc: 0.5927\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9893 - acc: 0.6671 - val_loss: 1.1375 - val_acc: 0.6371\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0580 - acc: 0.6577 - val_loss: 1.1844 - val_acc: 0.6573\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9449 - acc: 0.6981 - val_loss: 1.1654 - val_acc: 0.6613\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.0416 - acc: 0.6469 - val_loss: 1.1293 - val_acc: 0.6613\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 0s 188us/step - loss: 0.9698 - acc: 0.6954 - val_loss: 1.1561 - val_acc: 0.6895\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9962 - acc: 0.6725 - val_loss: 1.2300 - val_acc: 0.6653\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9635 - acc: 0.6846 - val_loss: 1.2004 - val_acc: 0.6653\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 1.0437 - acc: 0.6469 - val_loss: 1.3472 - val_acc: 0.6331\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9636 - acc: 0.6792 - val_loss: 1.1770 - val_acc: 0.6895\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.8945 - acc: 0.6900 - val_loss: 1.1871 - val_acc: 0.6653\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 1.0508 - acc: 0.6496 - val_loss: 1.2219 - val_acc: 0.6694\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.9831 - acc: 0.6671 - val_loss: 1.1940 - val_acc: 0.6411\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9481 - acc: 0.6604 - val_loss: 1.2192 - val_acc: 0.6613\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9958 - acc: 0.6685 - val_loss: 1.3689 - val_acc: 0.6129\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.1357 - acc: 0.6307 - val_loss: 1.1110 - val_acc: 0.6895\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9712 - acc: 0.6792 - val_loss: 1.1813 - val_acc: 0.6935\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9039 - acc: 0.6995 - val_loss: 1.2801 - val_acc: 0.6734\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9894 - acc: 0.6792 - val_loss: 1.2361 - val_acc: 0.6452\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.9499 - acc: 0.6954 - val_loss: 1.2427 - val_acc: 0.6492\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 1.0007 - acc: 0.6765 - val_loss: 1.1067 - val_acc: 0.7056\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9187 - acc: 0.7102 - val_loss: 1.1803 - val_acc: 0.6895\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0223 - acc: 0.6563 - val_loss: 1.1394 - val_acc: 0.6694\n",
      "Epoch 474/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9903 - acc: 0.6685 - val_loss: 1.1029 - val_acc: 0.6815\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9227 - acc: 0.7008 - val_loss: 1.2031 - val_acc: 0.6532\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 1.0457 - acc: 0.6685 - val_loss: 1.0906 - val_acc: 0.6734\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9597 - acc: 0.6644 - val_loss: 1.2484 - val_acc: 0.6653\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9297 - acc: 0.6873 - val_loss: 1.1237 - val_acc: 0.6935\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.9381 - acc: 0.7022 - val_loss: 1.1391 - val_acc: 0.6855\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 1.0060 - acc: 0.6873 - val_loss: 1.0937 - val_acc: 0.6774\n",
      "Epoch 481/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9271 - acc: 0.6792 - val_loss: 1.1730 - val_acc: 0.6653\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0243 - acc: 0.6685 - val_loss: 1.3248 - val_acc: 0.6250\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9516 - acc: 0.6792 - val_loss: 1.0611 - val_acc: 0.6815\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.9687 - acc: 0.6617 - val_loss: 1.1652 - val_acc: 0.6935\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0249 - acc: 0.6604 - val_loss: 1.1916 - val_acc: 0.6734\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9511 - acc: 0.6819 - val_loss: 1.1659 - val_acc: 0.6774\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9621 - acc: 0.6617 - val_loss: 1.1272 - val_acc: 0.6573\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8676 - acc: 0.7008 - val_loss: 1.2277 - val_acc: 0.6734\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0888 - acc: 0.6509 - val_loss: 1.1376 - val_acc: 0.6976\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9341 - acc: 0.6833 - val_loss: 1.1260 - val_acc: 0.6815\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8272 - acc: 0.7170 - val_loss: 1.1472 - val_acc: 0.6734\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9250 - acc: 0.7062 - val_loss: 1.2083 - val_acc: 0.6573\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.1150 - acc: 0.6536 - val_loss: 1.2714 - val_acc: 0.6411\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.8616 - acc: 0.7129 - val_loss: 1.0939 - val_acc: 0.7137\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9404 - acc: 0.6860 - val_loss: 1.1722 - val_acc: 0.6613\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9275 - acc: 0.6806 - val_loss: 1.1277 - val_acc: 0.6734\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9134 - acc: 0.6860 - val_loss: 1.2075 - val_acc: 0.6774\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9051 - acc: 0.6900 - val_loss: 1.3073 - val_acc: 0.6613\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9098 - acc: 0.7049 - val_loss: 1.0952 - val_acc: 0.7056\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9362 - acc: 0.7022 - val_loss: 1.1073 - val_acc: 0.6935\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8014 - acc: 0.7305 - val_loss: 1.1020 - val_acc: 0.7137\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 0.9739 - acc: 0.6792 - val_loss: 1.1377 - val_acc: 0.6935\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0196 - acc: 0.6698 - val_loss: 1.1000 - val_acc: 0.7056\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9398 - acc: 0.6900 - val_loss: 1.0375 - val_acc: 0.7137\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.8984 - acc: 0.6968 - val_loss: 1.0636 - val_acc: 0.7177\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.9935 - acc: 0.6900 - val_loss: 1.1350 - val_acc: 0.6855\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 0.8490 - acc: 0.7075 - val_loss: 1.0553 - val_acc: 0.7137\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 1.0549 - acc: 0.6712 - val_loss: 1.1049 - val_acc: 0.6976\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8556 - acc: 0.6846 - val_loss: 1.1409 - val_acc: 0.6815\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8482 - acc: 0.7143 - val_loss: 1.2084 - val_acc: 0.6573\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.9951 - acc: 0.6779 - val_loss: 1.1338 - val_acc: 0.6935\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8141 - acc: 0.7278 - val_loss: 1.1022 - val_acc: 0.6935\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8331 - acc: 0.7183 - val_loss: 1.1497 - val_acc: 0.6815\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7675 - acc: 0.7358 - val_loss: 1.2110 - val_acc: 0.6895\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 0.8775 - acc: 0.6765 - val_loss: 1.1802 - val_acc: 0.6815\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8980 - acc: 0.6914 - val_loss: 1.1338 - val_acc: 0.6815\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 1.0296 - acc: 0.6698 - val_loss: 1.1561 - val_acc: 0.6895\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9815 - acc: 0.6779 - val_loss: 1.1315 - val_acc: 0.7016\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9171 - acc: 0.6900 - val_loss: 1.0826 - val_acc: 0.7218\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8702 - acc: 0.7251 - val_loss: 1.2799 - val_acc: 0.6532\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 1.0783 - acc: 0.6348 - val_loss: 1.3303 - val_acc: 0.6411\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9537 - acc: 0.6563 - val_loss: 1.1290 - val_acc: 0.6935\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8585 - acc: 0.7251 - val_loss: 1.0741 - val_acc: 0.6774\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 0.8994 - acc: 0.6900 - val_loss: 1.1388 - val_acc: 0.6855\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8249 - acc: 0.7278 - val_loss: 1.1162 - val_acc: 0.7016\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.8547 - acc: 0.7129 - val_loss: 1.4568 - val_acc: 0.6008\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9559 - acc: 0.6914 - val_loss: 1.0928 - val_acc: 0.7137\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.9078 - acc: 0.7062 - val_loss: 1.0857 - val_acc: 0.7097\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0128 - acc: 0.6631 - val_loss: 1.1342 - val_acc: 0.7097\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8229 - acc: 0.7129 - val_loss: 1.1632 - val_acc: 0.6774\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.9236 - acc: 0.6914 - val_loss: 1.0444 - val_acc: 0.7339\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8444 - acc: 0.7143 - val_loss: 1.0889 - val_acc: 0.7097\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 197us/step - loss: 0.7776 - acc: 0.7547 - val_loss: 1.0970 - val_acc: 0.7097\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.8775 - acc: 0.6995 - val_loss: 1.0994 - val_acc: 0.6774\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8274 - acc: 0.7332 - val_loss: 1.0674 - val_acc: 0.7177\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 1.0878 - acc: 0.6698 - val_loss: 1.0682 - val_acc: 0.6935\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8754 - acc: 0.7089 - val_loss: 1.0384 - val_acc: 0.7137\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7991 - acc: 0.7278 - val_loss: 1.0902 - val_acc: 0.7056\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.8160 - acc: 0.7035 - val_loss: 1.0516 - val_acc: 0.7137\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8972 - acc: 0.6900 - val_loss: 1.1395 - val_acc: 0.6895\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8542 - acc: 0.7116 - val_loss: 1.0916 - val_acc: 0.7218\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7846 - acc: 0.7466 - val_loss: 1.1606 - val_acc: 0.6935\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 1.0468 - acc: 0.6927 - val_loss: 1.0365 - val_acc: 0.7016\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.8884 - acc: 0.7129 - val_loss: 1.0111 - val_acc: 0.7419\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.8999 - acc: 0.6927 - val_loss: 1.0279 - val_acc: 0.7258\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.8880 - acc: 0.7102 - val_loss: 1.0647 - val_acc: 0.7016\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.8470 - acc: 0.7251 - val_loss: 1.1089 - val_acc: 0.7016\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.8458 - acc: 0.7170 - val_loss: 1.2219 - val_acc: 0.6613\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.8548 - acc: 0.7251 - val_loss: 1.0963 - val_acc: 0.7177\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7967 - acc: 0.7493 - val_loss: 1.0806 - val_acc: 0.7298\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.8139 - acc: 0.7143 - val_loss: 1.2952 - val_acc: 0.6371\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.8847 - acc: 0.7156 - val_loss: 1.0268 - val_acc: 0.7298\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.9249 - acc: 0.6981 - val_loss: 1.1177 - val_acc: 0.6976\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.8053 - acc: 0.7480 - val_loss: 1.1888 - val_acc: 0.7056\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.8802 - acc: 0.6954 - val_loss: 1.0945 - val_acc: 0.7056\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.8279 - acc: 0.7210 - val_loss: 1.0795 - val_acc: 0.7177\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8219 - acc: 0.7305 - val_loss: 1.1191 - val_acc: 0.7137\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7803 - acc: 0.7237 - val_loss: 1.0803 - val_acc: 0.7056\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.8310 - acc: 0.7156 - val_loss: 1.0499 - val_acc: 0.7177\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.8052 - acc: 0.7399 - val_loss: 1.0624 - val_acc: 0.7500\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8628 - acc: 0.7224 - val_loss: 1.0775 - val_acc: 0.7218\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8783 - acc: 0.7075 - val_loss: 1.1858 - val_acc: 0.6815\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.8669 - acc: 0.7264 - val_loss: 1.0351 - val_acc: 0.7218\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.8270 - acc: 0.7102 - val_loss: 1.6153 - val_acc: 0.6290\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.9488 - acc: 0.6927 - val_loss: 1.1130 - val_acc: 0.7016\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.8075 - acc: 0.7251 - val_loss: 1.1256 - val_acc: 0.6976\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7679 - acc: 0.7412 - val_loss: 1.0013 - val_acc: 0.7097\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.8087 - acc: 0.7345 - val_loss: 1.0385 - val_acc: 0.7177\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.7520 - acc: 0.7466 - val_loss: 1.0430 - val_acc: 0.7218\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7773 - acc: 0.7668 - val_loss: 1.0749 - val_acc: 0.7298\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.8448 - acc: 0.7062 - val_loss: 1.0296 - val_acc: 0.7258\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.8152 - acc: 0.7291 - val_loss: 1.0938 - val_acc: 0.6855\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.8111 - acc: 0.7332 - val_loss: 1.0673 - val_acc: 0.6976\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.7672 - acc: 0.7372 - val_loss: 1.0096 - val_acc: 0.7137\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.9219 - acc: 0.6779 - val_loss: 1.0008 - val_acc: 0.7218\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.8259 - acc: 0.7197 - val_loss: 1.1141 - val_acc: 0.7056\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 0.7486 - acc: 0.7358 - val_loss: 1.2253 - val_acc: 0.6694\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.9058 - acc: 0.6914 - val_loss: 1.0598 - val_acc: 0.7258\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7949 - acc: 0.7332 - val_loss: 0.9698 - val_acc: 0.7137\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.8417 - acc: 0.6995 - val_loss: 1.1604 - val_acc: 0.6694\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7723 - acc: 0.7439 - val_loss: 1.0867 - val_acc: 0.7137\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.7075 - acc: 0.7574 - val_loss: 1.0426 - val_acc: 0.7258\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.8427 - acc: 0.7183 - val_loss: 1.0361 - val_acc: 0.7218\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.8227 - acc: 0.7399 - val_loss: 1.0107 - val_acc: 0.7177\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.8169 - acc: 0.7210 - val_loss: 1.2693 - val_acc: 0.6694\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.9009 - acc: 0.7035 - val_loss: 1.0779 - val_acc: 0.7177\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7637 - acc: 0.7332 - val_loss: 1.0364 - val_acc: 0.7460\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.8073 - acc: 0.7143 - val_loss: 1.1771 - val_acc: 0.6734\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7787 - acc: 0.7062 - val_loss: 1.0740 - val_acc: 0.7298\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.7855 - acc: 0.7588 - val_loss: 1.0760 - val_acc: 0.6855\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.8710 - acc: 0.7210 - val_loss: 1.1675 - val_acc: 0.6532\n",
      "Epoch 592/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.8314 - acc: 0.7116 - val_loss: 1.0780 - val_acc: 0.7137\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7938 - acc: 0.7561 - val_loss: 1.0465 - val_acc: 0.7016\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7177 - acc: 0.7493 - val_loss: 1.1396 - val_acc: 0.6774\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7760 - acc: 0.7278 - val_loss: 1.0519 - val_acc: 0.7137\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7725 - acc: 0.7278 - val_loss: 1.1112 - val_acc: 0.7097\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.8201 - acc: 0.7345 - val_loss: 1.2553 - val_acc: 0.6653\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.9473 - acc: 0.6833 - val_loss: 1.0097 - val_acc: 0.7298\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7806 - acc: 0.7264 - val_loss: 1.0044 - val_acc: 0.7379\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.7316 - acc: 0.7695 - val_loss: 1.0460 - val_acc: 0.7177\n",
      "Epoch 601/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 0.7418 - acc: 0.7372 - val_loss: 1.1387 - val_acc: 0.7016\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.7394 - acc: 0.7561 - val_loss: 1.0255 - val_acc: 0.7056\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.8344 - acc: 0.7305 - val_loss: 1.0220 - val_acc: 0.7056\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.7985 - acc: 0.7251 - val_loss: 1.0569 - val_acc: 0.6976\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7463 - acc: 0.7439 - val_loss: 0.9877 - val_acc: 0.7298\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.8318 - acc: 0.7156 - val_loss: 1.0322 - val_acc: 0.7177\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7817 - acc: 0.7466 - val_loss: 1.0481 - val_acc: 0.7056\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7679 - acc: 0.7480 - val_loss: 0.9642 - val_acc: 0.7177\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.7971 - acc: 0.7385 - val_loss: 1.0484 - val_acc: 0.6935\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7594 - acc: 0.7466 - val_loss: 1.1988 - val_acc: 0.6774\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7912 - acc: 0.7385 - val_loss: 1.0798 - val_acc: 0.7177\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.7164 - acc: 0.7493 - val_loss: 1.0460 - val_acc: 0.7137\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.8267 - acc: 0.7399 - val_loss: 0.9628 - val_acc: 0.7218\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7511 - acc: 0.7547 - val_loss: 1.0258 - val_acc: 0.7379\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.8559 - acc: 0.7075 - val_loss: 0.9541 - val_acc: 0.7460\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7807 - acc: 0.7399 - val_loss: 1.0600 - val_acc: 0.6935\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7825 - acc: 0.7264 - val_loss: 1.0763 - val_acc: 0.7177\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 0.7594 - acc: 0.7520 - val_loss: 1.1259 - val_acc: 0.7137\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.8667 - acc: 0.7345 - val_loss: 1.0348 - val_acc: 0.7097\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7117 - acc: 0.7520 - val_loss: 1.0110 - val_acc: 0.7298\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7649 - acc: 0.7507 - val_loss: 1.1026 - val_acc: 0.6855\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 0s 190us/step - loss: 0.7122 - acc: 0.7466 - val_loss: 1.0504 - val_acc: 0.7056\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.8306 - acc: 0.7466 - val_loss: 1.1352 - val_acc: 0.6815\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.7060 - acc: 0.7655 - val_loss: 1.0451 - val_acc: 0.7056\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.7534 - acc: 0.7453 - val_loss: 1.0617 - val_acc: 0.6935\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7520 - acc: 0.7493 - val_loss: 1.0115 - val_acc: 0.7339\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7634 - acc: 0.7278 - val_loss: 1.0730 - val_acc: 0.7137\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.7637 - acc: 0.7372 - val_loss: 1.1424 - val_acc: 0.6855\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.8426 - acc: 0.7305 - val_loss: 0.9843 - val_acc: 0.7218\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6814 - acc: 0.7682 - val_loss: 0.9735 - val_acc: 0.7339\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6965 - acc: 0.7588 - val_loss: 1.0386 - val_acc: 0.7298\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7902 - acc: 0.7237 - val_loss: 1.0115 - val_acc: 0.7177\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.7454 - acc: 0.7763 - val_loss: 0.9626 - val_acc: 0.7460\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7318 - acc: 0.7412 - val_loss: 1.0026 - val_acc: 0.7419\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6730 - acc: 0.7682 - val_loss: 1.0115 - val_acc: 0.7218\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7312 - acc: 0.7480 - val_loss: 1.1978 - val_acc: 0.6734\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7749 - acc: 0.7345 - val_loss: 1.0252 - val_acc: 0.7298\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7861 - acc: 0.7210 - val_loss: 0.9847 - val_acc: 0.7379\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7213 - acc: 0.7466 - val_loss: 1.0997 - val_acc: 0.7258\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.8453 - acc: 0.7035 - val_loss: 0.9694 - val_acc: 0.7460\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.7569 - acc: 0.7426 - val_loss: 0.9824 - val_acc: 0.7419\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6288 - acc: 0.7978 - val_loss: 0.9580 - val_acc: 0.7460\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.7718 - acc: 0.7305 - val_loss: 1.2823 - val_acc: 0.6694\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.7645 - acc: 0.7493 - val_loss: 0.9971 - val_acc: 0.7298\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.7116 - acc: 0.7520 - val_loss: 0.9828 - val_acc: 0.7258\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 0.6380 - acc: 0.7898 - val_loss: 1.0279 - val_acc: 0.7379\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.7489 - acc: 0.7358 - val_loss: 1.0513 - val_acc: 0.7298\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.8078 - acc: 0.7251 - val_loss: 1.0165 - val_acc: 0.7097\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.8230 - acc: 0.7372 - val_loss: 1.2041 - val_acc: 0.7016\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7128 - acc: 0.7372 - val_loss: 0.9989 - val_acc: 0.7500\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 211us/step - loss: 0.7631 - acc: 0.7561 - val_loss: 1.0941 - val_acc: 0.7137\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7630 - acc: 0.7278 - val_loss: 1.1158 - val_acc: 0.7177\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6801 - acc: 0.7925 - val_loss: 1.1510 - val_acc: 0.7218\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7062 - acc: 0.7655 - val_loss: 1.0631 - val_acc: 0.7258\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.8700 - acc: 0.7264 - val_loss: 1.0047 - val_acc: 0.7500\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7204 - acc: 0.7453 - val_loss: 1.0789 - val_acc: 0.7056\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.6642 - acc: 0.7682 - val_loss: 1.0621 - val_acc: 0.7258\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.7107 - acc: 0.7682 - val_loss: 1.0183 - val_acc: 0.7218\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7869 - acc: 0.7426 - val_loss: 0.9806 - val_acc: 0.7460\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6685 - acc: 0.7898 - val_loss: 1.0415 - val_acc: 0.7298\n",
      "Epoch 661/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.6783 - acc: 0.7776 - val_loss: 1.0609 - val_acc: 0.7258\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7090 - acc: 0.7642 - val_loss: 1.2173 - val_acc: 0.6774\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.7102 - acc: 0.7642 - val_loss: 1.1204 - val_acc: 0.7258\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7167 - acc: 0.7655 - val_loss: 0.9905 - val_acc: 0.7419\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7340 - acc: 0.7682 - val_loss: 1.0542 - val_acc: 0.7016\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7373 - acc: 0.7466 - val_loss: 1.0226 - val_acc: 0.7540\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.7033 - acc: 0.7547 - val_loss: 1.1501 - val_acc: 0.7016\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7367 - acc: 0.7561 - val_loss: 1.1121 - val_acc: 0.7137\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7339 - acc: 0.7588 - val_loss: 1.0465 - val_acc: 0.7218\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6500 - acc: 0.7763 - val_loss: 1.0121 - val_acc: 0.7339\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7528 - acc: 0.7776 - val_loss: 1.1461 - val_acc: 0.7056\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7596 - acc: 0.7345 - val_loss: 0.9819 - val_acc: 0.7581\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.7008 - acc: 0.7682 - val_loss: 0.9521 - val_acc: 0.7540\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7133 - acc: 0.7655 - val_loss: 1.0331 - val_acc: 0.7016\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7260 - acc: 0.7682 - val_loss: 1.1499 - val_acc: 0.6855\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6826 - acc: 0.7844 - val_loss: 0.9608 - val_acc: 0.7661\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7293 - acc: 0.7493 - val_loss: 0.9450 - val_acc: 0.7460\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6803 - acc: 0.7547 - val_loss: 0.9872 - val_acc: 0.7661\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7480 - acc: 0.7561 - val_loss: 1.1040 - val_acc: 0.6976\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7627 - acc: 0.7318 - val_loss: 0.9572 - val_acc: 0.7581\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6741 - acc: 0.7722 - val_loss: 1.0122 - val_acc: 0.7379\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.7505 - acc: 0.7642 - val_loss: 0.9454 - val_acc: 0.7621\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7053 - acc: 0.7628 - val_loss: 1.0983 - val_acc: 0.7137\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6500 - acc: 0.7803 - val_loss: 1.1868 - val_acc: 0.6895\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7026 - acc: 0.7615 - val_loss: 1.0531 - val_acc: 0.7500\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.7170 - acc: 0.7574 - val_loss: 1.0686 - val_acc: 0.7460\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7918 - acc: 0.7426 - val_loss: 1.0369 - val_acc: 0.7258\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6376 - acc: 0.7763 - val_loss: 0.8924 - val_acc: 0.7702\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7469 - acc: 0.7507 - val_loss: 0.8676 - val_acc: 0.7742\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6878 - acc: 0.7682 - val_loss: 0.8868 - val_acc: 0.7782\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6654 - acc: 0.7803 - val_loss: 0.9493 - val_acc: 0.7823\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7142 - acc: 0.7709 - val_loss: 0.9305 - val_acc: 0.7298\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.6433 - acc: 0.7695 - val_loss: 1.0215 - val_acc: 0.7258\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.8180 - acc: 0.7345 - val_loss: 1.2247 - val_acc: 0.6694\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7392 - acc: 0.7493 - val_loss: 0.9325 - val_acc: 0.7460\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7442 - acc: 0.7547 - val_loss: 0.9644 - val_acc: 0.7460\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.7061 - acc: 0.7561 - val_loss: 1.0517 - val_acc: 0.7540\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7450 - acc: 0.7547 - val_loss: 0.9695 - val_acc: 0.7419\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6902 - acc: 0.7547 - val_loss: 1.0559 - val_acc: 0.7097\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5833 - acc: 0.7951 - val_loss: 1.0754 - val_acc: 0.7258\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5904 - acc: 0.8221 - val_loss: 0.9279 - val_acc: 0.7581\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7657 - acc: 0.7520 - val_loss: 0.9225 - val_acc: 0.7500\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.5761 - acc: 0.7951 - val_loss: 0.8979 - val_acc: 0.7500\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.6788 - acc: 0.7628 - val_loss: 0.9334 - val_acc: 0.7621\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6575 - acc: 0.7722 - val_loss: 1.0727 - val_acc: 0.7339\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6200 - acc: 0.7871 - val_loss: 1.1112 - val_acc: 0.7218\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.7234 - acc: 0.7507 - val_loss: 0.9807 - val_acc: 0.7339\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7186 - acc: 0.7466 - val_loss: 0.9661 - val_acc: 0.7379\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.7197 - acc: 0.7426 - val_loss: 1.0961 - val_acc: 0.6815\n",
      "Epoch 710/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7534 - acc: 0.7412 - val_loss: 1.0448 - val_acc: 0.7298\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6161 - acc: 0.7884 - val_loss: 0.9872 - val_acc: 0.7419\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6755 - acc: 0.7709 - val_loss: 0.8939 - val_acc: 0.7540\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.7223 - acc: 0.7925 - val_loss: 1.1111 - val_acc: 0.6935\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7086 - acc: 0.7547 - val_loss: 0.9534 - val_acc: 0.7379\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.6564 - acc: 0.7749 - val_loss: 0.9605 - val_acc: 0.7460\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6501 - acc: 0.7803 - val_loss: 0.9667 - val_acc: 0.7621\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6310 - acc: 0.7844 - val_loss: 1.0198 - val_acc: 0.7419\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7898 - acc: 0.7453 - val_loss: 1.0694 - val_acc: 0.6895\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7543 - acc: 0.7642 - val_loss: 0.8949 - val_acc: 0.7258\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.6696 - acc: 0.7830 - val_loss: 0.9763 - val_acc: 0.7298\n",
      "Epoch 721/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6342 - acc: 0.7830 - val_loss: 0.9301 - val_acc: 0.7218\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6769 - acc: 0.7844 - val_loss: 0.9973 - val_acc: 0.7258\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6543 - acc: 0.7722 - val_loss: 0.9776 - val_acc: 0.7339\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6930 - acc: 0.7803 - val_loss: 0.9543 - val_acc: 0.7339\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6354 - acc: 0.7830 - val_loss: 1.0274 - val_acc: 0.7177\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.6818 - acc: 0.7790 - val_loss: 1.1063 - val_acc: 0.7177\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.7259 - acc: 0.7574 - val_loss: 1.0324 - val_acc: 0.7339\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6461 - acc: 0.7803 - val_loss: 1.0302 - val_acc: 0.7177\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6870 - acc: 0.7709 - val_loss: 1.0126 - val_acc: 0.7218\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6568 - acc: 0.7925 - val_loss: 0.8842 - val_acc: 0.7419\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6202 - acc: 0.7736 - val_loss: 1.3311 - val_acc: 0.6371\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6879 - acc: 0.7763 - val_loss: 1.0713 - val_acc: 0.7460\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.7060 - acc: 0.7722 - val_loss: 0.9417 - val_acc: 0.7419\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.6999 - acc: 0.7871 - val_loss: 0.9549 - val_acc: 0.7419\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6165 - acc: 0.7938 - val_loss: 0.9405 - val_acc: 0.7621\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6679 - acc: 0.7736 - val_loss: 1.0359 - val_acc: 0.7379\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7138 - acc: 0.7574 - val_loss: 1.0535 - val_acc: 0.7258\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6668 - acc: 0.7898 - val_loss: 0.9494 - val_acc: 0.7177\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6807 - acc: 0.7695 - val_loss: 0.9914 - val_acc: 0.7339\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5971 - acc: 0.7925 - val_loss: 0.9407 - val_acc: 0.7581\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6350 - acc: 0.7830 - val_loss: 0.9600 - val_acc: 0.7702\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7081 - acc: 0.7709 - val_loss: 0.9115 - val_acc: 0.7460\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.7375 - acc: 0.7601 - val_loss: 0.9609 - val_acc: 0.7661\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6498 - acc: 0.7749 - val_loss: 0.9952 - val_acc: 0.7621\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6697 - acc: 0.7790 - val_loss: 0.9666 - val_acc: 0.7339\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5953 - acc: 0.7871 - val_loss: 1.0013 - val_acc: 0.7460\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6491 - acc: 0.7857 - val_loss: 1.1568 - val_acc: 0.7016\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6757 - acc: 0.7588 - val_loss: 0.9957 - val_acc: 0.7540\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6567 - acc: 0.7682 - val_loss: 0.9962 - val_acc: 0.7379\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6620 - acc: 0.7736 - val_loss: 1.0716 - val_acc: 0.7177\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7109 - acc: 0.7453 - val_loss: 0.9517 - val_acc: 0.7419\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.6442 - acc: 0.7817 - val_loss: 1.0796 - val_acc: 0.7218\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6549 - acc: 0.7830 - val_loss: 1.1876 - val_acc: 0.7056\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.6251 - acc: 0.7844 - val_loss: 1.0503 - val_acc: 0.7298\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6469 - acc: 0.7668 - val_loss: 0.9684 - val_acc: 0.7621\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6596 - acc: 0.7817 - val_loss: 0.9726 - val_acc: 0.7218\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6231 - acc: 0.7844 - val_loss: 0.9361 - val_acc: 0.7419\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6285 - acc: 0.7709 - val_loss: 1.0874 - val_acc: 0.7056\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6802 - acc: 0.7709 - val_loss: 0.9973 - val_acc: 0.7298\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6352 - acc: 0.7898 - val_loss: 0.9709 - val_acc: 0.7460\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6496 - acc: 0.7763 - val_loss: 0.9384 - val_acc: 0.7379\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6500 - acc: 0.7776 - val_loss: 1.1907 - val_acc: 0.6855\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6277 - acc: 0.7871 - val_loss: 0.9520 - val_acc: 0.7500\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6550 - acc: 0.7817 - val_loss: 0.9505 - val_acc: 0.7661\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6073 - acc: 0.8059 - val_loss: 0.9169 - val_acc: 0.7379\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.6236 - acc: 0.8059 - val_loss: 1.0679 - val_acc: 0.7177\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6604 - acc: 0.7722 - val_loss: 0.9083 - val_acc: 0.7419\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6059 - acc: 0.7884 - val_loss: 0.9423 - val_acc: 0.7702\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 197us/step - loss: 0.7196 - acc: 0.7574 - val_loss: 0.9280 - val_acc: 0.7379\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 0s 189us/step - loss: 0.7191 - acc: 0.7776 - val_loss: 0.9526 - val_acc: 0.7581\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.6581 - acc: 0.7898 - val_loss: 1.1030 - val_acc: 0.7177\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5654 - acc: 0.8140 - val_loss: 1.0178 - val_acc: 0.7379\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6149 - acc: 0.8046 - val_loss: 0.9578 - val_acc: 0.7460\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.6446 - acc: 0.7695 - val_loss: 0.9521 - val_acc: 0.7298\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.7117 - acc: 0.7574 - val_loss: 1.0085 - val_acc: 0.7379\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5707 - acc: 0.8059 - val_loss: 0.9431 - val_acc: 0.7298\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 0s 195us/step - loss: 0.6317 - acc: 0.8005 - val_loss: 0.8811 - val_acc: 0.7500\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.9047 - acc: 0.7075 - val_loss: 0.9654 - val_acc: 0.7419\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6658 - acc: 0.7871 - val_loss: 0.8872 - val_acc: 0.7500\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6027 - acc: 0.8019 - val_loss: 0.9042 - val_acc: 0.7540\n",
      "Epoch 781/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5767 - acc: 0.8059 - val_loss: 0.9977 - val_acc: 0.7702\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5666 - acc: 0.8140 - val_loss: 0.9936 - val_acc: 0.7500\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6326 - acc: 0.7951 - val_loss: 0.8516 - val_acc: 0.7661\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6940 - acc: 0.7682 - val_loss: 0.8889 - val_acc: 0.7581\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6163 - acc: 0.8019 - val_loss: 1.0955 - val_acc: 0.7177\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6180 - acc: 0.8032 - val_loss: 0.9764 - val_acc: 0.7419\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6962 - acc: 0.7628 - val_loss: 0.9446 - val_acc: 0.7540\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5349 - acc: 0.8086 - val_loss: 0.9500 - val_acc: 0.7661\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6254 - acc: 0.7871 - val_loss: 0.9546 - val_acc: 0.7419\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6171 - acc: 0.7951 - val_loss: 0.9884 - val_acc: 0.7419\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6875 - acc: 0.7722 - val_loss: 0.9440 - val_acc: 0.7621\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6240 - acc: 0.7736 - val_loss: 0.9530 - val_acc: 0.7863\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.7168 - acc: 0.7722 - val_loss: 0.9499 - val_acc: 0.7500\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.4883 - acc: 0.8235 - val_loss: 0.9840 - val_acc: 0.7540\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6289 - acc: 0.7978 - val_loss: 1.0238 - val_acc: 0.7419\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6034 - acc: 0.8046 - val_loss: 0.9987 - val_acc: 0.7540\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6593 - acc: 0.7520 - val_loss: 0.9432 - val_acc: 0.7419\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5326 - acc: 0.8221 - val_loss: 0.9398 - val_acc: 0.7540\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.8313 - acc: 0.7426 - val_loss: 0.9304 - val_acc: 0.7419\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6690 - acc: 0.7884 - val_loss: 0.8859 - val_acc: 0.7540\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6506 - acc: 0.7790 - val_loss: 0.9099 - val_acc: 0.7621\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6825 - acc: 0.7790 - val_loss: 0.8587 - val_acc: 0.7742\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5970 - acc: 0.7938 - val_loss: 0.9326 - val_acc: 0.7379\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6124 - acc: 0.7871 - val_loss: 0.9835 - val_acc: 0.7379\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7032 - acc: 0.7803 - val_loss: 0.9571 - val_acc: 0.7379\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5768 - acc: 0.8005 - val_loss: 0.9934 - val_acc: 0.7581\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5896 - acc: 0.8127 - val_loss: 0.9903 - val_acc: 0.7581\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5589 - acc: 0.7898 - val_loss: 0.9645 - val_acc: 0.7621\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5609 - acc: 0.7978 - val_loss: 0.9946 - val_acc: 0.7540\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.6304 - acc: 0.7817 - val_loss: 0.9676 - val_acc: 0.7500\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.6057 - acc: 0.7898 - val_loss: 1.1080 - val_acc: 0.7298\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.7666 - acc: 0.7749 - val_loss: 1.0035 - val_acc: 0.7258\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 0s 214us/step - loss: 0.5514 - acc: 0.8127 - val_loss: 1.0441 - val_acc: 0.7298\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5155 - acc: 0.8302 - val_loss: 1.0855 - val_acc: 0.7581\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5774 - acc: 0.8073 - val_loss: 1.0167 - val_acc: 0.7419\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.6787 - acc: 0.7844 - val_loss: 1.0591 - val_acc: 0.7379\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6127 - acc: 0.7938 - val_loss: 0.9621 - val_acc: 0.7258\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5209 - acc: 0.8208 - val_loss: 1.0579 - val_acc: 0.7298\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5392 - acc: 0.8140 - val_loss: 0.9181 - val_acc: 0.7661\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5505 - acc: 0.8221 - val_loss: 0.9547 - val_acc: 0.7379\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.7820 - acc: 0.7588 - val_loss: 0.9825 - val_acc: 0.7460\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 0s 213us/step - loss: 0.5707 - acc: 0.7951 - val_loss: 0.9179 - val_acc: 0.7540\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5766 - acc: 0.8032 - val_loss: 0.9868 - val_acc: 0.7500\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6273 - acc: 0.7817 - val_loss: 1.0534 - val_acc: 0.7177\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 0s 213us/step - loss: 0.6426 - acc: 0.7736 - val_loss: 0.9802 - val_acc: 0.7460\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.5732 - acc: 0.8221 - val_loss: 0.8942 - val_acc: 0.7419\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.7096 - acc: 0.7561 - val_loss: 0.8572 - val_acc: 0.7460\n",
      "Epoch 828/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.5661 - acc: 0.8086 - val_loss: 0.8884 - val_acc: 0.7621\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6234 - acc: 0.7951 - val_loss: 0.9671 - val_acc: 0.7500\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5933 - acc: 0.8127 - val_loss: 0.9618 - val_acc: 0.7581\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6264 - acc: 0.7938 - val_loss: 1.3051 - val_acc: 0.6855\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7334 - acc: 0.7749 - val_loss: 0.8386 - val_acc: 0.7742\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5419 - acc: 0.8140 - val_loss: 0.9620 - val_acc: 0.7581\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6602 - acc: 0.7911 - val_loss: 0.8900 - val_acc: 0.7702\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 0s 213us/step - loss: 0.6270 - acc: 0.7830 - val_loss: 0.9683 - val_acc: 0.7540\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6096 - acc: 0.7965 - val_loss: 0.9082 - val_acc: 0.7661\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6060 - acc: 0.7965 - val_loss: 0.8829 - val_acc: 0.7742\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.5474 - acc: 0.8248 - val_loss: 0.9150 - val_acc: 0.7782\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5093 - acc: 0.8235 - val_loss: 0.9122 - val_acc: 0.7742\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6181 - acc: 0.8086 - val_loss: 0.9500 - val_acc: 0.7702\n",
      "Epoch 841/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5900 - acc: 0.8167 - val_loss: 1.1074 - val_acc: 0.7137\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.5765 - acc: 0.8046 - val_loss: 0.8993 - val_acc: 0.7661\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5716 - acc: 0.7978 - val_loss: 0.9717 - val_acc: 0.7581\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5737 - acc: 0.8154 - val_loss: 1.1522 - val_acc: 0.7298\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.7185 - acc: 0.7668 - val_loss: 0.9083 - val_acc: 0.7702\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5707 - acc: 0.8073 - val_loss: 0.8997 - val_acc: 0.7581\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5064 - acc: 0.8275 - val_loss: 0.8576 - val_acc: 0.7823\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6368 - acc: 0.7871 - val_loss: 1.4994 - val_acc: 0.6532\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.7360 - acc: 0.7561 - val_loss: 0.9196 - val_acc: 0.7621\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.5869 - acc: 0.8208 - val_loss: 0.9404 - val_acc: 0.7621\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5559 - acc: 0.8059 - val_loss: 0.9456 - val_acc: 0.7540\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.6092 - acc: 0.7992 - val_loss: 0.8951 - val_acc: 0.7742\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5786 - acc: 0.8167 - val_loss: 0.8789 - val_acc: 0.7339\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5783 - acc: 0.7884 - val_loss: 0.9314 - val_acc: 0.7621\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.7246 - acc: 0.7898 - val_loss: 0.8240 - val_acc: 0.7823\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5610 - acc: 0.8302 - val_loss: 0.9009 - val_acc: 0.7581\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5411 - acc: 0.8113 - val_loss: 0.9621 - val_acc: 0.7460\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5860 - acc: 0.8315 - val_loss: 0.9720 - val_acc: 0.7581\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6345 - acc: 0.7844 - val_loss: 0.9038 - val_acc: 0.7419\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6514 - acc: 0.7992 - val_loss: 1.1629 - val_acc: 0.7097\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5641 - acc: 0.8005 - val_loss: 0.9471 - val_acc: 0.7702\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 0s 214us/step - loss: 0.5680 - acc: 0.8261 - val_loss: 0.8722 - val_acc: 0.7621\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6448 - acc: 0.7965 - val_loss: 0.8920 - val_acc: 0.7540\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6102 - acc: 0.7951 - val_loss: 0.8666 - val_acc: 0.7984\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.5686 - acc: 0.8127 - val_loss: 1.0727 - val_acc: 0.7056\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.5976 - acc: 0.8032 - val_loss: 0.8472 - val_acc: 0.7702\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6207 - acc: 0.7992 - val_loss: 0.8813 - val_acc: 0.7500\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6227 - acc: 0.7884 - val_loss: 1.1024 - val_acc: 0.7298\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.5657 - acc: 0.8059 - val_loss: 0.9726 - val_acc: 0.7419\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6064 - acc: 0.7978 - val_loss: 0.9572 - val_acc: 0.7621\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5922 - acc: 0.8127 - val_loss: 0.9636 - val_acc: 0.7661\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6093 - acc: 0.8059 - val_loss: 0.9616 - val_acc: 0.7621\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5261 - acc: 0.8235 - val_loss: 0.9218 - val_acc: 0.7823\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 0s 193us/step - loss: 0.6061 - acc: 0.7925 - val_loss: 0.9821 - val_acc: 0.7460\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5945 - acc: 0.8100 - val_loss: 0.8843 - val_acc: 0.7702\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5422 - acc: 0.8154 - val_loss: 0.9571 - val_acc: 0.7661\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6182 - acc: 0.7992 - val_loss: 0.9816 - val_acc: 0.7540\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5790 - acc: 0.8208 - val_loss: 0.8684 - val_acc: 0.7581\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5271 - acc: 0.8181 - val_loss: 0.8858 - val_acc: 0.7823\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.6597 - acc: 0.7668 - val_loss: 0.8896 - val_acc: 0.7621\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5258 - acc: 0.8248 - val_loss: 0.9474 - val_acc: 0.7540\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5117 - acc: 0.8356 - val_loss: 1.0849 - val_acc: 0.7540\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5434 - acc: 0.8181 - val_loss: 1.0496 - val_acc: 0.7460\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5685 - acc: 0.8046 - val_loss: 0.9284 - val_acc: 0.7621\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5588 - acc: 0.8073 - val_loss: 0.9352 - val_acc: 0.7823\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5594 - acc: 0.8032 - val_loss: 0.9333 - val_acc: 0.7500\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 198us/step - loss: 0.6351 - acc: 0.7965 - val_loss: 0.9892 - val_acc: 0.7419\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6363 - acc: 0.7925 - val_loss: 0.9426 - val_acc: 0.7500\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5924 - acc: 0.8167 - val_loss: 0.8997 - val_acc: 0.7661\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5641 - acc: 0.8046 - val_loss: 0.9175 - val_acc: 0.7621\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5144 - acc: 0.8288 - val_loss: 0.9050 - val_acc: 0.7540\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5863 - acc: 0.7938 - val_loss: 1.0070 - val_acc: 0.7379\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5184 - acc: 0.8261 - val_loss: 0.8648 - val_acc: 0.7863\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5998 - acc: 0.8100 - val_loss: 0.9589 - val_acc: 0.7581\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6107 - acc: 0.8194 - val_loss: 0.8806 - val_acc: 0.7702\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5095 - acc: 0.8302 - val_loss: 1.0080 - val_acc: 0.7460\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6186 - acc: 0.7844 - val_loss: 0.8915 - val_acc: 0.7540\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5973 - acc: 0.8046 - val_loss: 0.9878 - val_acc: 0.7581\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5249 - acc: 0.8059 - val_loss: 0.9637 - val_acc: 0.7702\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5636 - acc: 0.8100 - val_loss: 1.0564 - val_acc: 0.7419\n",
      "Epoch 901/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5871 - acc: 0.8261 - val_loss: 0.9393 - val_acc: 0.7621\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5503 - acc: 0.7965 - val_loss: 1.0204 - val_acc: 0.7581\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5316 - acc: 0.8208 - val_loss: 0.9275 - val_acc: 0.7702\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5856 - acc: 0.8046 - val_loss: 1.0247 - val_acc: 0.7460\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5033 - acc: 0.8140 - val_loss: 1.0067 - val_acc: 0.7460\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5282 - acc: 0.8221 - val_loss: 0.8613 - val_acc: 0.7782\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.6810 - acc: 0.7668 - val_loss: 1.0327 - val_acc: 0.7581\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5646 - acc: 0.8046 - val_loss: 1.1194 - val_acc: 0.7097\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5862 - acc: 0.8019 - val_loss: 0.9523 - val_acc: 0.7339\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.5509 - acc: 0.8113 - val_loss: 0.8933 - val_acc: 0.7379\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.6187 - acc: 0.7978 - val_loss: 0.9683 - val_acc: 0.7339\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5335 - acc: 0.8181 - val_loss: 0.8445 - val_acc: 0.7661\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 0s 214us/step - loss: 0.7209 - acc: 0.7817 - val_loss: 1.0167 - val_acc: 0.7298\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5650 - acc: 0.8140 - val_loss: 0.9662 - val_acc: 0.7379\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5083 - acc: 0.8302 - val_loss: 1.0272 - val_acc: 0.7460\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5846 - acc: 0.8154 - val_loss: 0.9681 - val_acc: 0.7460\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5137 - acc: 0.8275 - val_loss: 1.0033 - val_acc: 0.7419\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.6244 - acc: 0.7978 - val_loss: 1.0013 - val_acc: 0.7540\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5109 - acc: 0.8356 - val_loss: 0.9397 - val_acc: 0.7702\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6662 - acc: 0.8019 - val_loss: 0.9075 - val_acc: 0.7782\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5193 - acc: 0.8208 - val_loss: 0.9917 - val_acc: 0.7702\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5301 - acc: 0.8140 - val_loss: 0.9400 - val_acc: 0.7460\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5675 - acc: 0.8073 - val_loss: 0.9908 - val_acc: 0.7379\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 0s 196us/step - loss: 0.5533 - acc: 0.8194 - val_loss: 1.0335 - val_acc: 0.7339\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.5482 - acc: 0.8194 - val_loss: 0.9325 - val_acc: 0.7540\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.5713 - acc: 0.7925 - val_loss: 1.1101 - val_acc: 0.7016\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5950 - acc: 0.7951 - val_loss: 0.9180 - val_acc: 0.7581\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5690 - acc: 0.8396 - val_loss: 0.9635 - val_acc: 0.7339\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5438 - acc: 0.8194 - val_loss: 0.9327 - val_acc: 0.7500\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5626 - acc: 0.8073 - val_loss: 0.9005 - val_acc: 0.7460\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5595 - acc: 0.7978 - val_loss: 0.9232 - val_acc: 0.7742\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5848 - acc: 0.8019 - val_loss: 0.8999 - val_acc: 0.7621\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.6064 - acc: 0.7776 - val_loss: 1.0044 - val_acc: 0.7460\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.4865 - acc: 0.8342 - val_loss: 0.9194 - val_acc: 0.7702\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5407 - acc: 0.8248 - val_loss: 0.9582 - val_acc: 0.7460\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5937 - acc: 0.8100 - val_loss: 0.9185 - val_acc: 0.7661\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 0s 192us/step - loss: 0.5577 - acc: 0.8140 - val_loss: 1.0166 - val_acc: 0.7298\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5352 - acc: 0.8181 - val_loss: 0.9067 - val_acc: 0.7702\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.4900 - acc: 0.8248 - val_loss: 0.9233 - val_acc: 0.7782\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.4984 - acc: 0.8315 - val_loss: 1.0386 - val_acc: 0.7621\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5444 - acc: 0.8167 - val_loss: 1.0426 - val_acc: 0.7540\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.6037 - acc: 0.8194 - val_loss: 0.8864 - val_acc: 0.7581\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.4685 - acc: 0.8410 - val_loss: 0.9523 - val_acc: 0.7581\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.6593 - acc: 0.8248 - val_loss: 0.9755 - val_acc: 0.7621\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.4965 - acc: 0.8356 - val_loss: 0.9952 - val_acc: 0.7621\n",
      "Epoch 946/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5157 - acc: 0.8288 - val_loss: 1.1547 - val_acc: 0.7258\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5493 - acc: 0.8113 - val_loss: 0.9885 - val_acc: 0.7379\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5922 - acc: 0.7951 - val_loss: 0.8864 - val_acc: 0.7661\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.6401 - acc: 0.8032 - val_loss: 0.8662 - val_acc: 0.7702\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5019 - acc: 0.8369 - val_loss: 0.8906 - val_acc: 0.7621\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5324 - acc: 0.8288 - val_loss: 0.9629 - val_acc: 0.7782\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5589 - acc: 0.8005 - val_loss: 1.0023 - val_acc: 0.7661\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.5676 - acc: 0.8208 - val_loss: 1.0280 - val_acc: 0.7540\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5580 - acc: 0.8208 - val_loss: 0.9246 - val_acc: 0.7379\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5251 - acc: 0.8396 - val_loss: 0.9141 - val_acc: 0.7500\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5045 - acc: 0.8248 - val_loss: 0.8980 - val_acc: 0.7460\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.4878 - acc: 0.8396 - val_loss: 1.0630 - val_acc: 0.7298\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 0s 208us/step - loss: 0.5898 - acc: 0.8073 - val_loss: 0.8545 - val_acc: 0.7460\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5200 - acc: 0.8342 - val_loss: 0.9020 - val_acc: 0.7661\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5391 - acc: 0.8113 - val_loss: 0.9120 - val_acc: 0.7702\n",
      "Epoch 961/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.5239 - acc: 0.8154 - val_loss: 0.9158 - val_acc: 0.7540\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 0s 209us/step - loss: 0.5535 - acc: 0.8194 - val_loss: 0.9213 - val_acc: 0.7863\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5316 - acc: 0.8208 - val_loss: 0.8586 - val_acc: 0.7621\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5502 - acc: 0.8235 - val_loss: 0.9552 - val_acc: 0.7742\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5819 - acc: 0.8194 - val_loss: 0.8460 - val_acc: 0.7581\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.5269 - acc: 0.8221 - val_loss: 0.9325 - val_acc: 0.7581\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 0s 194us/step - loss: 0.5677 - acc: 0.7992 - val_loss: 0.9971 - val_acc: 0.7661\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5506 - acc: 0.8100 - val_loss: 0.9333 - val_acc: 0.7621\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.6237 - acc: 0.8127 - val_loss: 0.8802 - val_acc: 0.7702\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5236 - acc: 0.8181 - val_loss: 0.9385 - val_acc: 0.7339\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5233 - acc: 0.8369 - val_loss: 0.9564 - val_acc: 0.7460\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5289 - acc: 0.8235 - val_loss: 0.9073 - val_acc: 0.7621\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.4715 - acc: 0.8464 - val_loss: 1.0289 - val_acc: 0.7540\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.6411 - acc: 0.8046 - val_loss: 0.8643 - val_acc: 0.7540\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.5067 - acc: 0.8181 - val_loss: 0.8968 - val_acc: 0.7661\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.5536 - acc: 0.8127 - val_loss: 0.9182 - val_acc: 0.7581\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 0s 200us/step - loss: 0.4966 - acc: 0.8275 - val_loss: 0.9251 - val_acc: 0.7540\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.6313 - acc: 0.8127 - val_loss: 0.8981 - val_acc: 0.7621\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 0s 197us/step - loss: 0.4970 - acc: 0.8383 - val_loss: 0.9724 - val_acc: 0.7742\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 0s 213us/step - loss: 0.5797 - acc: 0.8046 - val_loss: 0.9562 - val_acc: 0.7419\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5811 - acc: 0.8019 - val_loss: 0.9397 - val_acc: 0.7621\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.5486 - acc: 0.8167 - val_loss: 0.9091 - val_acc: 0.7581\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 0s 199us/step - loss: 0.6164 - acc: 0.7938 - val_loss: 0.9422 - val_acc: 0.7621\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 0s 204us/step - loss: 0.5336 - acc: 0.8275 - val_loss: 0.9017 - val_acc: 0.7581\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 0s 201us/step - loss: 0.6217 - acc: 0.7978 - val_loss: 0.9093 - val_acc: 0.7621\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 0s 212us/step - loss: 0.5390 - acc: 0.8261 - val_loss: 0.8652 - val_acc: 0.7742\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 0s 210us/step - loss: 0.5022 - acc: 0.8086 - val_loss: 0.8572 - val_acc: 0.8024\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5087 - acc: 0.8302 - val_loss: 1.0336 - val_acc: 0.7621\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5250 - acc: 0.8315 - val_loss: 0.9805 - val_acc: 0.7419\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 0s 207us/step - loss: 0.6213 - acc: 0.8167 - val_loss: 0.8710 - val_acc: 0.7621\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5227 - acc: 0.8302 - val_loss: 0.9419 - val_acc: 0.7581\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 0s 198us/step - loss: 0.4833 - acc: 0.8342 - val_loss: 0.8549 - val_acc: 0.7581\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 0s 203us/step - loss: 0.5129 - acc: 0.8181 - val_loss: 0.8078 - val_acc: 0.7863\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.5098 - acc: 0.8383 - val_loss: 1.2669 - val_acc: 0.7097\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 0s 187us/step - loss: 0.5838 - acc: 0.8032 - val_loss: 0.8943 - val_acc: 0.7702\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 0s 202us/step - loss: 0.5038 - acc: 0.8127 - val_loss: 0.9138 - val_acc: 0.7581\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 0s 206us/step - loss: 0.4983 - acc: 0.8356 - val_loss: 0.9390 - val_acc: 0.7742\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 0s 191us/step - loss: 0.6330 - acc: 0.8086 - val_loss: 0.8900 - val_acc: 0.7782\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 0s 205us/step - loss: 0.4952 - acc: 0.8302 - val_loss: 0.9639 - val_acc: 0.7581\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 0s 211us/step - loss: 0.5383 - acc: 0.8113 - val_loss: 0.9659 - val_acc: 0.7419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, epochs=1000, batch_size=128, validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be4c9c3198>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果：过拟合减弱了，但是模型的精度还是不够高！\n",
    "\n",
    "提高模型精度主要行为就是“增大网络容量”：1. 把层增多；2. 每层的单元数增多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化2："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化策略：在上一种模型深度不变的条件下，增大每层的单元数。—— 提高网络容量，从而增加模型的精度上限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(128, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(256, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(256, 7, activation='relu', padding='same'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 192, 32)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 192, 32)           7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 64, 64)            14400     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 64, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 21, 128)           57472     \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 21, 128)           114816    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 7, 256)            229632    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 7, 256)            459008    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 99)                25443     \n",
      "=================================================================\n",
      "Total params: 936,963\n",
      "Trainable params: 936,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 4s 6ms/step - loss: 4.6237 - acc: 0.0081 - val_loss: 4.5973 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 0s 374us/step - loss: 4.5927 - acc: 0.0081 - val_loss: 4.5938 - val_acc: 0.0081\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 0s 348us/step - loss: 4.5734 - acc: 0.0148 - val_loss: 4.5939 - val_acc: 0.0040\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 4.5280 - acc: 0.0162 - val_loss: 4.5597 - val_acc: 0.0121\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.5266 - acc: 0.0162 - val_loss: 4.5073 - val_acc: 0.0121\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.4412 - acc: 0.0216 - val_loss: 4.3995 - val_acc: 0.0081\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.4491 - acc: 0.0148 - val_loss: 4.4913 - val_acc: 0.0081\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.3710 - acc: 0.0256 - val_loss: 4.3805 - val_acc: 0.0081\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 4.3771 - acc: 0.0256 - val_loss: 4.3491 - val_acc: 0.0161\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 4.2478 - acc: 0.0189 - val_loss: 4.2478 - val_acc: 0.0081\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 4.2344 - acc: 0.0148 - val_loss: 4.2393 - val_acc: 0.0121\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 4.2158 - acc: 0.0216 - val_loss: 4.3064 - val_acc: 0.0121\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 4.1294 - acc: 0.0175 - val_loss: 4.1474 - val_acc: 0.0081\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.1640 - acc: 0.0189 - val_loss: 4.2138 - val_acc: 0.0161\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 4.0805 - acc: 0.0175 - val_loss: 4.1296 - val_acc: 0.0242\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 4.1560 - acc: 0.0283 - val_loss: 4.0786 - val_acc: 0.0202\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 4.0440 - acc: 0.0243 - val_loss: 4.0636 - val_acc: 0.0242\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 4.0396 - acc: 0.0377 - val_loss: 4.2011 - val_acc: 0.0242\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 3.9883 - acc: 0.0404 - val_loss: 3.9497 - val_acc: 0.0363\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 4.0343 - acc: 0.0323 - val_loss: 4.0867 - val_acc: 0.0484\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 0s 333us/step - loss: 3.9446 - acc: 0.0458 - val_loss: 3.9925 - val_acc: 0.0323\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 3.8239 - acc: 0.0512 - val_loss: 3.7913 - val_acc: 0.0444\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 3.7715 - acc: 0.0620 - val_loss: 3.7319 - val_acc: 0.0806\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 0s 333us/step - loss: 3.6370 - acc: 0.0903 - val_loss: 3.6317 - val_acc: 0.0806\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 3.6768 - acc: 0.0660 - val_loss: 3.5362 - val_acc: 0.0968\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 3.5178 - acc: 0.0836 - val_loss: 3.4479 - val_acc: 0.1048\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 3.5006 - acc: 0.0916 - val_loss: 3.4144 - val_acc: 0.1089\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 3.4017 - acc: 0.1011 - val_loss: 3.4103 - val_acc: 0.1411\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 3.3076 - acc: 0.1213 - val_loss: 3.4014 - val_acc: 0.0927\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 3.3841 - acc: 0.0970 - val_loss: 3.3238 - val_acc: 0.1290\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 3.1702 - acc: 0.1402 - val_loss: 3.1198 - val_acc: 0.1452\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 3.1710 - acc: 0.1402 - val_loss: 3.2189 - val_acc: 0.1411\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 3.1919 - acc: 0.1280 - val_loss: 3.1825 - val_acc: 0.1129\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 3.0229 - acc: 0.1644 - val_loss: 3.5173 - val_acc: 0.0484\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 3.0394 - acc: 0.1698 - val_loss: 2.9430 - val_acc: 0.1613\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 2.9456 - acc: 0.1725 - val_loss: 2.8019 - val_acc: 0.2177\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.8949 - acc: 0.1833 - val_loss: 2.8443 - val_acc: 0.2016\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 3.0552 - acc: 0.1482 - val_loss: 2.9348 - val_acc: 0.1976\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.6921 - acc: 0.2197 - val_loss: 2.6404 - val_acc: 0.2177\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.6974 - acc: 0.2251 - val_loss: 3.0179 - val_acc: 0.1371\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 2.8071 - acc: 0.2035 - val_loss: 3.0777 - val_acc: 0.1008\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 2.6506 - acc: 0.2129 - val_loss: 2.8350 - val_acc: 0.1815\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 2.7708 - acc: 0.1941 - val_loss: 2.6144 - val_acc: 0.2137\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 2.6484 - acc: 0.2102 - val_loss: 2.6382 - val_acc: 0.2379\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 2.6854 - acc: 0.2210 - val_loss: 2.7507 - val_acc: 0.2097\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 2.4595 - acc: 0.3154 - val_loss: 2.6420 - val_acc: 0.2460\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.4655 - acc: 0.2722 - val_loss: 2.5953 - val_acc: 0.2500\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 2.4743 - acc: 0.2601 - val_loss: 2.5191 - val_acc: 0.2540\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 2.3323 - acc: 0.2588 - val_loss: 2.4093 - val_acc: 0.2782\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 2.3857 - acc: 0.2992 - val_loss: 2.2905 - val_acc: 0.3065\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 2.3781 - acc: 0.3019 - val_loss: 2.3684 - val_acc: 0.3105\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.2671 - acc: 0.3059 - val_loss: 2.3554 - val_acc: 0.2903\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 2.3072 - acc: 0.3005 - val_loss: 2.3111 - val_acc: 0.2984\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 2.0760 - acc: 0.3369 - val_loss: 2.4487 - val_acc: 0.2621\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 2.2233 - acc: 0.3329 - val_loss: 2.6271 - val_acc: 0.2500\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 2.1905 - acc: 0.3261 - val_loss: 2.5389 - val_acc: 0.2097\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 0s 334us/step - loss: 2.0251 - acc: 0.3760 - val_loss: 2.1383 - val_acc: 0.3629\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 2.0037 - acc: 0.3625 - val_loss: 2.2449 - val_acc: 0.3306\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 1.9448 - acc: 0.3922 - val_loss: 1.9980 - val_acc: 0.3669\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 2.0360 - acc: 0.3679 - val_loss: 2.2871 - val_acc: 0.3065\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 1.9235 - acc: 0.3935 - val_loss: 1.9896 - val_acc: 0.3790\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 1.7766 - acc: 0.4286 - val_loss: 1.9184 - val_acc: 0.3871\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 2.1579 - acc: 0.3639 - val_loss: 1.9545 - val_acc: 0.4032\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.7195 - acc: 0.4569 - val_loss: 1.9060 - val_acc: 0.4032\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.6504 - acc: 0.4596 - val_loss: 1.8469 - val_acc: 0.4032\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 1.8432 - acc: 0.4218 - val_loss: 1.9547 - val_acc: 0.3669\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.8828 - acc: 0.4097 - val_loss: 2.1192 - val_acc: 0.3347\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.6034 - acc: 0.4744 - val_loss: 2.1381 - val_acc: 0.3589\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.7052 - acc: 0.4811 - val_loss: 1.8518 - val_acc: 0.3710\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 1.6446 - acc: 0.4677 - val_loss: 1.9398 - val_acc: 0.4032\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.5941 - acc: 0.4960 - val_loss: 2.2168 - val_acc: 0.3992\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.5696 - acc: 0.5081 - val_loss: 1.9435 - val_acc: 0.4516\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.5288 - acc: 0.5000 - val_loss: 1.8618 - val_acc: 0.4476\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.5507 - acc: 0.4852 - val_loss: 2.0559 - val_acc: 0.4516\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 1.4403 - acc: 0.5243 - val_loss: 1.8850 - val_acc: 0.4435\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.4909 - acc: 0.4784 - val_loss: 1.7741 - val_acc: 0.4758\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 1.4547 - acc: 0.5445 - val_loss: 1.9317 - val_acc: 0.4637\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.3140 - acc: 0.5714 - val_loss: 1.7780 - val_acc: 0.4919\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 1.3831 - acc: 0.5674 - val_loss: 1.8541 - val_acc: 0.4113\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.3526 - acc: 0.5539 - val_loss: 1.7915 - val_acc: 0.4879\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.4494 - acc: 0.5512 - val_loss: 1.6667 - val_acc: 0.5242\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.1639 - acc: 0.6065 - val_loss: 1.4949 - val_acc: 0.5524\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 1.4355 - acc: 0.5431 - val_loss: 1.6642 - val_acc: 0.4556\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.1475 - acc: 0.6226 - val_loss: 1.6363 - val_acc: 0.4960\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 1.2207 - acc: 0.5863 - val_loss: 1.5834 - val_acc: 0.5081\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.2281 - acc: 0.6011 - val_loss: 1.5118 - val_acc: 0.5403\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.0908 - acc: 0.6456 - val_loss: 1.6826 - val_acc: 0.5040\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 1.1975 - acc: 0.5930 - val_loss: 1.4025 - val_acc: 0.5887\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 1.0738 - acc: 0.6456 - val_loss: 1.5504 - val_acc: 0.5565\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.9831 - acc: 0.6819 - val_loss: 1.4208 - val_acc: 0.5887\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.1220 - acc: 0.6402 - val_loss: 2.2489 - val_acc: 0.3750\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 1.0313 - acc: 0.6496 - val_loss: 1.3150 - val_acc: 0.6008\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.9181 - acc: 0.6927 - val_loss: 1.4328 - val_acc: 0.6048\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 1.1258 - acc: 0.6388 - val_loss: 1.4052 - val_acc: 0.5685\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.9460 - acc: 0.6927 - val_loss: 1.3235 - val_acc: 0.6048\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 1.1121 - acc: 0.6456 - val_loss: 1.3847 - val_acc: 0.5927\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.8119 - acc: 0.7224 - val_loss: 1.3343 - val_acc: 0.5847\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 1.0066 - acc: 0.6509 - val_loss: 1.5128 - val_acc: 0.5565\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.9308 - acc: 0.7022 - val_loss: 1.2867 - val_acc: 0.6210\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.7364 - acc: 0.7547 - val_loss: 1.4977 - val_acc: 0.5766\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 1.0675 - acc: 0.6604 - val_loss: 1.4792 - val_acc: 0.5484\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.8357 - acc: 0.7197 - val_loss: 1.5904 - val_acc: 0.5484\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.7875 - acc: 0.7507 - val_loss: 1.5965 - val_acc: 0.5282\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.7180 - acc: 0.7534 - val_loss: 1.3060 - val_acc: 0.6008\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.8928 - acc: 0.6927 - val_loss: 1.4309 - val_acc: 0.5484\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.7175 - acc: 0.7749 - val_loss: 1.2937 - val_acc: 0.6129\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.9107 - acc: 0.7049 - val_loss: 1.3786 - val_acc: 0.5847\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.6720 - acc: 0.7749 - val_loss: 1.2704 - val_acc: 0.6089\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.6534 - acc: 0.7628 - val_loss: 1.1401 - val_acc: 0.6532\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.6593 - acc: 0.7736 - val_loss: 1.6481 - val_acc: 0.5242\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.7833 - acc: 0.7372 - val_loss: 1.2035 - val_acc: 0.6532\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.7707 - acc: 0.7601 - val_loss: 1.3118 - val_acc: 0.5968\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.6236 - acc: 0.7992 - val_loss: 1.1857 - val_acc: 0.6613\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.6533 - acc: 0.7978 - val_loss: 1.1435 - val_acc: 0.6492\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.6338 - acc: 0.7898 - val_loss: 1.8865 - val_acc: 0.4879\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.7484 - acc: 0.7466 - val_loss: 1.3769 - val_acc: 0.6371\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.5059 - acc: 0.8302 - val_loss: 1.0677 - val_acc: 0.6492\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.6589 - acc: 0.7830 - val_loss: 1.0544 - val_acc: 0.6492\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.5432 - acc: 0.8140 - val_loss: 1.4587 - val_acc: 0.5524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.6898 - acc: 0.7776 - val_loss: 1.0505 - val_acc: 0.6532\n",
      "Epoch 121/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.4964 - acc: 0.8450 - val_loss: 1.1783 - val_acc: 0.6492\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.4932 - acc: 0.8288 - val_loss: 1.5403 - val_acc: 0.5927\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.7882 - acc: 0.7507 - val_loss: 1.1529 - val_acc: 0.6734\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.4594 - acc: 0.8423 - val_loss: 1.0219 - val_acc: 0.6694\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.5320 - acc: 0.8248 - val_loss: 1.9190 - val_acc: 0.5202\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.6203 - acc: 0.7965 - val_loss: 1.0648 - val_acc: 0.6895\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.4281 - acc: 0.8652 - val_loss: 1.0420 - val_acc: 0.6976\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.5159 - acc: 0.8261 - val_loss: 1.0805 - val_acc: 0.6815\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.4935 - acc: 0.8383 - val_loss: 1.0374 - val_acc: 0.7016\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.4560 - acc: 0.8396 - val_loss: 1.2820 - val_acc: 0.6573\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.4027 - acc: 0.8571 - val_loss: 1.0928 - val_acc: 0.6895\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.3883 - acc: 0.8585 - val_loss: 0.9777 - val_acc: 0.7218\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.6350 - acc: 0.7871 - val_loss: 1.0370 - val_acc: 0.6935\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.3519 - acc: 0.8787 - val_loss: 1.0013 - val_acc: 0.6895\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.3800 - acc: 0.8720 - val_loss: 1.1910 - val_acc: 0.6331\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.4339 - acc: 0.8787 - val_loss: 2.7937 - val_acc: 0.3992\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.6843 - acc: 0.7817 - val_loss: 0.9403 - val_acc: 0.6976\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.3391 - acc: 0.8841 - val_loss: 1.0219 - val_acc: 0.7056\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.4087 - acc: 0.8693 - val_loss: 1.0763 - val_acc: 0.6855\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.4000 - acc: 0.8733 - val_loss: 1.0311 - val_acc: 0.6774\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.3530 - acc: 0.8801 - val_loss: 1.0428 - val_acc: 0.6855\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.5078 - acc: 0.8450 - val_loss: 1.1474 - val_acc: 0.6371\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.3153 - acc: 0.8747 - val_loss: 1.1815 - val_acc: 0.6653\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2822 - acc: 0.8935 - val_loss: 0.9879 - val_acc: 0.7177\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.3112 - acc: 0.8949 - val_loss: 0.9902 - val_acc: 0.7177\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.7321 - acc: 0.7938 - val_loss: 1.1021 - val_acc: 0.6653\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.3601 - acc: 0.8827 - val_loss: 0.9192 - val_acc: 0.7339\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.2574 - acc: 0.9097 - val_loss: 0.9621 - val_acc: 0.7097\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.2780 - acc: 0.9164 - val_loss: 1.0868 - val_acc: 0.7016\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.2936 - acc: 0.8949 - val_loss: 1.0991 - val_acc: 0.7016\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.4432 - acc: 0.8558 - val_loss: 1.6405 - val_acc: 0.5806\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.2926 - acc: 0.9084 - val_loss: 0.9917 - val_acc: 0.7056\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.2659 - acc: 0.9124 - val_loss: 1.0135 - val_acc: 0.7218\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.3900 - acc: 0.8679 - val_loss: 1.1641 - val_acc: 0.6774\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.2886 - acc: 0.9111 - val_loss: 1.1713 - val_acc: 0.7016\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.3826 - acc: 0.8733 - val_loss: 1.8135 - val_acc: 0.5403\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.2996 - acc: 0.9016 - val_loss: 0.9733 - val_acc: 0.6895\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.2929 - acc: 0.9057 - val_loss: 1.2977 - val_acc: 0.6411\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.2388 - acc: 0.9286 - val_loss: 0.9864 - val_acc: 0.7298\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.2081 - acc: 0.9245 - val_loss: 1.0146 - val_acc: 0.7097\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.3095 - acc: 0.8935 - val_loss: 2.1383 - val_acc: 0.4919\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.2556 - acc: 0.9070 - val_loss: 1.1445 - val_acc: 0.7137\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.2937 - acc: 0.8935 - val_loss: 0.8392 - val_acc: 0.7460\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.2130 - acc: 0.9326 - val_loss: 1.2373 - val_acc: 0.6855\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2006 - acc: 0.9299 - val_loss: 0.9986 - val_acc: 0.7702\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.2578 - acc: 0.9151 - val_loss: 0.9593 - val_acc: 0.7621\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.2437 - acc: 0.9070 - val_loss: 1.0211 - val_acc: 0.7379\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.2368 - acc: 0.9191 - val_loss: 1.1682 - val_acc: 0.6734\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.3534 - acc: 0.8774 - val_loss: 1.1780 - val_acc: 0.6694\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1899 - acc: 0.9326 - val_loss: 1.3352 - val_acc: 0.6371\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2473 - acc: 0.9245 - val_loss: 0.9054 - val_acc: 0.7540\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2169 - acc: 0.9245 - val_loss: 0.9704 - val_acc: 0.7258\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.2140 - acc: 0.9367 - val_loss: 1.0531 - val_acc: 0.7379\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.2836 - acc: 0.9097 - val_loss: 1.0035 - val_acc: 0.7097\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1897 - acc: 0.9272 - val_loss: 1.2325 - val_acc: 0.6895\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2643 - acc: 0.9070 - val_loss: 1.1113 - val_acc: 0.6815\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.1690 - acc: 0.9501 - val_loss: 1.0077 - val_acc: 0.7177\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.4044 - acc: 0.8814 - val_loss: 1.0051 - val_acc: 0.7258\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1284 - acc: 0.9515 - val_loss: 1.0047 - val_acc: 0.7581\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.1677 - acc: 0.9407 - val_loss: 1.0908 - val_acc: 0.7056\n",
      "Epoch 181/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.2416 - acc: 0.9178 - val_loss: 1.1313 - val_acc: 0.6895\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1404 - acc: 0.9569 - val_loss: 1.4580 - val_acc: 0.6411\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.1576 - acc: 0.9461 - val_loss: 1.0117 - val_acc: 0.7500\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.4565 - acc: 0.8801 - val_loss: 1.0124 - val_acc: 0.6976\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1877 - acc: 0.9407 - val_loss: 0.9628 - val_acc: 0.7258\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1560 - acc: 0.9515 - val_loss: 1.0292 - val_acc: 0.7218\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.1448 - acc: 0.9501 - val_loss: 1.3791 - val_acc: 0.6452\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1709 - acc: 0.9474 - val_loss: 1.0346 - val_acc: 0.7379\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2763 - acc: 0.9084 - val_loss: 1.0004 - val_acc: 0.7218\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1377 - acc: 0.9555 - val_loss: 0.9890 - val_acc: 0.7137\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1660 - acc: 0.9447 - val_loss: 1.0802 - val_acc: 0.7258\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.3133 - acc: 0.9164 - val_loss: 0.9524 - val_acc: 0.7460\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1149 - acc: 0.9677 - val_loss: 0.9978 - val_acc: 0.7621\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1961 - acc: 0.9420 - val_loss: 0.8827 - val_acc: 0.7500\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1464 - acc: 0.9501 - val_loss: 1.1581 - val_acc: 0.6935\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.4444 - acc: 0.8585 - val_loss: 0.9124 - val_acc: 0.7379\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1304 - acc: 0.9650 - val_loss: 0.8628 - val_acc: 0.7742\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1060 - acc: 0.9663 - val_loss: 1.0342 - val_acc: 0.7460\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.1434 - acc: 0.9515 - val_loss: 0.8067 - val_acc: 0.7863\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1104 - acc: 0.9623 - val_loss: 1.0282 - val_acc: 0.7500\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1332 - acc: 0.9501 - val_loss: 1.2807 - val_acc: 0.6895\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.2159 - acc: 0.9407 - val_loss: 0.9162 - val_acc: 0.7460\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1166 - acc: 0.9650 - val_loss: 0.9186 - val_acc: 0.7540\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1961 - acc: 0.9340 - val_loss: 1.1404 - val_acc: 0.6895\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1481 - acc: 0.9501 - val_loss: 1.0424 - val_acc: 0.7419\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1767 - acc: 0.9488 - val_loss: 0.8131 - val_acc: 0.7782\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0914 - acc: 0.9704 - val_loss: 1.1087 - val_acc: 0.7419\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.1535 - acc: 0.9528 - val_loss: 0.7957 - val_acc: 0.7742\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1274 - acc: 0.9582 - val_loss: 1.1653 - val_acc: 0.7097\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1499 - acc: 0.9474 - val_loss: 1.1051 - val_acc: 0.7097\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.2082 - acc: 0.9353 - val_loss: 0.9692 - val_acc: 0.7540\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1287 - acc: 0.9515 - val_loss: 0.8707 - val_acc: 0.7661\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.1120 - acc: 0.9677 - val_loss: 0.9262 - val_acc: 0.7742\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.1242 - acc: 0.9623 - val_loss: 0.9287 - val_acc: 0.7782\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.1277 - acc: 0.9569 - val_loss: 0.9420 - val_acc: 0.7621\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.2332 - acc: 0.9205 - val_loss: 0.8148 - val_acc: 0.7661\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1102 - acc: 0.9650 - val_loss: 0.9411 - val_acc: 0.7823\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1050 - acc: 0.9636 - val_loss: 1.0123 - val_acc: 0.7298\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0725 - acc: 0.9704 - val_loss: 1.1324 - val_acc: 0.7177\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1141 - acc: 0.9663 - val_loss: 0.9286 - val_acc: 0.7500\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.2110 - acc: 0.9380 - val_loss: 1.2470 - val_acc: 0.7177\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1468 - acc: 0.9542 - val_loss: 0.9695 - val_acc: 0.7460\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0990 - acc: 0.9663 - val_loss: 1.0079 - val_acc: 0.7419\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0960 - acc: 0.9663 - val_loss: 0.9047 - val_acc: 0.7661\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0937 - acc: 0.9663 - val_loss: 1.1792 - val_acc: 0.7258\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.1637 - acc: 0.9515 - val_loss: 1.5642 - val_acc: 0.6774\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1134 - acc: 0.9636 - val_loss: 0.8895 - val_acc: 0.7621\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0939 - acc: 0.9730 - val_loss: 1.0406 - val_acc: 0.7621\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.1423 - acc: 0.9650 - val_loss: 1.2328 - val_acc: 0.6855\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.1625 - acc: 0.9474 - val_loss: 0.9479 - val_acc: 0.7661\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1490 - acc: 0.9596 - val_loss: 0.9379 - val_acc: 0.7621\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0782 - acc: 0.9757 - val_loss: 0.9843 - val_acc: 0.7621\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0880 - acc: 0.9704 - val_loss: 1.0937 - val_acc: 0.7621\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.1253 - acc: 0.9636 - val_loss: 0.9740 - val_acc: 0.7742\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0730 - acc: 0.9717 - val_loss: 0.9966 - val_acc: 0.7661\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0869 - acc: 0.9730 - val_loss: 1.1137 - val_acc: 0.7419\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.3085 - acc: 0.9232 - val_loss: 1.0523 - val_acc: 0.7258\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 342us/step - loss: 0.0943 - acc: 0.9704 - val_loss: 1.1162 - val_acc: 0.7218\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1012 - acc: 0.9650 - val_loss: 0.9520 - val_acc: 0.7258\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0790 - acc: 0.9730 - val_loss: 0.9698 - val_acc: 0.7581\n",
      "Epoch 241/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1180 - acc: 0.9623 - val_loss: 1.1227 - val_acc: 0.7419\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0653 - acc: 0.9784 - val_loss: 0.9392 - val_acc: 0.7863\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0820 - acc: 0.9690 - val_loss: 1.0337 - val_acc: 0.7621\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.3270 - acc: 0.9205 - val_loss: 0.9014 - val_acc: 0.7621\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0758 - acc: 0.9704 - val_loss: 0.9592 - val_acc: 0.7702\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0424 - acc: 0.9892 - val_loss: 1.0098 - val_acc: 0.7661\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0739 - acc: 0.9730 - val_loss: 1.0286 - val_acc: 0.7339\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0912 - acc: 0.9798 - val_loss: 1.4637 - val_acc: 0.6653\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.1068 - acc: 0.9717 - val_loss: 0.9273 - val_acc: 0.7863\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1000 - acc: 0.9650 - val_loss: 0.9230 - val_acc: 0.7621\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0473 - acc: 0.9825 - val_loss: 1.3517 - val_acc: 0.7056\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.1157 - acc: 0.9623 - val_loss: 1.2379 - val_acc: 0.7177\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1441 - acc: 0.9596 - val_loss: 0.9766 - val_acc: 0.7621\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0528 - acc: 0.9811 - val_loss: 1.1395 - val_acc: 0.7419\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0611 - acc: 0.9798 - val_loss: 1.1739 - val_acc: 0.7702\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.1486 - acc: 0.9596 - val_loss: 1.3921 - val_acc: 0.6976\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0598 - acc: 0.9798 - val_loss: 0.9295 - val_acc: 0.7702\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1127 - acc: 0.9582 - val_loss: 1.1935 - val_acc: 0.7379\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0857 - acc: 0.9663 - val_loss: 0.9637 - val_acc: 0.7823\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0565 - acc: 0.9825 - val_loss: 0.9258 - val_acc: 0.8105\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0574 - acc: 0.9865 - val_loss: 0.8336 - val_acc: 0.8145\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.2941 - acc: 0.9218 - val_loss: 0.9867 - val_acc: 0.7419\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0724 - acc: 0.9757 - val_loss: 0.7904 - val_acc: 0.8105\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0473 - acc: 0.9892 - val_loss: 0.9379 - val_acc: 0.7823\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0873 - acc: 0.9704 - val_loss: 0.8177 - val_acc: 0.8065\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.8589 - val_acc: 0.7782\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0641 - acc: 0.9879 - val_loss: 1.0161 - val_acc: 0.7379\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0757 - acc: 0.9690 - val_loss: 0.9295 - val_acc: 0.7823\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0666 - acc: 0.9838 - val_loss: 0.9076 - val_acc: 0.8024\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0919 - acc: 0.9744 - val_loss: 1.1948 - val_acc: 0.7258\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0866 - acc: 0.9677 - val_loss: 0.9288 - val_acc: 0.7742\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.1423 - acc: 0.9623 - val_loss: 0.6975 - val_acc: 0.8105\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0944 - acc: 0.9677 - val_loss: 0.6589 - val_acc: 0.8105\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0874 - acc: 0.9717 - val_loss: 1.0014 - val_acc: 0.7500\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0808 - acc: 0.9744 - val_loss: 0.9333 - val_acc: 0.7661\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0480 - acc: 0.9852 - val_loss: 1.2981 - val_acc: 0.7137\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1843 - acc: 0.9542 - val_loss: 0.9252 - val_acc: 0.7500\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0417 - acc: 0.9892 - val_loss: 0.8711 - val_acc: 0.7823\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0601 - acc: 0.9798 - val_loss: 1.1749 - val_acc: 0.7258\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0365 - acc: 0.9865 - val_loss: 1.0029 - val_acc: 0.7782\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0298 - acc: 0.9892 - val_loss: 1.0755 - val_acc: 0.7742\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.1216 - acc: 0.9636 - val_loss: 2.4544 - val_acc: 0.5605\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.4101 - acc: 0.9124 - val_loss: 1.0025 - val_acc: 0.7540\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0634 - acc: 0.9811 - val_loss: 0.9205 - val_acc: 0.7742\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0720 - acc: 0.9798 - val_loss: 0.9167 - val_acc: 0.7581\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0415 - acc: 0.9879 - val_loss: 0.9694 - val_acc: 0.7823\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0662 - acc: 0.9784 - val_loss: 0.9387 - val_acc: 0.7742\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0653 - acc: 0.9811 - val_loss: 0.9432 - val_acc: 0.7702\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0505 - acc: 0.9811 - val_loss: 0.9889 - val_acc: 0.7742\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.1928 - acc: 0.9434 - val_loss: 0.9096 - val_acc: 0.7581\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0704 - acc: 0.9744 - val_loss: 1.0148 - val_acc: 0.7339\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0577 - acc: 0.9865 - val_loss: 0.9376 - val_acc: 0.7782\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0962 - acc: 0.9623 - val_loss: 1.0343 - val_acc: 0.7419\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0725 - acc: 0.9771 - val_loss: 0.9254 - val_acc: 0.7581\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0501 - acc: 0.9892 - val_loss: 0.8956 - val_acc: 0.7702\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0432 - acc: 0.9865 - val_loss: 0.9635 - val_acc: 0.7863\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0841 - acc: 0.9771 - val_loss: 0.9103 - val_acc: 0.8024\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0751 - acc: 0.9757 - val_loss: 1.0744 - val_acc: 0.7661\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0843 - acc: 0.9677 - val_loss: 0.8437 - val_acc: 0.8024\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0380 - acc: 0.9879 - val_loss: 1.0929 - val_acc: 0.7460\n",
      "Epoch 301/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0496 - acc: 0.9879 - val_loss: 1.3054 - val_acc: 0.7177\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0787 - acc: 0.9744 - val_loss: 0.9177 - val_acc: 0.7823\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0845 - acc: 0.9757 - val_loss: 1.0102 - val_acc: 0.7581\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0661 - acc: 0.9852 - val_loss: 1.1096 - val_acc: 0.7339\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0749 - acc: 0.9865 - val_loss: 0.8887 - val_acc: 0.7863\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0702 - acc: 0.9771 - val_loss: 1.0057 - val_acc: 0.8024\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0683 - acc: 0.9838 - val_loss: 0.9807 - val_acc: 0.7621\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0343 - acc: 0.9879 - val_loss: 1.0091 - val_acc: 0.7540\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0630 - acc: 0.9825 - val_loss: 1.0498 - val_acc: 0.7379\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0639 - acc: 0.9825 - val_loss: 0.9278 - val_acc: 0.7702\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0393 - acc: 0.9811 - val_loss: 0.9707 - val_acc: 0.7984\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0844 - acc: 0.9730 - val_loss: 2.1349 - val_acc: 0.6290\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.1134 - acc: 0.9663 - val_loss: 0.7919 - val_acc: 0.7984\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0660 - acc: 0.9825 - val_loss: 0.8547 - val_acc: 0.7742\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0310 - acc: 0.9892 - val_loss: 0.9979 - val_acc: 0.7621\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0568 - acc: 0.9798 - val_loss: 1.0160 - val_acc: 0.7661\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0591 - acc: 0.9811 - val_loss: 1.0025 - val_acc: 0.7581\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0496 - acc: 0.9838 - val_loss: 0.9146 - val_acc: 0.7903\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0608 - acc: 0.9771 - val_loss: 0.9290 - val_acc: 0.7903\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0468 - acc: 0.9838 - val_loss: 1.1441 - val_acc: 0.7702\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.1647 - acc: 0.9569 - val_loss: 0.9494 - val_acc: 0.7621\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0369 - acc: 0.9919 - val_loss: 1.2061 - val_acc: 0.7298\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0595 - acc: 0.9784 - val_loss: 0.9888 - val_acc: 0.7661\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.1412 - acc: 0.9663 - val_loss: 0.9295 - val_acc: 0.7863\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0537 - acc: 0.9825 - val_loss: 0.9452 - val_acc: 0.7661\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0532 - acc: 0.9811 - val_loss: 1.0102 - val_acc: 0.7339\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0576 - acc: 0.9838 - val_loss: 1.0740 - val_acc: 0.7177\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0540 - acc: 0.9865 - val_loss: 0.9985 - val_acc: 0.7621\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0614 - acc: 0.9838 - val_loss: 1.0922 - val_acc: 0.7742\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0861 - acc: 0.9798 - val_loss: 1.3161 - val_acc: 0.7298\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0746 - acc: 0.9744 - val_loss: 0.9285 - val_acc: 0.7823\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0385 - acc: 0.9865 - val_loss: 1.0992 - val_acc: 0.7298\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0749 - acc: 0.9784 - val_loss: 0.9853 - val_acc: 0.7500\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0305 - acc: 0.9933 - val_loss: 1.0196 - val_acc: 0.7742\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0724 - acc: 0.9784 - val_loss: 1.2080 - val_acc: 0.7137\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0363 - acc: 0.9892 - val_loss: 1.3025 - val_acc: 0.7460\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0364 - acc: 0.9879 - val_loss: 1.0693 - val_acc: 0.7944\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 1.2947 - val_acc: 0.7540\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0815 - acc: 0.9690 - val_loss: 1.4780 - val_acc: 0.7218\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0789 - acc: 0.9690 - val_loss: 0.9452 - val_acc: 0.8065\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0465 - acc: 0.9852 - val_loss: 1.2855 - val_acc: 0.7218\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0411 - acc: 0.9825 - val_loss: 1.2833 - val_acc: 0.7500\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0574 - acc: 0.9771 - val_loss: 1.1327 - val_acc: 0.7419\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0508 - acc: 0.9865 - val_loss: 1.1354 - val_acc: 0.7419\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0678 - acc: 0.9825 - val_loss: 0.8639 - val_acc: 0.7742\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0558 - acc: 0.9852 - val_loss: 0.9439 - val_acc: 0.7823\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0206 - acc: 0.9946 - val_loss: 0.9534 - val_acc: 0.7863\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.1200 - acc: 0.9623 - val_loss: 1.1334 - val_acc: 0.7581\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0378 - acc: 0.9892 - val_loss: 0.8994 - val_acc: 0.7903\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0494 - acc: 0.9825 - val_loss: 0.8201 - val_acc: 0.8024\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0522 - acc: 0.9825 - val_loss: 1.1356 - val_acc: 0.7460\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0642 - acc: 0.9852 - val_loss: 1.1122 - val_acc: 0.7500\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0921 - acc: 0.9717 - val_loss: 0.9552 - val_acc: 0.7581\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0592 - acc: 0.9852 - val_loss: 0.8880 - val_acc: 0.7742\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0320 - acc: 0.9906 - val_loss: 1.0105 - val_acc: 0.7500\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 343us/step - loss: 0.0499 - acc: 0.9771 - val_loss: 0.9011 - val_acc: 0.7903\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0831 - acc: 0.9838 - val_loss: 1.2187 - val_acc: 0.7218\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0406 - acc: 0.9838 - val_loss: 0.8033 - val_acc: 0.8185\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0533 - acc: 0.9838 - val_loss: 1.1287 - val_acc: 0.7621\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0527 - acc: 0.9838 - val_loss: 0.9908 - val_acc: 0.7661\n",
      "Epoch 361/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.7788 - val_acc: 0.8024\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0370 - acc: 0.9906 - val_loss: 0.9980 - val_acc: 0.7823\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0358 - acc: 0.9906 - val_loss: 1.2497 - val_acc: 0.7540\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0961 - acc: 0.9717 - val_loss: 0.8359 - val_acc: 0.7863\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0554 - acc: 0.9825 - val_loss: 0.9743 - val_acc: 0.7863\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0414 - acc: 0.9865 - val_loss: 0.9965 - val_acc: 0.7742\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0340 - acc: 0.9919 - val_loss: 0.9765 - val_acc: 0.7944\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0260 - acc: 0.9919 - val_loss: 1.0208 - val_acc: 0.7823\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0227 - acc: 0.9906 - val_loss: 1.8049 - val_acc: 0.7016\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0506 - acc: 0.9825 - val_loss: 1.0924 - val_acc: 0.7944\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0459 - acc: 0.9906 - val_loss: 1.2713 - val_acc: 0.7782\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0515 - acc: 0.9798 - val_loss: 1.2243 - val_acc: 0.8024\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0655 - acc: 0.9865 - val_loss: 1.2792 - val_acc: 0.7661\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0830 - acc: 0.9744 - val_loss: 1.1312 - val_acc: 0.7540\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0591 - acc: 0.9811 - val_loss: 1.0369 - val_acc: 0.7661\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0483 - acc: 0.9838 - val_loss: 1.0666 - val_acc: 0.7782\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0245 - acc: 0.9946 - val_loss: 1.1547 - val_acc: 0.7702\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0698 - acc: 0.9690 - val_loss: 1.1659 - val_acc: 0.7661\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0656 - acc: 0.9784 - val_loss: 1.4820 - val_acc: 0.7016\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0624 - acc: 0.9825 - val_loss: 1.1763 - val_acc: 0.7339\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0613 - acc: 0.9838 - val_loss: 1.0742 - val_acc: 0.7540\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0180 - acc: 0.9946 - val_loss: 1.0537 - val_acc: 0.7581\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0356 - acc: 0.9852 - val_loss: 0.9905 - val_acc: 0.7661\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0248 - acc: 0.9933 - val_loss: 0.9915 - val_acc: 0.8105\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0545 - acc: 0.9798 - val_loss: 1.0675 - val_acc: 0.7500\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0437 - acc: 0.9865 - val_loss: 1.1336 - val_acc: 0.7742\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0842 - acc: 0.9811 - val_loss: 1.0316 - val_acc: 0.7621\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0562 - acc: 0.9798 - val_loss: 1.0929 - val_acc: 0.7460\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0407 - acc: 0.9865 - val_loss: 0.9566 - val_acc: 0.7863\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9330 - val_acc: 0.7702\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0688 - acc: 0.9838 - val_loss: 1.4405 - val_acc: 0.7298\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0538 - acc: 0.9852 - val_loss: 1.1080 - val_acc: 0.7540\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0348 - acc: 0.9892 - val_loss: 1.5369 - val_acc: 0.6976\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0411 - acc: 0.9879 - val_loss: 1.0692 - val_acc: 0.7782\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.9207 - val_acc: 0.8065\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0332 - acc: 0.9892 - val_loss: 1.0956 - val_acc: 0.7621\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0412 - acc: 0.9865 - val_loss: 1.0336 - val_acc: 0.7823\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0378 - acc: 0.9906 - val_loss: 0.9799 - val_acc: 0.7742\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0660 - acc: 0.9838 - val_loss: 1.1506 - val_acc: 0.7621\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0461 - acc: 0.9852 - val_loss: 0.9620 - val_acc: 0.8024\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0239 - acc: 0.9906 - val_loss: 1.0465 - val_acc: 0.7823\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0568 - acc: 0.9879 - val_loss: 1.2788 - val_acc: 0.7379\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0347 - acc: 0.9865 - val_loss: 1.3112 - val_acc: 0.7460\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0923 - acc: 0.9771 - val_loss: 1.1289 - val_acc: 0.7702\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0303 - acc: 0.9879 - val_loss: 1.1329 - val_acc: 0.7702\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0283 - acc: 0.9892 - val_loss: 0.9934 - val_acc: 0.7863\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0409 - acc: 0.9865 - val_loss: 1.0594 - val_acc: 0.8024\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0832 - acc: 0.9771 - val_loss: 1.1482 - val_acc: 0.7339\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.9866 - val_acc: 0.7702\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0554 - acc: 0.9879 - val_loss: 1.1061 - val_acc: 0.7621\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0601 - acc: 0.9852 - val_loss: 1.0543 - val_acc: 0.7702\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0387 - acc: 0.9933 - val_loss: 1.3471 - val_acc: 0.7218\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0606 - acc: 0.9838 - val_loss: 1.0760 - val_acc: 0.7823\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0447 - acc: 0.9852 - val_loss: 0.9422 - val_acc: 0.7863\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0397 - acc: 0.9879 - val_loss: 1.0076 - val_acc: 0.7702\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0408 - acc: 0.9892 - val_loss: 1.1247 - val_acc: 0.7540\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0386 - acc: 0.9852 - val_loss: 0.9528 - val_acc: 0.7702\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0449 - acc: 0.9865 - val_loss: 1.0632 - val_acc: 0.7742\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0198 - acc: 0.9919 - val_loss: 1.7055 - val_acc: 0.7177\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0547 - acc: 0.9838 - val_loss: 1.0245 - val_acc: 0.7702\n",
      "Epoch 421/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0196 - acc: 0.9933 - val_loss: 0.9946 - val_acc: 0.7742\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0877 - acc: 0.9784 - val_loss: 0.9928 - val_acc: 0.7540\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 0s 349us/step - loss: 0.0513 - acc: 0.9865 - val_loss: 1.0352 - val_acc: 0.7984\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0555 - acc: 0.9879 - val_loss: 0.9128 - val_acc: 0.7863\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0363 - acc: 0.9879 - val_loss: 0.9892 - val_acc: 0.7782\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.8608 - val_acc: 0.7944\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0167 - acc: 0.9960 - val_loss: 1.7289 - val_acc: 0.6774\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.1396 - acc: 0.9663 - val_loss: 1.1402 - val_acc: 0.7702\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0388 - acc: 0.9852 - val_loss: 0.9963 - val_acc: 0.7782\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 0.9059 - val_acc: 0.8024\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0327 - acc: 0.9906 - val_loss: 0.8928 - val_acc: 0.7863\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0234 - acc: 0.9892 - val_loss: 0.8932 - val_acc: 0.7903\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0186 - acc: 0.9933 - val_loss: 1.0417 - val_acc: 0.7903\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0431 - acc: 0.9838 - val_loss: 1.0360 - val_acc: 0.8065\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0556 - acc: 0.9865 - val_loss: 0.8943 - val_acc: 0.8105\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0358 - acc: 0.9879 - val_loss: 1.0387 - val_acc: 0.7742\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0198 - acc: 0.9933 - val_loss: 1.1242 - val_acc: 0.7742\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0292 - acc: 0.9919 - val_loss: 0.9856 - val_acc: 0.7903\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0330 - acc: 0.9933 - val_loss: 0.9772 - val_acc: 0.7823\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0279 - acc: 0.9919 - val_loss: 1.2378 - val_acc: 0.7500\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0808 - acc: 0.9811 - val_loss: 1.2053 - val_acc: 0.7661\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 1.0772 - val_acc: 0.7782\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0575 - acc: 0.9852 - val_loss: 0.9962 - val_acc: 0.7863\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0374 - acc: 0.9906 - val_loss: 0.9966 - val_acc: 0.7984\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0247 - acc: 0.9933 - val_loss: 0.9893 - val_acc: 0.7944\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0245 - acc: 0.9919 - val_loss: 0.9962 - val_acc: 0.8024\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0734 - acc: 0.9852 - val_loss: 1.0837 - val_acc: 0.7742\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0611 - acc: 0.9865 - val_loss: 0.9960 - val_acc: 0.7823\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0216 - acc: 0.9906 - val_loss: 1.0696 - val_acc: 0.7742\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0168 - acc: 0.9933 - val_loss: 1.1258 - val_acc: 0.7823\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0403 - acc: 0.9865 - val_loss: 0.9874 - val_acc: 0.7903\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0359 - acc: 0.9906 - val_loss: 1.0262 - val_acc: 0.7944\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0226 - acc: 0.9892 - val_loss: 0.9357 - val_acc: 0.8065\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0376 - acc: 0.9906 - val_loss: 1.0187 - val_acc: 0.8185\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0334 - acc: 0.9852 - val_loss: 1.2165 - val_acc: 0.7702\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0428 - acc: 0.9906 - val_loss: 1.1610 - val_acc: 0.7903\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0530 - acc: 0.9811 - val_loss: 0.9639 - val_acc: 0.8065\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 1.0141 - val_acc: 0.8065\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0198 - acc: 0.9906 - val_loss: 1.0457 - val_acc: 0.8065\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0338 - acc: 0.9879 - val_loss: 0.9866 - val_acc: 0.8185\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.9104 - val_acc: 0.8024\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0824 - acc: 0.9811 - val_loss: 0.9545 - val_acc: 0.7903\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0418 - acc: 0.9879 - val_loss: 1.0690 - val_acc: 0.7823\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0214 - acc: 0.9906 - val_loss: 1.1933 - val_acc: 0.7742\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0501 - acc: 0.9879 - val_loss: 1.1382 - val_acc: 0.7540\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0187 - acc: 0.9946 - val_loss: 1.1156 - val_acc: 0.7500\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0219 - acc: 0.9919 - val_loss: 1.2897 - val_acc: 0.7581\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0187 - acc: 0.9933 - val_loss: 1.2540 - val_acc: 0.7782\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0139 - acc: 0.9960 - val_loss: 1.0980 - val_acc: 0.8185\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0556 - acc: 0.9879 - val_loss: 1.2574 - val_acc: 0.7621\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.1106 - acc: 0.9677 - val_loss: 0.9984 - val_acc: 0.8024\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0166 - acc: 0.9919 - val_loss: 1.0932 - val_acc: 0.7863\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 1.0613 - val_acc: 0.7863\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 341us/step - loss: 0.0269 - acc: 0.9946 - val_loss: 1.1573 - val_acc: 0.7702\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 1.2747 - val_acc: 0.7661\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0223 - acc: 0.9906 - val_loss: 1.1289 - val_acc: 0.7903\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0220 - acc: 0.9906 - val_loss: 1.3099 - val_acc: 0.7500\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0397 - acc: 0.9879 - val_loss: 1.0497 - val_acc: 0.7903\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0317 - acc: 0.9879 - val_loss: 1.2946 - val_acc: 0.7903\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0712 - acc: 0.9811 - val_loss: 1.0481 - val_acc: 0.7903\n",
      "Epoch 481/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0399 - acc: 0.9919 - val_loss: 0.9350 - val_acc: 0.7944\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0361 - acc: 0.9933 - val_loss: 0.9055 - val_acc: 0.8065\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0202 - acc: 0.9960 - val_loss: 0.9715 - val_acc: 0.7782\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0346 - acc: 0.9906 - val_loss: 1.1179 - val_acc: 0.7944\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0342 - acc: 0.9865 - val_loss: 1.0650 - val_acc: 0.7702\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0507 - acc: 0.9798 - val_loss: 0.9414 - val_acc: 0.8185\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0327 - acc: 0.9906 - val_loss: 1.0251 - val_acc: 0.8024\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.1641 - val_acc: 0.7621\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0184 - acc: 0.9933 - val_loss: 1.3036 - val_acc: 0.7460\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0481 - acc: 0.9865 - val_loss: 1.5064 - val_acc: 0.7379\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0947 - acc: 0.9784 - val_loss: 1.2913 - val_acc: 0.7500\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0275 - acc: 0.9919 - val_loss: 1.1986 - val_acc: 0.7742\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0160 - acc: 0.9987 - val_loss: 1.1579 - val_acc: 0.7903\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0280 - acc: 0.9919 - val_loss: 1.4169 - val_acc: 0.7419\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0366 - acc: 0.9879 - val_loss: 1.0273 - val_acc: 0.7823\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0317 - acc: 0.9906 - val_loss: 1.0491 - val_acc: 0.8024\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0693 - acc: 0.9838 - val_loss: 1.4309 - val_acc: 0.7016\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0652 - acc: 0.9811 - val_loss: 0.9405 - val_acc: 0.8145\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0671 - acc: 0.9865 - val_loss: 0.9670 - val_acc: 0.7823\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.9279 - val_acc: 0.7984\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0495 - acc: 0.9865 - val_loss: 1.1452 - val_acc: 0.7621\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0189 - acc: 0.9919 - val_loss: 0.8587 - val_acc: 0.8065\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0545 - acc: 0.9892 - val_loss: 1.0219 - val_acc: 0.7903\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.9639 - val_acc: 0.7944\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0161 - acc: 0.9933 - val_loss: 1.0838 - val_acc: 0.7782\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0197 - acc: 0.9933 - val_loss: 0.9385 - val_acc: 0.8065\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0092 - acc: 0.9960 - val_loss: 1.4115 - val_acc: 0.7258\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0226 - acc: 0.9946 - val_loss: 1.2705 - val_acc: 0.7419\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0566 - acc: 0.9865 - val_loss: 0.9767 - val_acc: 0.8065\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0139 - acc: 0.9946 - val_loss: 0.8611 - val_acc: 0.8266\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0310 - acc: 0.9879 - val_loss: 1.0219 - val_acc: 0.8065\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0644 - acc: 0.9838 - val_loss: 1.0019 - val_acc: 0.8065\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0197 - acc: 0.9919 - val_loss: 0.8555 - val_acc: 0.8105\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0292 - acc: 0.9892 - val_loss: 0.9696 - val_acc: 0.8024\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0139 - acc: 0.9946 - val_loss: 1.0801 - val_acc: 0.8024\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0322 - acc: 0.9919 - val_loss: 0.9317 - val_acc: 0.7863\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0125 - acc: 0.9946 - val_loss: 0.8804 - val_acc: 0.8024\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0235 - acc: 0.9933 - val_loss: 1.0441 - val_acc: 0.7903\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0220 - acc: 0.9919 - val_loss: 1.4643 - val_acc: 0.7379\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0487 - acc: 0.9906 - val_loss: 0.8848 - val_acc: 0.8145\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0158 - acc: 0.9973 - val_loss: 1.0664 - val_acc: 0.7984\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0175 - acc: 0.9946 - val_loss: 1.0270 - val_acc: 0.8145\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0302 - acc: 0.9892 - val_loss: 1.1187 - val_acc: 0.7823\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0423 - acc: 0.9865 - val_loss: 1.2051 - val_acc: 0.8065\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0237 - acc: 0.9906 - val_loss: 1.2109 - val_acc: 0.7823\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0275 - acc: 0.9892 - val_loss: 0.9904 - val_acc: 0.7984\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0815 - acc: 0.9717 - val_loss: 1.2459 - val_acc: 0.7379\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0263 - acc: 0.9906 - val_loss: 0.7940 - val_acc: 0.8427\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0783 - acc: 0.9798 - val_loss: 0.7944 - val_acc: 0.8226\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0415 - acc: 0.9892 - val_loss: 0.8326 - val_acc: 0.8347\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0152 - acc: 0.9946 - val_loss: 0.9871 - val_acc: 0.8105\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0330 - acc: 0.9879 - val_loss: 0.9368 - val_acc: 0.8145\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0470 - acc: 0.9852 - val_loss: 0.9078 - val_acc: 0.7944\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.9268 - val_acc: 0.7944\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 0.8560 - val_acc: 0.8185\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.9493 - val_acc: 0.7944\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0357 - acc: 0.9865 - val_loss: 0.9016 - val_acc: 0.8266\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0340 - acc: 0.9933 - val_loss: 1.0845 - val_acc: 0.7782\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0430 - acc: 0.9865 - val_loss: 0.8323 - val_acc: 0.8306\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0373 - acc: 0.9879 - val_loss: 0.7998 - val_acc: 0.8266\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.9782 - val_acc: 0.8024\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.8017 - val_acc: 0.8347\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0311 - acc: 0.9865 - val_loss: 0.9110 - val_acc: 0.8226\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0643 - acc: 0.9865 - val_loss: 1.1102 - val_acc: 0.7863\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0159 - acc: 0.9946 - val_loss: 0.9704 - val_acc: 0.8145\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0451 - acc: 0.9892 - val_loss: 0.9889 - val_acc: 0.7782\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0405 - acc: 0.9865 - val_loss: 0.8793 - val_acc: 0.8105\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0252 - acc: 0.9906 - val_loss: 1.0224 - val_acc: 0.7823\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0271 - acc: 0.9946 - val_loss: 0.9816 - val_acc: 0.7823\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0457 - acc: 0.9919 - val_loss: 1.1285 - val_acc: 0.7581\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 0.8689 - val_acc: 0.8065\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0389 - acc: 0.9919 - val_loss: 0.8927 - val_acc: 0.8427\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0560 - acc: 0.9838 - val_loss: 1.2466 - val_acc: 0.7419\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0218 - acc: 0.9946 - val_loss: 0.9198 - val_acc: 0.8065\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0344 - acc: 0.9919 - val_loss: 0.8214 - val_acc: 0.8306\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.8145\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 1.0453 - val_acc: 0.7944\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0443 - acc: 0.9919 - val_loss: 1.0866 - val_acc: 0.8065\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9086 - val_acc: 0.8347\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0800 - acc: 0.9798 - val_loss: 1.3742 - val_acc: 0.7419\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0139 - acc: 0.9973 - val_loss: 0.9807 - val_acc: 0.8105\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.9488 - val_acc: 0.8266\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0221 - acc: 0.9919 - val_loss: 1.0743 - val_acc: 0.8105\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0270 - acc: 0.9919 - val_loss: 1.2903 - val_acc: 0.7944\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0254 - acc: 0.9892 - val_loss: 1.3415 - val_acc: 0.7702\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0372 - acc: 0.9906 - val_loss: 1.0533 - val_acc: 0.8105\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0305 - acc: 0.9919 - val_loss: 1.1973 - val_acc: 0.7782\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0184 - acc: 0.9919 - val_loss: 0.9367 - val_acc: 0.8266\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0304 - acc: 0.9919 - val_loss: 1.2583 - val_acc: 0.7581\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0599 - acc: 0.9825 - val_loss: 1.5599 - val_acc: 0.7339\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0329 - acc: 0.9852 - val_loss: 1.1118 - val_acc: 0.7863\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0145 - acc: 0.9946 - val_loss: 0.9353 - val_acc: 0.8266\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0078 - acc: 0.9960 - val_loss: 0.9636 - val_acc: 0.8347\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0386 - acc: 0.9919 - val_loss: 1.0898 - val_acc: 0.8065\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0244 - acc: 0.9906 - val_loss: 1.0853 - val_acc: 0.7984\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0252 - acc: 0.9946 - val_loss: 1.2680 - val_acc: 0.7742\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0145 - acc: 0.9960 - val_loss: 1.1224 - val_acc: 0.8024\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0399 - acc: 0.9892 - val_loss: 1.1269 - val_acc: 0.7863\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0337 - acc: 0.9892 - val_loss: 1.0477 - val_acc: 0.8024\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.9880 - val_acc: 0.8105\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0162 - acc: 0.9946 - val_loss: 1.0778 - val_acc: 0.8226\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0527 - acc: 0.9784 - val_loss: 0.9633 - val_acc: 0.8266\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0353 - acc: 0.9879 - val_loss: 1.0591 - val_acc: 0.8024\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0494 - acc: 0.9946 - val_loss: 0.8905 - val_acc: 0.8185\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0193 - acc: 0.9946 - val_loss: 1.2530 - val_acc: 0.7782\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0252 - acc: 0.9892 - val_loss: 0.9507 - val_acc: 0.8145\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0289 - acc: 0.9933 - val_loss: 0.8542 - val_acc: 0.8266\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0138 - acc: 0.9946 - val_loss: 1.1489 - val_acc: 0.7984\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0198 - acc: 0.9919 - val_loss: 1.1701 - val_acc: 0.8024\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 1.0021 - val_acc: 0.8226\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0309 - acc: 0.9919 - val_loss: 1.1210 - val_acc: 0.7823\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 343us/step - loss: 0.0299 - acc: 0.9919 - val_loss: 1.0974 - val_acc: 0.7782\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0177 - acc: 0.9933 - val_loss: 0.9966 - val_acc: 0.7944\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0080 - acc: 0.9973 - val_loss: 1.0836 - val_acc: 0.7984\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0221 - acc: 0.9960 - val_loss: 1.1888 - val_acc: 0.7984\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0623 - acc: 0.9838 - val_loss: 1.0101 - val_acc: 0.7782\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0217 - acc: 0.9906 - val_loss: 1.3040 - val_acc: 0.7782\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0399 - acc: 0.9865 - val_loss: 1.3011 - val_acc: 0.7702\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0327 - acc: 0.9946 - val_loss: 1.0677 - val_acc: 0.8065\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0213 - acc: 0.9946 - val_loss: 1.1175 - val_acc: 0.7702\n",
      "Epoch 601/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0120 - acc: 0.9946 - val_loss: 1.1537 - val_acc: 0.7823\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0188 - acc: 0.9946 - val_loss: 1.5140 - val_acc: 0.7460\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0284 - acc: 0.9906 - val_loss: 1.3031 - val_acc: 0.7661\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0147 - acc: 0.9933 - val_loss: 1.7486 - val_acc: 0.7621\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0176 - acc: 0.9933 - val_loss: 1.7344 - val_acc: 0.7540\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0417 - acc: 0.9946 - val_loss: 1.3859 - val_acc: 0.7944\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0656 - acc: 0.9852 - val_loss: 1.2276 - val_acc: 0.8024\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0079 - acc: 0.9960 - val_loss: 1.0210 - val_acc: 0.7944\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0240 - acc: 0.9946 - val_loss: 0.9259 - val_acc: 0.8266\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0247 - acc: 0.9906 - val_loss: 1.2768 - val_acc: 0.7782\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 0s 351us/step - loss: 0.0308 - acc: 0.9919 - val_loss: 1.1107 - val_acc: 0.8024\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0313 - acc: 0.9946 - val_loss: 1.0503 - val_acc: 0.8105\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0445 - acc: 0.9906 - val_loss: 0.8315 - val_acc: 0.8266\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.8734 - val_acc: 0.8185\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.9772 - val_acc: 0.8185\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0238 - acc: 0.9946 - val_loss: 1.1202 - val_acc: 0.7863\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0094 - acc: 0.9987 - val_loss: 1.1695 - val_acc: 0.8065\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0192 - acc: 0.9960 - val_loss: 0.9266 - val_acc: 0.8306\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.9626 - val_acc: 0.8306\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0077 - acc: 0.9960 - val_loss: 1.0458 - val_acc: 0.8105\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0108 - acc: 0.9973 - val_loss: 1.3817 - val_acc: 0.7661\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0395 - acc: 0.9919 - val_loss: 0.8258 - val_acc: 0.8266\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.8254 - val_acc: 0.8145\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0222 - acc: 0.9906 - val_loss: 0.9482 - val_acc: 0.8065\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0269 - acc: 0.9933 - val_loss: 1.0553 - val_acc: 0.7984\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0217 - acc: 0.9919 - val_loss: 1.2776 - val_acc: 0.7621\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0696 - acc: 0.9852 - val_loss: 1.3945 - val_acc: 0.7540\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0263 - acc: 0.9933 - val_loss: 1.2745 - val_acc: 0.7581\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0422 - acc: 0.9892 - val_loss: 0.9150 - val_acc: 0.7863\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0120 - acc: 0.9973 - val_loss: 0.9876 - val_acc: 0.7903\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0133 - acc: 0.9919 - val_loss: 1.0819 - val_acc: 0.7944\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0074 - acc: 0.9973 - val_loss: 1.0523 - val_acc: 0.7903\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0622 - acc: 0.9825 - val_loss: 1.0263 - val_acc: 0.7984\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0359 - acc: 0.9906 - val_loss: 0.9127 - val_acc: 0.8105\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0151 - acc: 0.9960 - val_loss: 0.9107 - val_acc: 0.8185\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0390 - acc: 0.9865 - val_loss: 0.8018 - val_acc: 0.8347\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0575 - acc: 0.9879 - val_loss: 1.0552 - val_acc: 0.8185\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0215 - acc: 0.9933 - val_loss: 1.0139 - val_acc: 0.7944\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 1.0546 - val_acc: 0.8105\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0221 - acc: 0.9960 - val_loss: 1.0976 - val_acc: 0.8024\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0456 - acc: 0.9865 - val_loss: 1.1732 - val_acc: 0.7903\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0343 - acc: 0.9906 - val_loss: 0.7846 - val_acc: 0.8347\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0091 - acc: 0.9960 - val_loss: 0.8562 - val_acc: 0.8024\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0466 - acc: 0.9865 - val_loss: 1.0380 - val_acc: 0.7984\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0391 - acc: 0.9919 - val_loss: 0.7928 - val_acc: 0.8226\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 0s 349us/step - loss: 0.0203 - acc: 0.9933 - val_loss: 0.9194 - val_acc: 0.8468\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 0s 348us/step - loss: 0.0133 - acc: 0.9946 - val_loss: 1.1269 - val_acc: 0.8105\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0238 - acc: 0.9906 - val_loss: 0.9654 - val_acc: 0.8306\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0466 - acc: 0.9852 - val_loss: 0.9950 - val_acc: 0.8105\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0219 - acc: 0.9933 - val_loss: 1.0539 - val_acc: 0.8145\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 0s 352us/step - loss: 0.0196 - acc: 0.9892 - val_loss: 1.3616 - val_acc: 0.7782\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0367 - acc: 0.9865 - val_loss: 1.1125 - val_acc: 0.7944\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.0321 - val_acc: 0.8266\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 0s 348us/step - loss: 0.0191 - acc: 0.9919 - val_loss: 1.2065 - val_acc: 0.7823\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0079 - acc: 0.9973 - val_loss: 1.1153 - val_acc: 0.7984\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0223 - acc: 0.9919 - val_loss: 1.1102 - val_acc: 0.8065\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0474 - acc: 0.9852 - val_loss: 0.9552 - val_acc: 0.8347\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.8693 - val_acc: 0.8306\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0355 - acc: 0.9906 - val_loss: 1.0657 - val_acc: 0.7782\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 1.0730 - val_acc: 0.7984\n",
      "Epoch 661/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0585 - acc: 0.9906 - val_loss: 1.0324 - val_acc: 0.8185\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0284 - acc: 0.9892 - val_loss: 1.1116 - val_acc: 0.8105\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0234 - acc: 0.9946 - val_loss: 1.0668 - val_acc: 0.8065\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0096 - acc: 0.9960 - val_loss: 1.0672 - val_acc: 0.7984\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.9774 - val_acc: 0.8024\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0337 - acc: 0.9919 - val_loss: 1.3338 - val_acc: 0.7702\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0093 - acc: 0.9960 - val_loss: 0.9591 - val_acc: 0.8145\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0157 - acc: 0.9933 - val_loss: 0.8869 - val_acc: 0.8347\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0376 - acc: 0.9933 - val_loss: 1.1201 - val_acc: 0.8024\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0258 - acc: 0.9933 - val_loss: 0.8458 - val_acc: 0.8306\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0330 - acc: 0.9946 - val_loss: 0.7760 - val_acc: 0.8347\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0158 - acc: 0.9946 - val_loss: 1.0328 - val_acc: 0.8185\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.9586 - val_acc: 0.8306\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.9596 - val_acc: 0.8145\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0353 - acc: 0.9960 - val_loss: 1.0760 - val_acc: 0.7984\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.8347 - val_acc: 0.8226\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0100 - acc: 0.9987 - val_loss: 0.9728 - val_acc: 0.8185\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0117 - acc: 0.9973 - val_loss: 0.9112 - val_acc: 0.8347\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0784 - acc: 0.9838 - val_loss: 0.9202 - val_acc: 0.8105\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0531 - acc: 0.9838 - val_loss: 0.8337 - val_acc: 0.8226\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0244 - acc: 0.9960 - val_loss: 1.1731 - val_acc: 0.7903\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0275 - acc: 0.9933 - val_loss: 0.8255 - val_acc: 0.8266\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0116 - acc: 0.9973 - val_loss: 1.0645 - val_acc: 0.7863\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0400 - acc: 0.9892 - val_loss: 0.8519 - val_acc: 0.8387\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.9424 - val_acc: 0.8226\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0182 - acc: 0.9933 - val_loss: 0.8198 - val_acc: 0.8427\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0057 - acc: 0.9973 - val_loss: 1.0770 - val_acc: 0.7984\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 1.0458 - val_acc: 0.8145\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0753 - acc: 0.9865 - val_loss: 0.8769 - val_acc: 0.8347\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0536 - acc: 0.9879 - val_loss: 1.1615 - val_acc: 0.7823\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0261 - acc: 0.9906 - val_loss: 0.9387 - val_acc: 0.8145\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0292 - acc: 0.9946 - val_loss: 1.2098 - val_acc: 0.7944\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0067 - acc: 0.9987 - val_loss: 1.0654 - val_acc: 0.8024\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0492 - acc: 0.9906 - val_loss: 0.8511 - val_acc: 0.8387\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0366 - acc: 0.9919 - val_loss: 0.8181 - val_acc: 0.8306\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 0s 353us/step - loss: 0.0311 - acc: 0.9933 - val_loss: 0.9465 - val_acc: 0.8065\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0318 - acc: 0.9919 - val_loss: 0.8538 - val_acc: 0.8065\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0193 - acc: 0.9919 - val_loss: 0.8626 - val_acc: 0.8185\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 0s 351us/step - loss: 0.0278 - acc: 0.9919 - val_loss: 1.2026 - val_acc: 0.7903\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0367 - acc: 0.9892 - val_loss: 0.8267 - val_acc: 0.8306\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.8053 - val_acc: 0.8266\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0510 - acc: 0.9906 - val_loss: 0.8978 - val_acc: 0.8306\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 0s 349us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 1.0106 - val_acc: 0.8065\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0089 - acc: 0.9960 - val_loss: 0.9300 - val_acc: 0.8387\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9350 - val_acc: 0.8347\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0205 - acc: 0.9960 - val_loss: 1.3249 - val_acc: 0.7903\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 0s 350us/step - loss: 0.0162 - acc: 0.9933 - val_loss: 1.0138 - val_acc: 0.8387\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0278 - acc: 0.9919 - val_loss: 0.9076 - val_acc: 0.8387\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0253 - acc: 0.9906 - val_loss: 1.1461 - val_acc: 0.8024\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 344us/step - loss: 0.0212 - acc: 0.9919 - val_loss: 1.0170 - val_acc: 0.8145\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 0s 331us/step - loss: 0.0248 - acc: 0.9946 - val_loss: 0.9788 - val_acc: 0.8024\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.9592 - val_acc: 0.8226\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 0s 349us/step - loss: 0.0255 - acc: 0.9919 - val_loss: 1.1109 - val_acc: 0.7782\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 0s 349us/step - loss: 0.0291 - acc: 0.9879 - val_loss: 1.0615 - val_acc: 0.7984\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.9963 - val_acc: 0.8145\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.8821 - val_acc: 0.8266\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0114 - acc: 0.9960 - val_loss: 0.8711 - val_acc: 0.8226\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0195 - acc: 0.9960 - val_loss: 1.3650 - val_acc: 0.7823\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0316 - acc: 0.9892 - val_loss: 1.0825 - val_acc: 0.8185\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0958 - acc: 0.9771 - val_loss: 1.0444 - val_acc: 0.7742\n",
      "Epoch 721/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0241 - acc: 0.9933 - val_loss: 0.8719 - val_acc: 0.8306\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.8358 - val_acc: 0.8226\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0215 - acc: 0.9960 - val_loss: 1.0006 - val_acc: 0.8024\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0551 - acc: 0.9919 - val_loss: 0.9460 - val_acc: 0.8185\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0163 - acc: 0.9960 - val_loss: 0.9796 - val_acc: 0.8065\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.8320 - val_acc: 0.8266\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0365 - acc: 0.9933 - val_loss: 0.8789 - val_acc: 0.8266\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 1.4462 - val_acc: 0.7540\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0213 - acc: 0.9919 - val_loss: 1.0798 - val_acc: 0.8226\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0225 - acc: 0.9919 - val_loss: 1.3176 - val_acc: 0.7823\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0468 - acc: 0.9879 - val_loss: 0.9742 - val_acc: 0.8226\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0245 - acc: 0.9933 - val_loss: 1.0744 - val_acc: 0.7984\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0224 - acc: 0.9946 - val_loss: 1.0800 - val_acc: 0.8226\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0402 - acc: 0.9919 - val_loss: 1.0218 - val_acc: 0.8105\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0084 - acc: 0.9960 - val_loss: 0.9802 - val_acc: 0.8226\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0293 - acc: 0.9946 - val_loss: 1.0606 - val_acc: 0.7903\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0202 - acc: 0.9946 - val_loss: 1.1030 - val_acc: 0.7984\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.0554 - val_acc: 0.8065\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0483 - acc: 0.9879 - val_loss: 0.9788 - val_acc: 0.8266\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 0s 335us/step - loss: 0.0311 - acc: 0.9946 - val_loss: 1.6134 - val_acc: 0.7379\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0484 - acc: 0.9906 - val_loss: 1.0106 - val_acc: 0.8105\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0512 - acc: 0.9933 - val_loss: 1.0237 - val_acc: 0.8024\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0337 - acc: 0.9946 - val_loss: 0.9855 - val_acc: 0.8145\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 1.0217 - val_acc: 0.8105\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0257 - acc: 0.9960 - val_loss: 1.0796 - val_acc: 0.7984\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0165 - acc: 0.9973 - val_loss: 1.0517 - val_acc: 0.7903\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 1.1343 - val_acc: 0.8024\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0501 - acc: 0.9852 - val_loss: 0.9546 - val_acc: 0.8185\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0397 - acc: 0.9892 - val_loss: 1.1383 - val_acc: 0.7984\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.9807 - val_acc: 0.8105\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0160 - acc: 0.9946 - val_loss: 1.0618 - val_acc: 0.8024\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0081 - acc: 0.9973 - val_loss: 1.1227 - val_acc: 0.7702\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0143 - acc: 0.9973 - val_loss: 0.9465 - val_acc: 0.7944\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0212 - acc: 0.9919 - val_loss: 0.9323 - val_acc: 0.8065\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0875 - acc: 0.9798 - val_loss: 0.9301 - val_acc: 0.8065\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.9138 - val_acc: 0.8105\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0321 - acc: 0.9906 - val_loss: 0.8989 - val_acc: 0.7984\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0516 - acc: 0.9879 - val_loss: 0.9586 - val_acc: 0.8065\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 1.0322 - val_acc: 0.7742\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0555 - acc: 0.9865 - val_loss: 0.9704 - val_acc: 0.7903\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0233 - acc: 0.9933 - val_loss: 1.0303 - val_acc: 0.7903\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.8669 - val_acc: 0.8185\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0213 - acc: 0.9946 - val_loss: 0.9321 - val_acc: 0.8024\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.9450 - val_acc: 0.8065\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0107 - acc: 0.9973 - val_loss: 1.3933 - val_acc: 0.7419\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0274 - acc: 0.9933 - val_loss: 0.9180 - val_acc: 0.8266\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0074 - acc: 0.9960 - val_loss: 1.3756 - val_acc: 0.7661\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0298 - acc: 0.9933 - val_loss: 1.0165 - val_acc: 0.8024\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0236 - acc: 0.9960 - val_loss: 0.8163 - val_acc: 0.8548\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0106 - acc: 0.9987 - val_loss: 0.9834 - val_acc: 0.8185\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0051 - acc: 0.9973 - val_loss: 0.9966 - val_acc: 0.7863\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0199 - acc: 0.9973 - val_loss: 0.8695 - val_acc: 0.8306\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0380 - acc: 0.9892 - val_loss: 0.8222 - val_acc: 0.8589\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0272 - acc: 0.9919 - val_loss: 0.8505 - val_acc: 0.8548\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0326 - acc: 0.9906 - val_loss: 1.4573 - val_acc: 0.7540\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.9206 - val_acc: 0.8347\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0169 - acc: 0.9919 - val_loss: 0.8969 - val_acc: 0.8266\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0240 - acc: 0.9919 - val_loss: 1.0546 - val_acc: 0.8065\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0235 - acc: 0.9946 - val_loss: 0.9291 - val_acc: 0.8105\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0193 - acc: 0.9973 - val_loss: 1.0243 - val_acc: 0.8185\n",
      "Epoch 781/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.9625 - val_acc: 0.8266\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0335 - acc: 0.9919 - val_loss: 1.1940 - val_acc: 0.8226\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0350 - acc: 0.9906 - val_loss: 1.0245 - val_acc: 0.8347\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0190 - acc: 0.9933 - val_loss: 1.4320 - val_acc: 0.7621\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0544 - acc: 0.9892 - val_loss: 0.8424 - val_acc: 0.8508\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0160 - acc: 0.9960 - val_loss: 1.0482 - val_acc: 0.8024\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0409 - acc: 0.9906 - val_loss: 1.1458 - val_acc: 0.8226\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0170 - acc: 0.9960 - val_loss: 0.9999 - val_acc: 0.8266\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.9588 - val_acc: 0.8347\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 1.1086 - val_acc: 0.8105\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0243 - acc: 0.9933 - val_loss: 1.1218 - val_acc: 0.8185\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0107 - acc: 0.9973 - val_loss: 1.0137 - val_acc: 0.8468\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0150 - acc: 0.9946 - val_loss: 1.0460 - val_acc: 0.8306\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0435 - acc: 0.9919 - val_loss: 0.9861 - val_acc: 0.8105\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0363 - acc: 0.9892 - val_loss: 1.4566 - val_acc: 0.7661\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0750 - acc: 0.9852 - val_loss: 0.8510 - val_acc: 0.8226\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0084 - acc: 0.9946 - val_loss: 0.9554 - val_acc: 0.8266\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0169 - acc: 0.9973 - val_loss: 0.8975 - val_acc: 0.8145\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0095 - acc: 0.9973 - val_loss: 0.8354 - val_acc: 0.8468\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0140 - acc: 0.9946 - val_loss: 0.9243 - val_acc: 0.8226\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0136 - acc: 0.9946 - val_loss: 0.9136 - val_acc: 0.8427\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0309 - acc: 0.9946 - val_loss: 1.0955 - val_acc: 0.8145\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0347 - acc: 0.9933 - val_loss: 0.8901 - val_acc: 0.8589\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0789 - acc: 0.9865 - val_loss: 0.7738 - val_acc: 0.8548\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.8447 - val_acc: 0.8548\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.8923 - val_acc: 0.8548\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0125 - acc: 0.9973 - val_loss: 1.2162 - val_acc: 0.7782\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0165 - acc: 0.9933 - val_loss: 1.1758 - val_acc: 0.8065\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0323 - acc: 0.9919 - val_loss: 1.1251 - val_acc: 0.8266\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0052 - acc: 0.9987 - val_loss: 1.3116 - val_acc: 0.7863\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0309 - acc: 0.9919 - val_loss: 1.3390 - val_acc: 0.7903\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0159 - acc: 0.9933 - val_loss: 1.3511 - val_acc: 0.7984\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0225 - acc: 0.9919 - val_loss: 1.3549 - val_acc: 0.7984\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0188 - acc: 0.9919 - val_loss: 1.1682 - val_acc: 0.8266\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0371 - acc: 0.9919 - val_loss: 1.3791 - val_acc: 0.7984\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0305 - acc: 0.9933 - val_loss: 1.1789 - val_acc: 0.8024\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0315 - acc: 0.9919 - val_loss: 1.1179 - val_acc: 0.7984\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0126 - acc: 0.9960 - val_loss: 1.0592 - val_acc: 0.7903\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0160 - acc: 0.9946 - val_loss: 1.3671 - val_acc: 0.7661\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0239 - acc: 0.9919 - val_loss: 1.0370 - val_acc: 0.8065\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0070 - acc: 0.9973 - val_loss: 0.9710 - val_acc: 0.8145\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0079 - acc: 0.9973 - val_loss: 1.2148 - val_acc: 0.8105\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.9734 - val_acc: 0.8226\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0585 - acc: 0.9879 - val_loss: 1.2086 - val_acc: 0.7944\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0349 - acc: 0.9879 - val_loss: 1.0101 - val_acc: 0.7944\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0244 - acc: 0.9892 - val_loss: 1.0567 - val_acc: 0.8105\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0257 - acc: 0.9960 - val_loss: 1.1532 - val_acc: 0.8065\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 344us/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.9773 - val_acc: 0.8226\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0164 - acc: 0.9919 - val_loss: 1.1971 - val_acc: 0.8145\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0432 - acc: 0.9933 - val_loss: 0.8414 - val_acc: 0.8387\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0274 - acc: 0.9933 - val_loss: 0.8963 - val_acc: 0.8427\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.9717 - val_acc: 0.8427\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0316 - acc: 0.9906 - val_loss: 1.1701 - val_acc: 0.7984\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 1.1306 - val_acc: 0.8145\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0215 - acc: 0.9933 - val_loss: 1.3662 - val_acc: 0.7742\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0115 - acc: 0.9946 - val_loss: 1.0367 - val_acc: 0.8266\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0227 - acc: 0.9946 - val_loss: 1.2444 - val_acc: 0.7944\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0074 - acc: 0.9960 - val_loss: 1.0013 - val_acc: 0.8387\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.8427\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0690 - acc: 0.9838 - val_loss: 0.9632 - val_acc: 0.8347\n",
      "Epoch 841/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0149 - acc: 0.9946 - val_loss: 0.9374 - val_acc: 0.8427\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0405 - acc: 0.9906 - val_loss: 0.8585 - val_acc: 0.8508\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0214 - acc: 0.9946 - val_loss: 1.1402 - val_acc: 0.8306\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0148 - acc: 0.9960 - val_loss: 1.1803 - val_acc: 0.8226\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0317 - acc: 0.9919 - val_loss: 0.8704 - val_acc: 0.8427\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0175 - acc: 0.9946 - val_loss: 0.9071 - val_acc: 0.8589\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0236 - acc: 0.9946 - val_loss: 1.0467 - val_acc: 0.8226\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0122 - acc: 0.9946 - val_loss: 0.9380 - val_acc: 0.8306\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0114 - acc: 0.9973 - val_loss: 1.0841 - val_acc: 0.8105\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0107 - acc: 0.9987 - val_loss: 1.1727 - val_acc: 0.8387\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0523 - acc: 0.9892 - val_loss: 1.1554 - val_acc: 0.8226\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 1.3111 - val_acc: 0.8065\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0109 - acc: 0.9960 - val_loss: 1.1020 - val_acc: 0.8347\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.9526 - val_acc: 0.8468\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0146 - acc: 0.9919 - val_loss: 1.2602 - val_acc: 0.8185\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.9113 - val_acc: 0.8468\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0516 - acc: 0.9906 - val_loss: 1.0225 - val_acc: 0.8306\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.8871 - val_acc: 0.8387\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0157 - acc: 0.9933 - val_loss: 1.3202 - val_acc: 0.8105\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0228 - acc: 0.9973 - val_loss: 1.1306 - val_acc: 0.8266\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 0.0562 - acc: 0.9879 - val_loss: 1.1648 - val_acc: 0.8226\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0175 - acc: 0.9960 - val_loss: 1.0245 - val_acc: 0.8185\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0116 - acc: 0.9946 - val_loss: 1.0723 - val_acc: 0.8226\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0147 - acc: 0.9946 - val_loss: 0.8514 - val_acc: 0.8427\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0170 - acc: 0.9933 - val_loss: 1.1159 - val_acc: 0.8145\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0077 - acc: 0.9960 - val_loss: 1.2691 - val_acc: 0.8105\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 1.2510 - val_acc: 0.8145\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0250 - acc: 0.9919 - val_loss: 1.2286 - val_acc: 0.7944\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0187 - acc: 0.9973 - val_loss: 0.9409 - val_acc: 0.8387\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0115 - acc: 0.9960 - val_loss: 1.0316 - val_acc: 0.8185\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0411 - acc: 0.9865 - val_loss: 1.2617 - val_acc: 0.8185\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0492 - acc: 0.9892 - val_loss: 1.0314 - val_acc: 0.8266\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0092 - acc: 0.9973 - val_loss: 1.0368 - val_acc: 0.8226\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0218 - acc: 0.9946 - val_loss: 1.0326 - val_acc: 0.8306\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 1.0486 - val_acc: 0.8266\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 0s 347us/step - loss: 0.0523 - acc: 0.9798 - val_loss: 0.8704 - val_acc: 0.8306\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0314 - acc: 0.9946 - val_loss: 1.1054 - val_acc: 0.8347\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.9454 - val_acc: 0.8185\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 1.0511 - val_acc: 0.8065\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.9609 - val_acc: 0.8145\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0082 - acc: 0.9960 - val_loss: 0.9406 - val_acc: 0.8347\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0106 - acc: 0.9987 - val_loss: 1.1530 - val_acc: 0.7984\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0120 - acc: 0.9946 - val_loss: 1.0194 - val_acc: 0.8306\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0073 - acc: 0.9960 - val_loss: 1.0450 - val_acc: 0.8306\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0087 - acc: 0.9987 - val_loss: 0.9895 - val_acc: 0.8427\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0255 - acc: 0.9919 - val_loss: 1.1200 - val_acc: 0.8145\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0410 - acc: 0.9933 - val_loss: 0.9757 - val_acc: 0.8387\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.8697 - val_acc: 0.8347\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0261 - acc: 0.9906 - val_loss: 0.8220 - val_acc: 0.8508\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.9050 - val_acc: 0.8387\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0058 - acc: 0.9987 - val_loss: 1.0609 - val_acc: 0.8347\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0288 - acc: 0.9960 - val_loss: 0.8561 - val_acc: 0.8468\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.9089 - val_acc: 0.8468\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.9685 - val_acc: 0.8508\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.9997 - val_acc: 0.8266\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 1.1750 - val_acc: 0.7984\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0526 - acc: 0.9811 - val_loss: 0.8507 - val_acc: 0.8508\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0238 - acc: 0.9933 - val_loss: 0.8956 - val_acc: 0.8306\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0212 - acc: 0.9960 - val_loss: 1.2876 - val_acc: 0.8185 \n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0064 - acc: 0.9987 - val_loss: 1.2320 - val_acc: 0.8347\n",
      "Epoch 901/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0170 - acc: 0.9960 - val_loss: 1.1083 - val_acc: 0.8105\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0106 - acc: 0.9960 - val_loss: 1.1625 - val_acc: 0.8347\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0188 - acc: 0.9933 - val_loss: 0.9491 - val_acc: 0.8508\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0242 - acc: 0.9919 - val_loss: 1.1896 - val_acc: 0.8306\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0540 - acc: 0.9906 - val_loss: 1.3019 - val_acc: 0.8145\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0395 - acc: 0.9933 - val_loss: 1.0402 - val_acc: 0.8266\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 1.1597 - val_acc: 0.7984\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0297 - acc: 0.9906 - val_loss: 1.0137 - val_acc: 0.8306\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0199 - acc: 0.9919 - val_loss: 0.9500 - val_acc: 0.8306\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0193 - acc: 0.9960 - val_loss: 1.1498 - val_acc: 0.8145\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0153 - acc: 0.9960 - val_loss: 0.8148 - val_acc: 0.8387\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0342 - acc: 0.9960 - val_loss: 0.8958 - val_acc: 0.8306\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0073 - acc: 0.9960 - val_loss: 1.0210 - val_acc: 0.8105\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0047 - acc: 0.9973 - val_loss: 0.9802 - val_acc: 0.8306\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0241 - acc: 0.9919 - val_loss: 1.0397 - val_acc: 0.8226\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.8201 - val_acc: 0.8468\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.7787 - val_acc: 0.8790\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.7508 - val_acc: 0.8629\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0386 - acc: 0.9865 - val_loss: 0.9487 - val_acc: 0.8468\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0207 - acc: 0.9946 - val_loss: 1.0066 - val_acc: 0.8548\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0295 - acc: 0.9933 - val_loss: 0.7560 - val_acc: 0.8669\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0345 - acc: 0.9919 - val_loss: 1.0477 - val_acc: 0.8306\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0254 - acc: 0.9906 - val_loss: 0.8622 - val_acc: 0.8548\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0102 - acc: 0.9946 - val_loss: 1.0344 - val_acc: 0.8185\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0255 - acc: 0.9960 - val_loss: 0.8481 - val_acc: 0.8306\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0351 - acc: 0.9933 - val_loss: 0.8656 - val_acc: 0.8387\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0056 - acc: 0.9987 - val_loss: 1.0174 - val_acc: 0.8306\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0164 - acc: 0.9933 - val_loss: 0.8787 - val_acc: 0.8427\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0380 - acc: 0.9906 - val_loss: 0.8566 - val_acc: 0.8185\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0318 - acc: 0.9906 - val_loss: 1.3728 - val_acc: 0.7742\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0260 - acc: 0.9933 - val_loss: 0.9389 - val_acc: 0.8306\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0827 - acc: 0.9919 - val_loss: 0.7854 - val_acc: 0.8347\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0218 - acc: 0.9973 - val_loss: 1.1789 - val_acc: 0.7863\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0219 - acc: 0.9960 - val_loss: 0.9000 - val_acc: 0.8306\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.7691 - val_acc: 0.8589\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 0s 333us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.9866 - val_acc: 0.8387\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.9494 - val_acc: 0.8468\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0029 - acc: 0.9987 - val_loss: 0.9695 - val_acc: 0.8427\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.9215 - val_acc: 0.8347\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0392 - acc: 0.9852 - val_loss: 1.1127 - val_acc: 0.8145\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.9003 - val_acc: 0.8185\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0185 - acc: 0.9987 - val_loss: 0.8670 - val_acc: 0.8427\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0176 - acc: 0.9933 - val_loss: 1.0353 - val_acc: 0.8266\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0114 - acc: 0.9960 - val_loss: 1.1297 - val_acc: 0.7984\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0281 - acc: 0.9960 - val_loss: 0.9327 - val_acc: 0.8468\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 339us/step - loss: 0.0253 - acc: 0.9933 - val_loss: 0.8473 - val_acc: 0.8508\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0277 - acc: 0.9933 - val_loss: 0.7719 - val_acc: 0.8750\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0194 - acc: 0.9933 - val_loss: 0.8887 - val_acc: 0.8427\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0348 - acc: 0.9919 - val_loss: 0.9850 - val_acc: 0.8226\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 0s 343us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.9281 - val_acc: 0.8347\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0074 - acc: 0.9987 - val_loss: 0.9022 - val_acc: 0.8468\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0234 - acc: 0.9960 - val_loss: 1.1205 - val_acc: 0.8024\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0461 - acc: 0.9892 - val_loss: 1.0039 - val_acc: 0.8226\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0218 - acc: 0.9946 - val_loss: 1.0363 - val_acc: 0.8427\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.9941 - val_acc: 0.8226\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0054 - acc: 0.9973 - val_loss: 0.9553 - val_acc: 0.8347\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.8226\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.9452 - val_acc: 0.8427\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0441 - acc: 0.9933 - val_loss: 0.8662 - val_acc: 0.8548\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0430 - acc: 0.9906 - val_loss: 1.1419 - val_acc: 0.8105\n",
      "Epoch 961/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.8737 - val_acc: 0.8508\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0147 - acc: 0.9906 - val_loss: 0.8422 - val_acc: 0.8387\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0167 - acc: 0.9906 - val_loss: 1.1100 - val_acc: 0.8266\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0149 - acc: 0.9960 - val_loss: 1.0762 - val_acc: 0.8306\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0129 - acc: 0.9946 - val_loss: 1.1002 - val_acc: 0.8024\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 0s 333us/step - loss: 0.0223 - acc: 0.9933 - val_loss: 1.0957 - val_acc: 0.8226\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0265 - acc: 0.9933 - val_loss: 1.1357 - val_acc: 0.8347\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0533 - acc: 0.9919 - val_loss: 0.8341 - val_acc: 0.8266\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0157 - acc: 0.9933 - val_loss: 0.9194 - val_acc: 0.8508\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0173 - acc: 0.9946 - val_loss: 0.8108 - val_acc: 0.8306\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.7124 - val_acc: 0.8508\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7006 - val_acc: 0.8548\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.8223 - val_acc: 0.8226\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 0s 345us/step - loss: 4.8193e-04 - acc: 1.0000 - val_loss: 0.8954 - val_acc: 0.8145\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0263 - acc: 0.9933 - val_loss: 1.0592 - val_acc: 0.8468\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0204 - acc: 0.9906 - val_loss: 0.8638 - val_acc: 0.8548\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0269 - acc: 0.9960 - val_loss: 1.1678 - val_acc: 0.8145\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 0s 333us/step - loss: 0.0277 - acc: 0.9919 - val_loss: 1.3821 - val_acc: 0.8105\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0458 - acc: 0.9919 - val_loss: 0.8954 - val_acc: 0.8468\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0104 - acc: 0.9946 - val_loss: 0.7824 - val_acc: 0.8629\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0320 - acc: 0.9946 - val_loss: 0.8496 - val_acc: 0.8468\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0191 - acc: 0.9933 - val_loss: 0.9725 - val_acc: 0.8226\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 0s 346us/step - loss: 0.0030 - acc: 0.9987 - val_loss: 0.9531 - val_acc: 0.8306\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0087 - acc: 0.9960 - val_loss: 1.1195 - val_acc: 0.8226\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0271 - acc: 0.9946 - val_loss: 0.9687 - val_acc: 0.8508\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0579 - acc: 0.9906 - val_loss: 0.8217 - val_acc: 0.8629\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.8753 - val_acc: 0.8589\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0078 - acc: 0.9960 - val_loss: 0.8480 - val_acc: 0.8710\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0029 - acc: 0.9987 - val_loss: 0.9424 - val_acc: 0.8508\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 0s 339us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0147 - val_acc: 0.8508\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0397 - acc: 0.9906 - val_loss: 0.9275 - val_acc: 0.8629\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 0s 340us/step - loss: 0.0257 - acc: 0.9933 - val_loss: 0.9734 - val_acc: 0.8306\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.9697 - val_acc: 0.8427\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 0s 344us/step - loss: 0.0331 - acc: 0.9933 - val_loss: 0.9464 - val_acc: 0.8387\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 0s 337us/step - loss: 0.0207 - acc: 0.9960 - val_loss: 0.8823 - val_acc: 0.8387\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0057 - acc: 0.9973 - val_loss: 0.9119 - val_acc: 0.8427\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 0s 342us/step - loss: 0.0142 - acc: 0.9946 - val_loss: 0.9284 - val_acc: 0.8508\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 0s 341us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 1.1637 - val_acc: 0.8347\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 0s 338us/step - loss: 0.0365 - acc: 0.9892 - val_loss: 1.0182 - val_acc: 0.8065\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 0s 336us/step - loss: 0.0241 - acc: 0.9933 - val_loss: 0.9971 - val_acc: 0.8105\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, epochs=1000, batch_size=128, validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be46208ef0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果：拟合训练集的精度已经很可以了，同时对测试数据的预测精度也有了提升；\n",
    "\n",
    "但是：过拟合问题又出现了！—— 需要用dropout抑制一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化3："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上一种情况卷积池化后，再多加一个dropout层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(64, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(128, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(256, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(256, 7, activation='relu', padding='same'))\n",
    "model.add(layers.Dropout(0.5))  # 新加的！\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 3s 4ms/step - loss: 4.6020 - acc: 0.0121 - val_loss: 4.5928 - val_acc: 0.0121\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 0s 664us/step - loss: 4.5692 - acc: 0.0094 - val_loss: 4.4928 - val_acc: 0.0161\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 1s 702us/step - loss: 4.5218 - acc: 0.0202 - val_loss: 4.5121 - val_acc: 0.0242\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 1s 798us/step - loss: 4.4283 - acc: 0.0270 - val_loss: 4.3559 - val_acc: 0.0202\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 4.3433 - acc: 0.0175 - val_loss: 4.2694 - val_acc: 0.0161\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 1s 931us/step - loss: 4.2840 - acc: 0.0148 - val_loss: 4.2282 - val_acc: 0.0202\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 4.2204 - acc: 0.0202 - val_loss: 4.1876 - val_acc: 0.0081\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 1s 843us/step - loss: 4.1448 - acc: 0.0162 - val_loss: 4.2668 - val_acc: 0.0161\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 4.1156 - acc: 0.0270 - val_loss: 4.1500 - val_acc: 0.0121\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 4.0457 - acc: 0.0243 - val_loss: 4.2520 - val_acc: 0.0202\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 4.0089 - acc: 0.0350 - val_loss: 4.2709 - val_acc: 0.0161\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 1s 959us/step - loss: 3.9196 - acc: 0.0364 - val_loss: 3.9562 - val_acc: 0.0282\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 3.8837 - acc: 0.0445 - val_loss: 4.0469 - val_acc: 0.0161\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 3.7950 - acc: 0.0472 - val_loss: 4.5036 - val_acc: 0.0121\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 3.7307 - acc: 0.0485 - val_loss: 3.7925 - val_acc: 0.0444\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 3.6314 - acc: 0.0620 - val_loss: 4.6363 - val_acc: 0.0040\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 1s 970us/step - loss: 3.5785 - acc: 0.0768 - val_loss: 4.0498 - val_acc: 0.0242\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 3.5329 - acc: 0.0633 - val_loss: 3.7410 - val_acc: 0.0282\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 1s 820us/step - loss: 3.4662 - acc: 0.0822 - val_loss: 3.7026 - val_acc: 0.0565\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 3.3717 - acc: 0.0795 - val_loss: 3.5261 - val_acc: 0.0645\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 3.2375 - acc: 0.1199 - val_loss: 3.6842 - val_acc: 0.0645\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 3.1917 - acc: 0.1038 - val_loss: 3.6564 - val_acc: 0.0484\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 3.1368 - acc: 0.1240 - val_loss: 3.4322 - val_acc: 0.0806\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 3.0625 - acc: 0.1523 - val_loss: 3.3785 - val_acc: 0.1089\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 0s 666us/step - loss: 3.0135 - acc: 0.1456 - val_loss: 4.4008 - val_acc: 0.0202\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 2.8698 - acc: 0.1712 - val_loss: 5.0109 - val_acc: 0.0040\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 2.8799 - acc: 0.1779 - val_loss: 2.8848 - val_acc: 0.2097\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 2.8292 - acc: 0.1927 - val_loss: 3.1728 - val_acc: 0.1210\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 2.7897 - acc: 0.1833 - val_loss: 3.4104 - val_acc: 0.1089\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 2.7174 - acc: 0.2102 - val_loss: 4.1638 - val_acc: 0.0444\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 1s 680us/step - loss: 2.6709 - acc: 0.1995 - val_loss: 4.0666 - val_acc: 0.0323\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 1s 685us/step - loss: 2.5904 - acc: 0.2305 - val_loss: 4.4239 - val_acc: 0.0202\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 1s 689us/step - loss: 2.5763 - acc: 0.2237 - val_loss: 3.5105 - val_acc: 0.0524\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 1s 679us/step - loss: 2.5350 - acc: 0.2385 - val_loss: 3.4129 - val_acc: 0.1532\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 2.5192 - acc: 0.2480 - val_loss: 3.8924 - val_acc: 0.0524\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 0s 669us/step - loss: 2.4960 - acc: 0.2493 - val_loss: 3.6768 - val_acc: 0.0484\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 0s 668us/step - loss: 2.3700 - acc: 0.2615 - val_loss: 3.3225 - val_acc: 0.1371\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 0s 666us/step - loss: 2.3883 - acc: 0.2925 - val_loss: 3.6108 - val_acc: 0.0565\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 0s 663us/step - loss: 2.3170 - acc: 0.3261 - val_loss: 4.2778 - val_acc: 0.0645\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 2.1890 - acc: 0.2925 - val_loss: 3.2679 - val_acc: 0.1169\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 2.2251 - acc: 0.3248 - val_loss: 3.0655 - val_acc: 0.1169\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 2.2126 - acc: 0.3194 - val_loss: 2.9616 - val_acc: 0.1492\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 2.1126 - acc: 0.3288 - val_loss: 3.3402 - val_acc: 0.1411\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 1s 794us/step - loss: 2.1278 - acc: 0.3396 - val_loss: 3.6695 - val_acc: 0.0887\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 2.0656 - acc: 0.3477 - val_loss: 2.6117 - val_acc: 0.2177\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 1.9980 - acc: 0.3922 - val_loss: 4.0270 - val_acc: 0.0565\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 1.9864 - acc: 0.3733 - val_loss: 3.3066 - val_acc: 0.1452\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 1.9225 - acc: 0.3760 - val_loss: 3.5956 - val_acc: 0.0726\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 1.8327 - acc: 0.4178 - val_loss: 2.6365 - val_acc: 0.1855\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 1.8314 - acc: 0.4084 - val_loss: 5.0576 - val_acc: 0.0242\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 1.8688 - acc: 0.3881 - val_loss: 5.0442 - val_acc: 0.0323\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 1s 756us/step - loss: 1.7615 - acc: 0.4218 - val_loss: 3.0869 - val_acc: 0.1734\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 1.8012 - acc: 0.4164 - val_loss: 3.2960 - val_acc: 0.1613\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 1.7054 - acc: 0.4488 - val_loss: 2.1159 - val_acc: 0.3427\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 1s 701us/step - loss: 1.6865 - acc: 0.4528 - val_loss: 2.8130 - val_acc: 0.2621\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 1s 677us/step - loss: 1.6529 - acc: 0.4636 - val_loss: 1.8727 - val_acc: 0.4395\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 1.6356 - acc: 0.4542 - val_loss: 4.3008 - val_acc: 0.0726\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 1.5857 - acc: 0.4704 - val_loss: 3.5324 - val_acc: 0.1694\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 1.5897 - acc: 0.5148 - val_loss: 2.2643 - val_acc: 0.3145\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 1.5123 - acc: 0.5027 - val_loss: 1.8401 - val_acc: 0.4274\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 1.5327 - acc: 0.5000 - val_loss: 2.7809 - val_acc: 0.2419\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 1s 694us/step - loss: 1.4293 - acc: 0.5337 - val_loss: 3.8041 - val_acc: 0.1290\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 1.5300 - acc: 0.5256 - val_loss: 2.5142 - val_acc: 0.2984\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 1s 694us/step - loss: 1.2964 - acc: 0.5701 - val_loss: 2.4226 - val_acc: 0.3266\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 1s 755us/step - loss: 1.3234 - acc: 0.5606 - val_loss: 2.4180 - val_acc: 0.2984\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 1.4181 - acc: 0.5364 - val_loss: 2.6910 - val_acc: 0.2661\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 1.3145 - acc: 0.5633 - val_loss: 3.6025 - val_acc: 0.1371\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 1.2860 - acc: 0.5701 - val_loss: 3.8336 - val_acc: 0.1452\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 1.2680 - acc: 0.5741 - val_loss: 3.0781 - val_acc: 0.2460\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 1.2504 - acc: 0.5876 - val_loss: 2.5214 - val_acc: 0.2903\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 1.1550 - acc: 0.6038 - val_loss: 1.9035 - val_acc: 0.4637\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 1s 799us/step - loss: 1.1357 - acc: 0.6105 - val_loss: 3.2542 - val_acc: 0.2581\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 1s 782us/step - loss: 1.1191 - acc: 0.6469 - val_loss: 1.8987 - val_acc: 0.4355\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 1s 768us/step - loss: 1.1137 - acc: 0.6429 - val_loss: 2.5125 - val_acc: 0.3347\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 1.0939 - acc: 0.6361 - val_loss: 2.8877 - val_acc: 0.3145\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 1.1252 - acc: 0.6173 - val_loss: 5.0584 - val_acc: 0.1250\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 1.0315 - acc: 0.6509 - val_loss: 2.2976 - val_acc: 0.3992\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 1s 689us/step - loss: 1.0330 - acc: 0.6765 - val_loss: 1.9804 - val_acc: 0.4556\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 1s 694us/step - loss: 0.9736 - acc: 0.6712 - val_loss: 3.1951 - val_acc: 0.2218\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 1s 675us/step - loss: 1.0159 - acc: 0.6617 - val_loss: 3.5730 - val_acc: 0.1774\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 0s 673us/step - loss: 0.9086 - acc: 0.6968 - val_loss: 1.6607 - val_acc: 0.5161\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.8968 - acc: 0.7156 - val_loss: 1.5689 - val_acc: 0.5565\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 1s 804us/step - loss: 0.8305 - acc: 0.7197 - val_loss: 2.4338 - val_acc: 0.3790\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 1s 857us/step - loss: 0.8413 - acc: 0.7116 - val_loss: 3.0569 - val_acc: 0.3105\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 0.9593 - acc: 0.6968 - val_loss: 2.3011 - val_acc: 0.3831\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 1s 805us/step - loss: 0.9041 - acc: 0.7089 - val_loss: 2.8298 - val_acc: 0.3105\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.8328 - acc: 0.7399 - val_loss: 1.7023 - val_acc: 0.5524\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 0.7919 - acc: 0.7507 - val_loss: 5.4675 - val_acc: 0.1653\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.8164 - acc: 0.7372 - val_loss: 3.1645 - val_acc: 0.3347\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 1s 844us/step - loss: 0.7652 - acc: 0.7547 - val_loss: 2.0736 - val_acc: 0.4919\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 1s 825us/step - loss: 0.7845 - acc: 0.7601 - val_loss: 1.6290 - val_acc: 0.5645\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.7547 - acc: 0.7628 - val_loss: 3.2268 - val_acc: 0.3669\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.7295 - acc: 0.7547 - val_loss: 1.9762 - val_acc: 0.4879\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.7367 - acc: 0.7695 - val_loss: 2.8554 - val_acc: 0.3427\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.7108 - acc: 0.7615 - val_loss: 1.6724 - val_acc: 0.5242\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.6129 - acc: 0.7817 - val_loss: 2.2587 - val_acc: 0.4315\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 0.6592 - acc: 0.7830 - val_loss: 2.1191 - val_acc: 0.4677\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 0s 656us/step - loss: 0.6543 - acc: 0.7830 - val_loss: 3.4431 - val_acc: 0.2823\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 1s 748us/step - loss: 0.6229 - acc: 0.7844 - val_loss: 2.0721 - val_acc: 0.5081\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.6397 - acc: 0.7830 - val_loss: 1.6273 - val_acc: 0.5242\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.5732 - acc: 0.8019 - val_loss: 2.0522 - val_acc: 0.5202\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.5875 - acc: 0.7965 - val_loss: 2.6616 - val_acc: 0.4556\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.5502 - acc: 0.8235 - val_loss: 2.4522 - val_acc: 0.4435\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.5496 - acc: 0.8221 - val_loss: 1.3376 - val_acc: 0.6653\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.5646 - acc: 0.7965 - val_loss: 1.7457 - val_acc: 0.5685\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.5307 - acc: 0.8194 - val_loss: 1.6823 - val_acc: 0.5524\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.5439 - acc: 0.8248 - val_loss: 1.8764 - val_acc: 0.5444\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 0s 655us/step - loss: 0.5276 - acc: 0.8383 - val_loss: 2.5973 - val_acc: 0.4355\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 1s 678us/step - loss: 0.5626 - acc: 0.8181 - val_loss: 2.0660 - val_acc: 0.5242\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 1s 676us/step - loss: 0.5809 - acc: 0.8073 - val_loss: 1.9173 - val_acc: 0.5645\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.4811 - acc: 0.8261 - val_loss: 1.6807 - val_acc: 0.5887\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.5381 - acc: 0.8194 - val_loss: 2.5509 - val_acc: 0.4315\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.5509 - acc: 0.8275 - val_loss: 2.6522 - val_acc: 0.4315\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.4949 - acc: 0.8477 - val_loss: 2.5846 - val_acc: 0.3629\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.4359 - acc: 0.8598 - val_loss: 1.9040 - val_acc: 0.5444\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 1s 685us/step - loss: 0.5268 - acc: 0.8302 - val_loss: 1.6143 - val_acc: 0.6048\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.4758 - acc: 0.8531 - val_loss: 2.3521 - val_acc: 0.4798\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.4844 - acc: 0.8329 - val_loss: 2.0118 - val_acc: 0.5161\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.4605 - acc: 0.8598 - val_loss: 1.3541 - val_acc: 0.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.4584 - acc: 0.8450 - val_loss: 1.4030 - val_acc: 0.6452\n",
      "Epoch 121/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.4393 - acc: 0.8531 - val_loss: 2.6163 - val_acc: 0.4153\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.4463 - acc: 0.8693 - val_loss: 1.2851 - val_acc: 0.6532\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.4352 - acc: 0.8598 - val_loss: 2.1825 - val_acc: 0.5403\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.3967 - acc: 0.8639 - val_loss: 2.0706 - val_acc: 0.4960\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 0s 672us/step - loss: 0.4147 - acc: 0.8612 - val_loss: 2.3156 - val_acc: 0.4798\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.4231 - acc: 0.8679 - val_loss: 1.5909 - val_acc: 0.5605\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 1s 702us/step - loss: 0.3308 - acc: 0.8827 - val_loss: 1.5636 - val_acc: 0.6169\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 0s 673us/step - loss: 0.4548 - acc: 0.8518 - val_loss: 1.2104 - val_acc: 0.6895\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.3888 - acc: 0.8679 - val_loss: 1.9491 - val_acc: 0.4758\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 0.3965 - acc: 0.8706 - val_loss: 1.7054 - val_acc: 0.5968\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.3535 - acc: 0.8922 - val_loss: 1.8383 - val_acc: 0.5806\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 1s 680us/step - loss: 0.3273 - acc: 0.8962 - val_loss: 3.5374 - val_acc: 0.3952\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 1s 705us/step - loss: 0.3305 - acc: 0.8841 - val_loss: 1.7842 - val_acc: 0.5403\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.3705 - acc: 0.8922 - val_loss: 1.4358 - val_acc: 0.6331\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 0s 671us/step - loss: 0.3108 - acc: 0.8895 - val_loss: 1.2691 - val_acc: 0.7056\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.3538 - acc: 0.9016 - val_loss: 3.0603 - val_acc: 0.4677\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 1s 684us/step - loss: 0.4176 - acc: 0.8733 - val_loss: 1.1013 - val_acc: 0.7097\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 1s 691us/step - loss: 0.3267 - acc: 0.9016 - val_loss: 1.1949 - val_acc: 0.6694\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.3490 - acc: 0.8854 - val_loss: 1.6005 - val_acc: 0.6169\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 0s 653us/step - loss: 0.2776 - acc: 0.9097 - val_loss: 1.8398 - val_acc: 0.5847\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.3349 - acc: 0.8922 - val_loss: 1.5857 - val_acc: 0.6371\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.2759 - acc: 0.9003 - val_loss: 1.6482 - val_acc: 0.6411\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 0s 661us/step - loss: 0.3288 - acc: 0.8827 - val_loss: 1.2041 - val_acc: 0.6895\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.3052 - acc: 0.9030 - val_loss: 1.8772 - val_acc: 0.5887\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 0s 666us/step - loss: 0.2881 - acc: 0.9016 - val_loss: 2.2024 - val_acc: 0.5605\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 1s 701us/step - loss: 0.3133 - acc: 0.9057 - val_loss: 1.2613 - val_acc: 0.6976\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.3451 - acc: 0.8989 - val_loss: 1.2296 - val_acc: 0.7097\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 1s 685us/step - loss: 0.2548 - acc: 0.9191 - val_loss: 1.5137 - val_acc: 0.6008\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.2965 - acc: 0.9016 - val_loss: 1.6878 - val_acc: 0.6169\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 1s 734us/step - loss: 0.3743 - acc: 0.8922 - val_loss: 1.1669 - val_acc: 0.7056\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.3124 - acc: 0.9003 - val_loss: 1.6148 - val_acc: 0.6250\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.2801 - acc: 0.9070 - val_loss: 1.7371 - val_acc: 0.6048\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.4019 - acc: 0.8787 - val_loss: 1.4137 - val_acc: 0.6452\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.2432 - acc: 0.9259 - val_loss: 1.8812 - val_acc: 0.5726\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 1s 831us/step - loss: 0.3232 - acc: 0.9043 - val_loss: 1.2904 - val_acc: 0.6573\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.2476 - acc: 0.9218 - val_loss: 1.3775 - val_acc: 0.6815\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.3242 - acc: 0.9016 - val_loss: 2.4725 - val_acc: 0.5161\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.2010 - acc: 0.9313 - val_loss: 1.8918 - val_acc: 0.5968\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.3021 - acc: 0.9097 - val_loss: 1.2302 - val_acc: 0.6653\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.2441 - acc: 0.9205 - val_loss: 1.7596 - val_acc: 0.5927\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.2710 - acc: 0.9164 - val_loss: 2.0077 - val_acc: 0.5323\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 1s 755us/step - loss: 0.2456 - acc: 0.9178 - val_loss: 1.1912 - val_acc: 0.7016\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.3231 - acc: 0.8908 - val_loss: 1.4747 - val_acc: 0.6532\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.2267 - acc: 0.9299 - val_loss: 1.1312 - val_acc: 0.7298\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.2322 - acc: 0.9326 - val_loss: 2.5471 - val_acc: 0.5161\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.2915 - acc: 0.9286 - val_loss: 1.0316 - val_acc: 0.7137\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.1800 - acc: 0.9474 - val_loss: 1.3810 - val_acc: 0.6815\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.2837 - acc: 0.9151 - val_loss: 1.3179 - val_acc: 0.6895\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.2386 - acc: 0.9272 - val_loss: 1.4698 - val_acc: 0.6411\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.2274 - acc: 0.9326 - val_loss: 1.4454 - val_acc: 0.6452\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.2526 - acc: 0.9259 - val_loss: 1.2236 - val_acc: 0.6815\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 1s 694us/step - loss: 0.1954 - acc: 0.9313 - val_loss: 1.1208 - val_acc: 0.7500\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.2577 - acc: 0.9245 - val_loss: 3.6335 - val_acc: 0.3911\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 0.2529 - acc: 0.9299 - val_loss: 1.4808 - val_acc: 0.6532\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.2488 - acc: 0.9326 - val_loss: 1.2349 - val_acc: 0.6976\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 1s 698us/step - loss: 0.2312 - acc: 0.9286 - val_loss: 1.2129 - val_acc: 0.7137\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 0.2674 - acc: 0.9299 - val_loss: 1.1027 - val_acc: 0.7258\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.1618 - acc: 0.9407 - val_loss: 2.0683 - val_acc: 0.5605\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.2207 - acc: 0.9394 - val_loss: 1.7217 - val_acc: 0.6290\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.2088 - acc: 0.9447 - val_loss: 2.9941 - val_acc: 0.4919\n",
      "Epoch 181/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.2448 - acc: 0.9326 - val_loss: 1.6320 - val_acc: 0.6452\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 1s 705us/step - loss: 0.1852 - acc: 0.9407 - val_loss: 0.8345 - val_acc: 0.7782\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.2746 - acc: 0.9043 - val_loss: 1.1945 - val_acc: 0.7097\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 0.1808 - acc: 0.9461 - val_loss: 0.9276 - val_acc: 0.7621\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.2190 - acc: 0.9407 - val_loss: 1.3298 - val_acc: 0.7016\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.2534 - acc: 0.9218 - val_loss: 0.8821 - val_acc: 0.7661\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2523 - acc: 0.9191 - val_loss: 1.3720 - val_acc: 0.6774\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.1833 - acc: 0.9474 - val_loss: 0.9956 - val_acc: 0.7702\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 1s 684us/step - loss: 0.1964 - acc: 0.9528 - val_loss: 1.2287 - val_acc: 0.6976\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2091 - acc: 0.9407 - val_loss: 1.6253 - val_acc: 0.6210\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 1s 689us/step - loss: 0.1779 - acc: 0.9488 - val_loss: 1.1478 - val_acc: 0.6935\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.1349 - acc: 0.9515 - val_loss: 1.4261 - val_acc: 0.6935\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1963 - acc: 0.9407 - val_loss: 1.5471 - val_acc: 0.6774\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.2343 - acc: 0.9340 - val_loss: 1.3940 - val_acc: 0.7056\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1701 - acc: 0.9569 - val_loss: 1.5875 - val_acc: 0.6452\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.2651 - acc: 0.9299 - val_loss: 1.1899 - val_acc: 0.7419\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 0s 673us/step - loss: 0.2303 - acc: 0.9515 - val_loss: 1.4180 - val_acc: 0.7177\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.2126 - acc: 0.9461 - val_loss: 1.7956 - val_acc: 0.6331\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 0s 663us/step - loss: 0.2158 - acc: 0.9528 - val_loss: 1.1137 - val_acc: 0.7339\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1947 - acc: 0.9501 - val_loss: 1.3151 - val_acc: 0.7097\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.2273 - acc: 0.940 - 1s 686us/step - loss: 0.2178 - acc: 0.9434 - val_loss: 1.1386 - val_acc: 0.7460\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 0.1609 - acc: 0.9528 - val_loss: 0.9983 - val_acc: 0.7581\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 0.1985 - acc: 0.9420 - val_loss: 1.0574 - val_acc: 0.7339\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1362 - acc: 0.9677 - val_loss: 1.1990 - val_acc: 0.7419\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 1s 701us/step - loss: 0.2319 - acc: 0.9367 - val_loss: 1.0142 - val_acc: 0.7500\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.2013 - acc: 0.9447 - val_loss: 1.2637 - val_acc: 0.7339\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.2003 - acc: 0.9340 - val_loss: 0.8318 - val_acc: 0.7782\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.1398 - acc: 0.9488 - val_loss: 0.7907 - val_acc: 0.8024\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1978 - acc: 0.9326 - val_loss: 0.9802 - val_acc: 0.7903\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1981 - acc: 0.9367 - val_loss: 1.0386 - val_acc: 0.7460\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2379 - acc: 0.9447 - val_loss: 0.8587 - val_acc: 0.8065\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.1573 - acc: 0.9515 - val_loss: 0.9472 - val_acc: 0.7903\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 1s 823us/step - loss: 0.2237 - acc: 0.9394 - val_loss: 1.2839 - val_acc: 0.7339\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1225 - acc: 0.9690 - val_loss: 1.1839 - val_acc: 0.7460\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1374 - acc: 0.9650 - val_loss: 1.0079 - val_acc: 0.7742\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1345 - acc: 0.9569 - val_loss: 2.6994 - val_acc: 0.6008\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.2011 - acc: 0.9528 - val_loss: 1.0445 - val_acc: 0.7460\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1740 - acc: 0.9461 - val_loss: 0.9417 - val_acc: 0.7863\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1844 - acc: 0.9447 - val_loss: 1.2092 - val_acc: 0.7298\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.1842 - acc: 0.9501 - val_loss: 1.3758 - val_acc: 0.6895\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1320 - acc: 0.9542 - val_loss: 1.0892 - val_acc: 0.7863\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1736 - acc: 0.9461 - val_loss: 0.8694 - val_acc: 0.7621\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1693 - acc: 0.9501 - val_loss: 1.0739 - val_acc: 0.7581\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1433 - acc: 0.9609 - val_loss: 1.5381 - val_acc: 0.6935\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 1s 754us/step - loss: 0.1932 - acc: 0.9407 - val_loss: 0.8986 - val_acc: 0.7903\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 1s 802us/step - loss: 0.1478 - acc: 0.9569 - val_loss: 1.3681 - val_acc: 0.7016\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.1570 - acc: 0.9555 - val_loss: 1.3402 - val_acc: 0.7258\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 1s 808us/step - loss: 0.1100 - acc: 0.9717 - val_loss: 1.7285 - val_acc: 0.6573\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.2292 - acc: 0.9340 - val_loss: 0.8089 - val_acc: 0.8185\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.1731 - acc: 0.9434 - val_loss: 1.7343 - val_acc: 0.6774\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0834 - acc: 0.9757 - val_loss: 1.3003 - val_acc: 0.7137\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1676 - acc: 0.9596 - val_loss: 1.0438 - val_acc: 0.7782\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1555 - acc: 0.9582 - val_loss: 1.2806 - val_acc: 0.7460\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 1s 680us/step - loss: 0.1237 - acc: 0.9555 - val_loss: 1.2869 - val_acc: 0.7540\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.1543 - acc: 0.9582 - val_loss: 1.3980 - val_acc: 0.7218\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.1808 - acc: 0.9515 - val_loss: 1.2991 - val_acc: 0.7298\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 0.2193 - acc: 0.9501 - val_loss: 0.9095 - val_acc: 0.7944\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 738us/step - loss: 0.1338 - acc: 0.9596 - val_loss: 1.0892 - val_acc: 0.7500\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 0.1279 - acc: 0.9582 - val_loss: 1.5667 - val_acc: 0.7056\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.2181 - acc: 0.9299 - val_loss: 1.8664 - val_acc: 0.6210\n",
      "Epoch 241/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1792 - acc: 0.9461 - val_loss: 1.0810 - val_acc: 0.7298\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.1166 - acc: 0.9650 - val_loss: 0.9015 - val_acc: 0.8065\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.1386 - acc: 0.9609 - val_loss: 1.0283 - val_acc: 0.7500\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.1509 - acc: 0.9609 - val_loss: 1.7953 - val_acc: 0.6573\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.1520 - acc: 0.9528 - val_loss: 0.7722 - val_acc: 0.7782\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.0908 - acc: 0.9717 - val_loss: 1.2339 - val_acc: 0.7661\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.1755 - acc: 0.9582 - val_loss: 1.5794 - val_acc: 0.7258\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1856 - acc: 0.9555 - val_loss: 1.1727 - val_acc: 0.7339\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 0.1437 - acc: 0.9569 - val_loss: 0.8987 - val_acc: 0.7903\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 1s 727us/step - loss: 0.2092 - acc: 0.9474 - val_loss: 1.2898 - val_acc: 0.7218\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.1814 - acc: 0.9501 - val_loss: 0.7635 - val_acc: 0.8145\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 0s 669us/step - loss: 0.1571 - acc: 0.9623 - val_loss: 0.9510 - val_acc: 0.7903\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1303 - acc: 0.9569 - val_loss: 1.0451 - val_acc: 0.7460\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.2140 - acc: 0.9515 - val_loss: 0.9406 - val_acc: 0.7823\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 0.1063 - acc: 0.9704 - val_loss: 0.9892 - val_acc: 0.7500\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.1359 - acc: 0.9623 - val_loss: 0.7272 - val_acc: 0.8065\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.1553 - acc: 0.9636 - val_loss: 1.0905 - val_acc: 0.7661\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.2297 - acc: 0.9488 - val_loss: 2.3238 - val_acc: 0.5565\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.1620 - acc: 0.9515 - val_loss: 0.8433 - val_acc: 0.8065\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1384 - acc: 0.9609 - val_loss: 1.0366 - val_acc: 0.7823\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.1092 - acc: 0.9636 - val_loss: 0.8461 - val_acc: 0.8105\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 1s 678us/step - loss: 0.1261 - acc: 0.9623 - val_loss: 1.0969 - val_acc: 0.7702\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 1s 702us/step - loss: 0.1269 - acc: 0.9663 - val_loss: 0.9007 - val_acc: 0.7944\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.2579 - acc: 0.9380 - val_loss: 0.9232 - val_acc: 0.7823\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 1s 694us/step - loss: 0.1210 - acc: 0.9663 - val_loss: 0.7484 - val_acc: 0.8226\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1779 - acc: 0.9515 - val_loss: 0.9174 - val_acc: 0.7823\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.1157 - acc: 0.9623 - val_loss: 0.6538 - val_acc: 0.8185\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1448 - acc: 0.9501 - val_loss: 0.9235 - val_acc: 0.8024\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.1634 - acc: 0.9555 - val_loss: 0.9571 - val_acc: 0.8024\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 1s 684us/step - loss: 0.0957 - acc: 0.9690 - val_loss: 1.2779 - val_acc: 0.7742\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1385 - acc: 0.9690 - val_loss: 0.9063 - val_acc: 0.7903\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.1773 - acc: 0.9636 - val_loss: 1.0259 - val_acc: 0.7782\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 1s 691us/step - loss: 0.1525 - acc: 0.9636 - val_loss: 0.8533 - val_acc: 0.7984\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 1s 747us/step - loss: 0.1362 - acc: 0.9596 - val_loss: 0.8346 - val_acc: 0.8024\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 0.1783 - acc: 0.9501 - val_loss: 0.8924 - val_acc: 0.7944\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 1s 677us/step - loss: 0.0833 - acc: 0.9744 - val_loss: 0.9209 - val_acc: 0.7984\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.1145 - acc: 0.9623 - val_loss: 1.0315 - val_acc: 0.7702\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 0s 666us/step - loss: 0.1155 - acc: 0.9690 - val_loss: 0.8041 - val_acc: 0.8266\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.0934 - acc: 0.9798 - val_loss: 0.8650 - val_acc: 0.8065\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.0942 - acc: 0.9757 - val_loss: 0.8940 - val_acc: 0.7984\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.1074 - acc: 0.9663 - val_loss: 0.7842 - val_acc: 0.8145\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 1s 732us/step - loss: 0.1678 - acc: 0.9596 - val_loss: 1.2522 - val_acc: 0.7218\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1727 - acc: 0.9609 - val_loss: 1.1617 - val_acc: 0.7379\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1188 - acc: 0.9596 - val_loss: 0.7717 - val_acc: 0.8105\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.0996 - acc: 0.9690 - val_loss: 0.9410 - val_acc: 0.8065\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 0s 664us/step - loss: 0.1328 - acc: 0.9582 - val_loss: 1.6900 - val_acc: 0.6895\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1479 - acc: 0.9650 - val_loss: 1.0134 - val_acc: 0.7419\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1183 - acc: 0.9663 - val_loss: 1.1064 - val_acc: 0.7782\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.1565 - acc: 0.9690 - val_loss: 0.7605 - val_acc: 0.8065\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1384 - acc: 0.9609 - val_loss: 0.7132 - val_acc: 0.8145\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.1551 - acc: 0.9582 - val_loss: 0.9951 - val_acc: 0.7782\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.1260 - acc: 0.9677 - val_loss: 0.8215 - val_acc: 0.7903\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.1467 - acc: 0.9663 - val_loss: 0.8710 - val_acc: 0.8185\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 1s 682us/step - loss: 0.1487 - acc: 0.9555 - val_loss: 0.9384 - val_acc: 0.7903\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1427 - acc: 0.9542 - val_loss: 0.9437 - val_acc: 0.7742\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1439 - acc: 0.9690 - val_loss: 0.6802 - val_acc: 0.8266\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 1s 702us/step - loss: 0.1796 - acc: 0.9690 - val_loss: 1.3196 - val_acc: 0.7339\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 1s 756us/step - loss: 0.1327 - acc: 0.9704 - val_loss: 0.9091 - val_acc: 0.8105\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 1s 678us/step - loss: 0.0943 - acc: 0.9704 - val_loss: 1.5024 - val_acc: 0.7016\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.1644 - acc: 0.9636 - val_loss: 0.4839 - val_acc: 0.8589\n",
      "Epoch 301/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1195 - acc: 0.9623 - val_loss: 1.0266 - val_acc: 0.8065\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 1s 685us/step - loss: 0.1334 - acc: 0.9650 - val_loss: 0.8066 - val_acc: 0.8185\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 1s 727us/step - loss: 0.1516 - acc: 0.9501 - val_loss: 1.0308 - val_acc: 0.7903\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.2049 - acc: 0.9528 - val_loss: 1.4182 - val_acc: 0.7702\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 1s 702us/step - loss: 0.1315 - acc: 0.9690 - val_loss: 0.7640 - val_acc: 0.8266\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 1s 789us/step - loss: 0.1104 - acc: 0.9650 - val_loss: 0.7561 - val_acc: 0.8226\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1146 - acc: 0.9623 - val_loss: 0.9520 - val_acc: 0.7823\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.1170 - acc: 0.9636 - val_loss: 0.7317 - val_acc: 0.8387\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 0.1776 - acc: 0.9555 - val_loss: 0.8796 - val_acc: 0.8145\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1319 - acc: 0.9690 - val_loss: 0.8932 - val_acc: 0.8024\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.0904 - acc: 0.9677 - val_loss: 0.7183 - val_acc: 0.8427\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 1s 782us/step - loss: 0.0995 - acc: 0.9730 - val_loss: 0.6900 - val_acc: 0.8306\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.1512 - acc: 0.9582 - val_loss: 0.5898 - val_acc: 0.8548\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 1s 755us/step - loss: 0.2140 - acc: 0.9623 - val_loss: 0.6426 - val_acc: 0.8548\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1355 - acc: 0.9663 - val_loss: 0.9494 - val_acc: 0.7903\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.1113 - acc: 0.9663 - val_loss: 0.8546 - val_acc: 0.7702\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 1s 705us/step - loss: 0.1226 - acc: 0.9677 - val_loss: 1.1350 - val_acc: 0.7621\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1682 - acc: 0.9663 - val_loss: 0.6470 - val_acc: 0.8266\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0637 - acc: 0.9784 - val_loss: 1.1824 - val_acc: 0.7540\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1517 - acc: 0.9609 - val_loss: 0.7708 - val_acc: 0.8266\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.1394 - acc: 0.9582 - val_loss: 0.6375 - val_acc: 0.8306\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.0731 - acc: 0.9744 - val_loss: 0.6959 - val_acc: 0.8468\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.1098 - acc: 0.9717 - val_loss: 2.5202 - val_acc: 0.5726\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1167 - acc: 0.9636 - val_loss: 0.6331 - val_acc: 0.8387\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 0.0961 - acc: 0.9677 - val_loss: 0.8036 - val_acc: 0.8065\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 1s 727us/step - loss: 0.2030 - acc: 0.9609 - val_loss: 0.6884 - val_acc: 0.8347\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1177 - acc: 0.9757 - val_loss: 0.6372 - val_acc: 0.8508\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 1s 734us/step - loss: 0.1649 - acc: 0.9650 - val_loss: 0.7092 - val_acc: 0.8427\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0542 - acc: 0.9825 - val_loss: 0.9111 - val_acc: 0.8387\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1461 - acc: 0.9636 - val_loss: 0.7363 - val_acc: 0.8347\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1747 - acc: 0.9596 - val_loss: 0.7325 - val_acc: 0.8145\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1111 - acc: 0.9784 - val_loss: 0.9472 - val_acc: 0.7903\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.0895 - acc: 0.9717 - val_loss: 0.9544 - val_acc: 0.7944\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1745 - acc: 0.9663 - val_loss: 0.7659 - val_acc: 0.8065\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1052 - acc: 0.9690 - val_loss: 1.7078 - val_acc: 0.6734\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1540 - acc: 0.9569 - val_loss: 0.9181 - val_acc: 0.7903\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 1s 676us/step - loss: 0.1708 - acc: 0.9515 - val_loss: 0.6414 - val_acc: 0.8427\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0904 - acc: 0.9771 - val_loss: 0.6530 - val_acc: 0.8468\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.1262 - acc: 0.9757 - val_loss: 0.6334 - val_acc: 0.8226\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.1638 - acc: 0.9704 - val_loss: 0.8974 - val_acc: 0.7944\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.0511 - acc: 0.9825 - val_loss: 1.1370 - val_acc: 0.7661\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 0s 648us/step - loss: 0.0839 - acc: 0.9744 - val_loss: 0.8190 - val_acc: 0.8306\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.0899 - acc: 0.9730 - val_loss: 0.8767 - val_acc: 0.8306\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 0s 664us/step - loss: 0.1456 - acc: 0.9650 - val_loss: 0.9638 - val_acc: 0.7702\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 0.0726 - acc: 0.9784 - val_loss: 0.7906 - val_acc: 0.8185\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 1s 675us/step - loss: 0.1181 - acc: 0.9730 - val_loss: 0.7029 - val_acc: 0.8306\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 0s 666us/step - loss: 0.0929 - acc: 0.9690 - val_loss: 0.7345 - val_acc: 0.8185\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.1191 - acc: 0.9717 - val_loss: 1.1617 - val_acc: 0.7661\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 1s 681us/step - loss: 0.1213 - acc: 0.9636 - val_loss: 0.7584 - val_acc: 0.8387\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.0654 - acc: 0.9771 - val_loss: 1.0282 - val_acc: 0.7903\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1591 - acc: 0.9704 - val_loss: 0.7613 - val_acc: 0.8347\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 1s 682us/step - loss: 0.1013 - acc: 0.9771 - val_loss: 0.5588 - val_acc: 0.8548\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.0986 - acc: 0.9784 - val_loss: 0.9328 - val_acc: 0.7984\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 1s 682us/step - loss: 0.1793 - acc: 0.9528 - val_loss: 1.0193 - val_acc: 0.7621\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 0s 661us/step - loss: 0.0940 - acc: 0.9704 - val_loss: 1.0730 - val_acc: 0.7742\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 746us/step - loss: 0.1183 - acc: 0.9730 - val_loss: 1.1065 - val_acc: 0.7581\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 1s 680us/step - loss: 0.1447 - acc: 0.9623 - val_loss: 0.8481 - val_acc: 0.8024\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 0s 652us/step - loss: 0.1757 - acc: 0.9609 - val_loss: 1.3397 - val_acc: 0.7258\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.0432 - acc: 0.9852 - val_loss: 0.6933 - val_acc: 0.8347\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 1s 683us/step - loss: 0.0961 - acc: 0.9744 - val_loss: 1.1862 - val_acc: 0.7702\n",
      "Epoch 361/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1157 - acc: 0.9730 - val_loss: 0.8804 - val_acc: 0.8226\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1175 - acc: 0.9771 - val_loss: 0.8316 - val_acc: 0.8185\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.0972 - acc: 0.9757 - val_loss: 1.3904 - val_acc: 0.7500\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1341 - acc: 0.9704 - val_loss: 0.8691 - val_acc: 0.7903\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.1042 - acc: 0.9730 - val_loss: 0.8239 - val_acc: 0.8065\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.0672 - acc: 0.9838 - val_loss: 1.0421 - val_acc: 0.7863\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1338 - acc: 0.9690 - val_loss: 1.1099 - val_acc: 0.7903\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1485 - acc: 0.9542 - val_loss: 0.9110 - val_acc: 0.8024\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1110 - acc: 0.9663 - val_loss: 1.2463 - val_acc: 0.7500\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1211 - acc: 0.9596 - val_loss: 1.3873 - val_acc: 0.7339\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1295 - acc: 0.9677 - val_loss: 0.9397 - val_acc: 0.8185\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.1851 - acc: 0.9690 - val_loss: 1.2126 - val_acc: 0.7621\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 1s 734us/step - loss: 0.1369 - acc: 0.9717 - val_loss: 0.8352 - val_acc: 0.7782\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1219 - acc: 0.9609 - val_loss: 1.1354 - val_acc: 0.7419\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.0884 - acc: 0.9757 - val_loss: 1.0263 - val_acc: 0.7863\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 1s 804us/step - loss: 0.1353 - acc: 0.9744 - val_loss: 0.7261 - val_acc: 0.8065\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.1188 - acc: 0.9730 - val_loss: 0.8500 - val_acc: 0.8105\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.1222 - acc: 0.9690 - val_loss: 0.6451 - val_acc: 0.8306\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 1s 807us/step - loss: 0.1167 - acc: 0.9717 - val_loss: 0.5983 - val_acc: 0.8427\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 1s 828us/step - loss: 0.0948 - acc: 0.9757 - val_loss: 0.8671 - val_acc: 0.7944\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.1125 - acc: 0.9771 - val_loss: 0.6930 - val_acc: 0.8306\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 1s 755us/step - loss: 0.1395 - acc: 0.9650 - val_loss: 0.5979 - val_acc: 0.8589\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1064 - acc: 0.9744 - val_loss: 0.8254 - val_acc: 0.7944\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.1363 - acc: 0.9650 - val_loss: 0.9526 - val_acc: 0.7823\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1036 - acc: 0.9717 - val_loss: 0.8139 - val_acc: 0.8185\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.1532 - acc: 0.9636 - val_loss: 0.4828 - val_acc: 0.8629\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.1034 - acc: 0.9730 - val_loss: 0.4438 - val_acc: 0.8710\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.0658 - acc: 0.9838 - val_loss: 0.9252 - val_acc: 0.8185\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1510 - acc: 0.9650 - val_loss: 0.5059 - val_acc: 0.8508\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 0s 646us/step - loss: 0.1287 - acc: 0.9663 - val_loss: 0.5312 - val_acc: 0.8548\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 1s 727us/step - loss: 0.1312 - acc: 0.9717 - val_loss: 0.7277 - val_acc: 0.8185\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 0s 672us/step - loss: 0.1277 - acc: 0.9744 - val_loss: 1.2934 - val_acc: 0.7460\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0949 - acc: 0.9730 - val_loss: 0.6036 - val_acc: 0.8508\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.0921 - acc: 0.9771 - val_loss: 0.4748 - val_acc: 0.8750\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 0.1602 - acc: 0.9636 - val_loss: 0.7090 - val_acc: 0.8185\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1693 - acc: 0.9609 - val_loss: 0.4721 - val_acc: 0.8871\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1442 - acc: 0.9650 - val_loss: 0.6519 - val_acc: 0.8347\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1489 - acc: 0.9730 - val_loss: 0.7265 - val_acc: 0.8347\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1046 - acc: 0.9730 - val_loss: 0.4937 - val_acc: 0.8790\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.0877 - acc: 0.9784 - val_loss: 0.5570 - val_acc: 0.8871\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 1s 691us/step - loss: 0.0286 - acc: 0.9892 - val_loss: 1.0349 - val_acc: 0.8145\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.0730 - acc: 0.9811 - val_loss: 0.7109 - val_acc: 0.8750\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.0838 - acc: 0.9825 - val_loss: 0.9330 - val_acc: 0.8306\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.2035 - acc: 0.9623 - val_loss: 0.7282 - val_acc: 0.8427\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.0702 - acc: 0.9730 - val_loss: 0.8295 - val_acc: 0.8347\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1074 - acc: 0.9825 - val_loss: 0.8017 - val_acc: 0.8105\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1009 - acc: 0.9717 - val_loss: 0.7258 - val_acc: 0.8347\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1625 - acc: 0.9704 - val_loss: 0.6183 - val_acc: 0.8548\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 1s 681us/step - loss: 0.0932 - acc: 0.9730 - val_loss: 0.8728 - val_acc: 0.8185\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.1094 - acc: 0.9865 - val_loss: 0.8788 - val_acc: 0.8306\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.0714 - acc: 0.9744 - val_loss: 0.7083 - val_acc: 0.8508\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.0785 - acc: 0.9838 - val_loss: 0.7100 - val_acc: 0.8548\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1585 - acc: 0.9690 - val_loss: 0.5518 - val_acc: 0.8710\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.0841 - acc: 0.9811 - val_loss: 1.2301 - val_acc: 0.7702\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.0888 - acc: 0.9771 - val_loss: 0.5497 - val_acc: 0.8871\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 1s 832us/step - loss: 0.1550 - acc: 0.9677 - val_loss: 0.4944 - val_acc: 0.8629\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.0823 - acc: 0.9771 - val_loss: 0.5428 - val_acc: 0.8629\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 1s 882us/step - loss: 0.0655 - acc: 0.9798 - val_loss: 0.6054 - val_acc: 0.8629\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 1s 808us/step - loss: 0.1195 - acc: 0.9757 - val_loss: 0.6688 - val_acc: 0.8306\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 1s 771us/step - loss: 0.0959 - acc: 0.9757 - val_loss: 0.7376 - val_acc: 0.8589\n",
      "Epoch 421/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.0856 - acc: 0.9798 - val_loss: 0.8455 - val_acc: 0.8226\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1798 - acc: 0.9650 - val_loss: 0.6913 - val_acc: 0.8468\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 1s 705us/step - loss: 0.1260 - acc: 0.9704 - val_loss: 0.9672 - val_acc: 0.8065\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 1s 758us/step - loss: 0.1082 - acc: 0.9677 - val_loss: 0.7178 - val_acc: 0.8589\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.1078 - acc: 0.9771 - val_loss: 1.2869 - val_acc: 0.7540\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.1472 - acc: 0.9717 - val_loss: 0.8622 - val_acc: 0.8508\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.1163 - acc: 0.9757 - val_loss: 0.9125 - val_acc: 0.8266\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 1s 677us/step - loss: 0.0897 - acc: 0.9677 - val_loss: 0.7059 - val_acc: 0.8387\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.1098 - acc: 0.9744 - val_loss: 0.6208 - val_acc: 0.8710\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.0700 - acc: 0.9811 - val_loss: 0.8658 - val_acc: 0.8266\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 1s 701us/step - loss: 0.1117 - acc: 0.9771 - val_loss: 0.9578 - val_acc: 0.8306\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.0853 - acc: 0.9757 - val_loss: 0.7405 - val_acc: 0.8508\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.0995 - acc: 0.9784 - val_loss: 0.6882 - val_acc: 0.8790\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 1s 685us/step - loss: 0.1168 - acc: 0.9744 - val_loss: 0.8878 - val_acc: 0.8266\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.1222 - acc: 0.9771 - val_loss: 0.8501 - val_acc: 0.8145\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.0988 - acc: 0.9744 - val_loss: 0.6916 - val_acc: 0.8548\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.0971 - acc: 0.9690 - val_loss: 0.9146 - val_acc: 0.8468\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1090 - acc: 0.9704 - val_loss: 0.6541 - val_acc: 0.8589\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1683 - acc: 0.9582 - val_loss: 0.6802 - val_acc: 0.8508\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.1420 - acc: 0.9690 - val_loss: 0.9089 - val_acc: 0.8185\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.980 - 1s 679us/step - loss: 0.0724 - acc: 0.9798 - val_loss: 0.8441 - val_acc: 0.8468\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.0990 - acc: 0.9798 - val_loss: 0.7999 - val_acc: 0.8347\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.0970 - acc: 0.9771 - val_loss: 0.8207 - val_acc: 0.8387\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.1089 - acc: 0.9690 - val_loss: 0.8715 - val_acc: 0.8427\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.1093 - acc: 0.9811 - val_loss: 0.9804 - val_acc: 0.8548\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1123 - acc: 0.9704 - val_loss: 0.7801 - val_acc: 0.8065\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1277 - acc: 0.9744 - val_loss: 0.5892 - val_acc: 0.8548\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1593 - acc: 0.9623 - val_loss: 0.4934 - val_acc: 0.8629\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.5790 - val_acc: 0.8548\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.0770 - acc: 0.9784 - val_loss: 0.8288 - val_acc: 0.8306\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.1168 - acc: 0.9677 - val_loss: 0.7455 - val_acc: 0.8508\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.1297 - acc: 0.9717 - val_loss: 0.8129 - val_acc: 0.8629\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1832 - acc: 0.9677 - val_loss: 0.6916 - val_acc: 0.8427\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.1444 - acc: 0.9663 - val_loss: 0.8063 - val_acc: 0.8387\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.0682 - acc: 0.9798 - val_loss: 0.8828 - val_acc: 0.8306\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1202 - acc: 0.9704 - val_loss: 0.7919 - val_acc: 0.8266\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1325 - acc: 0.9704 - val_loss: 0.8772 - val_acc: 0.8266\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.1132 - acc: 0.9784 - val_loss: 0.6278 - val_acc: 0.8790\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 0s 668us/step - loss: 0.0682 - acc: 0.9852 - val_loss: 0.6670 - val_acc: 0.8589\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1148 - acc: 0.9771 - val_loss: 1.0967 - val_acc: 0.7944\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1166 - acc: 0.9690 - val_loss: 0.8407 - val_acc: 0.8468\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 1s 688us/step - loss: 0.0734 - acc: 0.9825 - val_loss: 1.4175 - val_acc: 0.7661\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1488 - acc: 0.9663 - val_loss: 0.6426 - val_acc: 0.8508\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.0952 - acc: 0.9852 - val_loss: 0.5533 - val_acc: 0.8669\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.0857 - acc: 0.9798 - val_loss: 0.5449 - val_acc: 0.8790\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 1s 800us/step - loss: 0.1337 - acc: 0.9744 - val_loss: 0.5700 - val_acc: 0.8790\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1353 - acc: 0.9757 - val_loss: 0.7236 - val_acc: 0.8468\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1677 - acc: 0.9690 - val_loss: 0.8090 - val_acc: 0.8266\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 1s 754us/step - loss: 0.0965 - acc: 0.9825 - val_loss: 0.6758 - val_acc: 0.8387\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.1204 - acc: 0.9704 - val_loss: 0.6923 - val_acc: 0.8387\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.0693 - acc: 0.9798 - val_loss: 0.6056 - val_acc: 0.8589\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.1030 - acc: 0.9690 - val_loss: 0.5300 - val_acc: 0.8508\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 0s 670us/step - loss: 0.1521 - acc: 0.9744 - val_loss: 0.7122 - val_acc: 0.8427\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 664us/step - loss: 0.1244 - acc: 0.9730 - val_loss: 0.6668 - val_acc: 0.8710\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.1144 - acc: 0.9717 - val_loss: 0.5744 - val_acc: 0.8669\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.0536 - acc: 0.9865 - val_loss: 0.6453 - val_acc: 0.8387\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.1474 - acc: 0.9677 - val_loss: 0.7177 - val_acc: 0.8387\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1278 - acc: 0.9690 - val_loss: 0.5244 - val_acc: 0.8831\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1142 - acc: 0.9730 - val_loss: 0.6962 - val_acc: 0.8589\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 0s 674us/step - loss: 0.1413 - acc: 0.9663 - val_loss: 0.5906 - val_acc: 0.8750\n",
      "Epoch 481/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.0941 - acc: 0.9811 - val_loss: 0.7070 - val_acc: 0.8790\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 1s 675us/step - loss: 0.1126 - acc: 0.9690 - val_loss: 0.7589 - val_acc: 0.8548\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 0s 663us/step - loss: 0.0871 - acc: 0.9717 - val_loss: 0.5209 - val_acc: 0.9032\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.1017 - acc: 0.9771 - val_loss: 0.4948 - val_acc: 0.8831\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 0s 665us/step - loss: 0.0986 - acc: 0.9811 - val_loss: 0.6724 - val_acc: 0.8871\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 0s 670us/step - loss: 0.0644 - acc: 0.9798 - val_loss: 0.9827 - val_acc: 0.8185\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.0889 - acc: 0.9784 - val_loss: 0.8855 - val_acc: 0.8508\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 1s 686us/step - loss: 0.1069 - acc: 0.9757 - val_loss: 0.6555 - val_acc: 0.8710\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 1s 674us/step - loss: 0.1609 - acc: 0.9730 - val_loss: 0.7720 - val_acc: 0.8669\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 0s 667us/step - loss: 0.0596 - acc: 0.9825 - val_loss: 0.7790 - val_acc: 0.8589\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.0550 - acc: 0.9865 - val_loss: 0.7496 - val_acc: 0.8548\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.1172 - acc: 0.9744 - val_loss: 0.7078 - val_acc: 0.8548\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.0746 - acc: 0.9879 - val_loss: 0.8794 - val_acc: 0.8306\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1451 - acc: 0.9730 - val_loss: 1.1317 - val_acc: 0.8105\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1146 - acc: 0.9650 - val_loss: 0.4616 - val_acc: 0.8952\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.1645 - acc: 0.9663 - val_loss: 0.7659 - val_acc: 0.8710\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.1010 - acc: 0.9784 - val_loss: 0.5782 - val_acc: 0.8871\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.0441 - acc: 0.9892 - val_loss: 0.4678 - val_acc: 0.8911\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.1150 - acc: 0.9811 - val_loss: 0.6149 - val_acc: 0.8589\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 1s 680us/step - loss: 0.1446 - acc: 0.9757 - val_loss: 0.5419 - val_acc: 0.8710\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.0954 - acc: 0.9852 - val_loss: 1.1121 - val_acc: 0.8306\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 1s 711us/step - loss: 0.0745 - acc: 0.9879 - val_loss: 0.6905 - val_acc: 0.8790\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 1s 687us/step - loss: 0.1544 - acc: 0.9744 - val_loss: 0.7323 - val_acc: 0.8508\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.1142 - acc: 0.9690 - val_loss: 0.7441 - val_acc: 0.8508\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.0725 - acc: 0.9825 - val_loss: 0.7321 - val_acc: 0.8710\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1216 - acc: 0.9717 - val_loss: 0.6328 - val_acc: 0.8710\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0723 - acc: 0.9865 - val_loss: 0.6789 - val_acc: 0.8468\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1004 - acc: 0.9744 - val_loss: 0.8178 - val_acc: 0.8306\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.0832 - acc: 0.9838 - val_loss: 0.8571 - val_acc: 0.8508\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1296 - acc: 0.9730 - val_loss: 0.8142 - val_acc: 0.8427\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.1185 - acc: 0.9825 - val_loss: 1.1365 - val_acc: 0.7984\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.1186 - acc: 0.9852 - val_loss: 0.6315 - val_acc: 0.8468\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0999 - acc: 0.9744 - val_loss: 0.9451 - val_acc: 0.8226\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.1178 - acc: 0.9757 - val_loss: 0.8678 - val_acc: 0.8306\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.1224 - acc: 0.9677 - val_loss: 0.6368 - val_acc: 0.8710\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.0494 - acc: 0.9838 - val_loss: 0.9391 - val_acc: 0.8589\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1601 - acc: 0.9798 - val_loss: 0.6489 - val_acc: 0.8871\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.0954 - acc: 0.9838 - val_loss: 0.7845 - val_acc: 0.8589\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.1095 - acc: 0.9717 - val_loss: 0.6496 - val_acc: 0.8548\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1381 - acc: 0.9744 - val_loss: 0.7831 - val_acc: 0.8548\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 1s 684us/step - loss: 0.1273 - acc: 0.9771 - val_loss: 0.6150 - val_acc: 0.8871\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.0980 - acc: 0.9798 - val_loss: 0.8621 - val_acc: 0.8468\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1360 - acc: 0.9690 - val_loss: 0.6970 - val_acc: 0.8669\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1347 - acc: 0.9717 - val_loss: 0.6907 - val_acc: 0.8266\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 1s 769us/step - loss: 0.1125 - acc: 0.9784 - val_loss: 0.6139 - val_acc: 0.8831\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.1365 - acc: 0.9596 - val_loss: 0.7441 - val_acc: 0.8710\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 1s 829us/step - loss: 0.2373 - acc: 0.9582 - val_loss: 0.7572 - val_acc: 0.8347\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.1124 - acc: 0.9744 - val_loss: 0.8917 - val_acc: 0.8387\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 1s 807us/step - loss: 0.1369 - acc: 0.9730 - val_loss: 0.9484 - val_acc: 0.8266\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 1s 809us/step - loss: 0.1092 - acc: 0.9784 - val_loss: 0.9023 - val_acc: 0.8589\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.0896 - acc: 0.9825 - val_loss: 0.8179 - val_acc: 0.8508\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1400 - acc: 0.9717 - val_loss: 0.6051 - val_acc: 0.8589\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 1s 827us/step - loss: 0.1162 - acc: 0.9798 - val_loss: 0.7782 - val_acc: 0.8508\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 1s 790us/step - loss: 0.2210 - acc: 0.9677 - val_loss: 1.4211 - val_acc: 0.7742\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1339 - acc: 0.9730 - val_loss: 0.6183 - val_acc: 0.8710\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.2035 - acc: 0.9609 - val_loss: 0.6712 - val_acc: 0.8427\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.0624 - acc: 0.9852 - val_loss: 0.5513 - val_acc: 0.8669\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.0523 - acc: 0.9865 - val_loss: 0.4915 - val_acc: 0.9032\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.1656 - acc: 0.9677 - val_loss: 0.5618 - val_acc: 0.8589\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.0882 - acc: 0.9771 - val_loss: 0.4728 - val_acc: 0.8871\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 1s 790us/step - loss: 0.2429 - acc: 0.9596 - val_loss: 0.8088 - val_acc: 0.8710\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.0854 - acc: 0.9784 - val_loss: 0.5749 - val_acc: 0.8710\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.1366 - acc: 0.9677 - val_loss: 0.6528 - val_acc: 0.8508\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 1s 748us/step - loss: 0.1419 - acc: 0.9677 - val_loss: 0.5984 - val_acc: 0.8831\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 1s 793us/step - loss: 0.0796 - acc: 0.9771 - val_loss: 0.6610 - val_acc: 0.8710\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 1s 780us/step - loss: 0.1360 - acc: 0.9717 - val_loss: 0.5355 - val_acc: 0.8710\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 1s 855us/step - loss: 0.1362 - acc: 0.9704 - val_loss: 0.6551 - val_acc: 0.8427\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1936 - acc: 0.9542 - val_loss: 0.5405 - val_acc: 0.8871\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 1s 756us/step - loss: 0.1198 - acc: 0.9757 - val_loss: 0.8278 - val_acc: 0.8468\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 1s 747us/step - loss: 0.1386 - acc: 0.9690 - val_loss: 0.4934 - val_acc: 0.8911\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 0.0618 - acc: 0.9879 - val_loss: 0.5690 - val_acc: 0.8629\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.0363 - acc: 0.9906 - val_loss: 0.7206 - val_acc: 0.8629\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1641 - acc: 0.9730 - val_loss: 0.8452 - val_acc: 0.8145\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1197 - acc: 0.9771 - val_loss: 0.7273 - val_acc: 0.8629\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 1s 786us/step - loss: 0.1589 - acc: 0.9757 - val_loss: 0.8248 - val_acc: 0.8790\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.2070 - acc: 0.9704 - val_loss: 0.6001 - val_acc: 0.8266\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.1132 - acc: 0.9650 - val_loss: 0.6641 - val_acc: 0.8669\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.0691 - acc: 0.9838 - val_loss: 1.0796 - val_acc: 0.8347\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.1407 - acc: 0.9730 - val_loss: 0.5414 - val_acc: 0.8548\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 1s 839us/step - loss: 0.1397 - acc: 0.9663 - val_loss: 0.6846 - val_acc: 0.8589\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.1031 - acc: 0.9690 - val_loss: 0.4762 - val_acc: 0.8992\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.1051 - acc: 0.9771 - val_loss: 0.5298 - val_acc: 0.8871\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.0798 - acc: 0.9879 - val_loss: 0.5230 - val_acc: 0.8710\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1158 - acc: 0.9757 - val_loss: 0.6530 - val_acc: 0.8508\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1426 - acc: 0.9744 - val_loss: 0.6472 - val_acc: 0.8548\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.2126 - acc: 0.9555 - val_loss: 0.5549 - val_acc: 0.8629\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1307 - acc: 0.9717 - val_loss: 0.6122 - val_acc: 0.8911\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1480 - acc: 0.9704 - val_loss: 0.5895 - val_acc: 0.8508\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1197 - acc: 0.9757 - val_loss: 0.5624 - val_acc: 0.8871\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.0446 - acc: 0.9825 - val_loss: 0.6377 - val_acc: 0.8710\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.2569 - acc: 0.9582 - val_loss: 0.4560 - val_acc: 0.8710\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1860 - acc: 0.9623 - val_loss: 0.5145 - val_acc: 0.8790\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1101 - acc: 0.9784 - val_loss: 0.9607 - val_acc: 0.8226\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 1s 714us/step - loss: 0.1119 - acc: 0.9798 - val_loss: 0.6176 - val_acc: 0.8669\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1220 - acc: 0.9704 - val_loss: 0.5812 - val_acc: 0.8831\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1563 - acc: 0.9744 - val_loss: 0.4777 - val_acc: 0.9032\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.1170 - acc: 0.9704 - val_loss: 0.5943 - val_acc: 0.8831\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.0951 - acc: 0.9757 - val_loss: 0.6412 - val_acc: 0.8911\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.1192 - acc: 0.9825 - val_loss: 0.5934 - val_acc: 0.8992\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.0988 - acc: 0.9798 - val_loss: 0.6216 - val_acc: 0.8831\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.0673 - acc: 0.9784 - val_loss: 0.6958 - val_acc: 0.8468\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1623 - acc: 0.9717 - val_loss: 0.5335 - val_acc: 0.8871\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1460 - acc: 0.9771 - val_loss: 0.5194 - val_acc: 0.8790\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1580 - acc: 0.9690 - val_loss: 0.5051 - val_acc: 0.8911\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.1755 - acc: 0.9744 - val_loss: 0.5649 - val_acc: 0.8790\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1264 - acc: 0.9784 - val_loss: 0.6810 - val_acc: 0.8750\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1060 - acc: 0.9730 - val_loss: 0.6937 - val_acc: 0.8629\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1257 - acc: 0.9771 - val_loss: 0.4842 - val_acc: 0.8871\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1601 - acc: 0.9730 - val_loss: 0.7184 - val_acc: 0.8589\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 1s 754us/step - loss: 0.1343 - acc: 0.9717 - val_loss: 0.7641 - val_acc: 0.8347\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.0673 - acc: 0.9825 - val_loss: 0.7236 - val_acc: 0.8589\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 772us/step - loss: 0.0893 - acc: 0.9811 - val_loss: 0.6375 - val_acc: 0.8629\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 1s 796us/step - loss: 0.0422 - acc: 0.9933 - val_loss: 0.7654 - val_acc: 0.8468\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.2132 - acc: 0.9623 - val_loss: 0.6335 - val_acc: 0.8669\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.1365 - acc: 0.9690 - val_loss: 0.8000 - val_acc: 0.8427\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 1s 789us/step - loss: 0.1131 - acc: 0.9771 - val_loss: 0.6270 - val_acc: 0.8468\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1625 - acc: 0.9744 - val_loss: 0.7927 - val_acc: 0.8427\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2150 - acc: 0.9582 - val_loss: 0.6024 - val_acc: 0.8629\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.1614 - acc: 0.9596 - val_loss: 0.5307 - val_acc: 0.8629\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.1362 - acc: 0.9690 - val_loss: 0.6796 - val_acc: 0.8468\n",
      "Epoch 601/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 0.0688 - acc: 0.9825 - val_loss: 0.5329 - val_acc: 0.8548\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 1s 837us/step - loss: 0.0904 - acc: 0.9811 - val_loss: 0.7969 - val_acc: 0.8226\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.0570 - acc: 0.9825 - val_loss: 0.6684 - val_acc: 0.8710\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.1152 - acc: 0.9690 - val_loss: 0.5921 - val_acc: 0.8710\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.1594 - acc: 0.9730 - val_loss: 0.6540 - val_acc: 0.8548\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1069 - acc: 0.9757 - val_loss: 0.6434 - val_acc: 0.8468\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1468 - acc: 0.9704 - val_loss: 0.6712 - val_acc: 0.8629\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.1498 - acc: 0.9663 - val_loss: 0.5146 - val_acc: 0.8790\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 1s 776us/step - loss: 0.1828 - acc: 0.9690 - val_loss: 0.5170 - val_acc: 0.8831\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 0.1714 - acc: 0.9784 - val_loss: 0.5128 - val_acc: 0.8710\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 1s 809us/step - loss: 0.1201 - acc: 0.9757 - val_loss: 0.5647 - val_acc: 0.8831\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.2334 - acc: 0.9582 - val_loss: 0.7767 - val_acc: 0.8468\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 1s 786us/step - loss: 0.1203 - acc: 0.9650 - val_loss: 0.6628 - val_acc: 0.8266\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 0.1517 - acc: 0.9663 - val_loss: 0.9272 - val_acc: 0.8145\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.1513 - acc: 0.9798 - val_loss: 0.7941 - val_acc: 0.8427\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 0.1630 - acc: 0.9704 - val_loss: 0.6001 - val_acc: 0.8911\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 1s 797us/step - loss: 0.1408 - acc: 0.9717 - val_loss: 0.5671 - val_acc: 0.8669\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1085 - acc: 0.9879 - val_loss: 0.5529 - val_acc: 0.8548\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.1955 - acc: 0.9771 - val_loss: 0.8987 - val_acc: 0.8387\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.2186 - acc: 0.9555 - val_loss: 0.7158 - val_acc: 0.8468\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 0.1546 - acc: 0.9717 - val_loss: 0.9277 - val_acc: 0.8226\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1889 - acc: 0.9704 - val_loss: 0.6086 - val_acc: 0.8589\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 1s 796us/step - loss: 0.1284 - acc: 0.9690 - val_loss: 0.6094 - val_acc: 0.8629\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 0.1002 - acc: 0.9771 - val_loss: 0.5730 - val_acc: 0.8589\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1263 - acc: 0.9744 - val_loss: 0.7699 - val_acc: 0.8427\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 0.1674 - acc: 0.9704 - val_loss: 0.6264 - val_acc: 0.8871\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 1s 827us/step - loss: 0.1871 - acc: 0.9704 - val_loss: 0.6364 - val_acc: 0.8871\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.1926 - acc: 0.9771 - val_loss: 0.6629 - val_acc: 0.8589\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1178 - acc: 0.9771 - val_loss: 0.5878 - val_acc: 0.8669\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.1856 - acc: 0.9730 - val_loss: 0.4887 - val_acc: 0.8871\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1067 - acc: 0.9771 - val_loss: 0.6207 - val_acc: 0.8468\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 0.1846 - acc: 0.9663 - val_loss: 0.6211 - val_acc: 0.8629\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 1s 758us/step - loss: 0.1432 - acc: 0.9744 - val_loss: 0.6322 - val_acc: 0.8548\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.1757 - acc: 0.9650 - val_loss: 0.7355 - val_acc: 0.8589\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1545 - acc: 0.9717 - val_loss: 0.6331 - val_acc: 0.8629\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.0832 - acc: 0.9798 - val_loss: 0.6713 - val_acc: 0.8750\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.0614 - acc: 0.9838 - val_loss: 0.6209 - val_acc: 0.8548\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 1s 777us/step - loss: 0.1226 - acc: 0.9811 - val_loss: 0.7544 - val_acc: 0.8468\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 1s 836us/step - loss: 0.1658 - acc: 0.9704 - val_loss: 0.6057 - val_acc: 0.8548\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 1s 817us/step - loss: 0.1699 - acc: 0.9677 - val_loss: 0.7404 - val_acc: 0.8710\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1094 - acc: 0.9757 - val_loss: 0.6717 - val_acc: 0.8548\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1538 - acc: 0.9663 - val_loss: 0.6455 - val_acc: 0.8669\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 1s 802us/step - loss: 0.1236 - acc: 0.9825 - val_loss: 0.6657 - val_acc: 0.8790\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 1s 814us/step - loss: 0.1822 - acc: 0.9757 - val_loss: 0.8431 - val_acc: 0.7984\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 1s 830us/step - loss: 0.1606 - acc: 0.9757 - val_loss: 0.6406 - val_acc: 0.8710\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 1s 777us/step - loss: 0.1958 - acc: 0.9650 - val_loss: 0.5114 - val_acc: 0.8871\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.1039 - acc: 0.9838 - val_loss: 0.6517 - val_acc: 0.8548\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 0.2153 - acc: 0.9636 - val_loss: 0.6702 - val_acc: 0.8669\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.0982 - acc: 0.9771 - val_loss: 0.5828 - val_acc: 0.8710\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 1s 794us/step - loss: 0.1679 - acc: 0.9663 - val_loss: 0.6015 - val_acc: 0.8710\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 1s 887us/step - loss: 0.0758 - acc: 0.9892 - val_loss: 0.7350 - val_acc: 0.8427\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.2003 - acc: 0.9623 - val_loss: 0.6547 - val_acc: 0.8508\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1325 - acc: 0.9757 - val_loss: 0.6334 - val_acc: 0.8871\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 1s 938us/step - loss: 0.0498 - acc: 0.9825 - val_loss: 0.6846 - val_acc: 0.8669\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.1459 - acc: 0.9757 - val_loss: 0.7682 - val_acc: 0.8911\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1349 - acc: 0.9704 - val_loss: 0.6883 - val_acc: 0.8790\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1532 - acc: 0.9704 - val_loss: 0.6661 - val_acc: 0.8710\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1769 - acc: 0.9582 - val_loss: 0.6487 - val_acc: 0.8468\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 1s 699us/step - loss: 0.1916 - acc: 0.9650 - val_loss: 0.7941 - val_acc: 0.8347\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1687 - acc: 0.9757 - val_loss: 0.7685 - val_acc: 0.8387\n",
      "Epoch 661/1000\n",
      "742/742 [==============================] - 1s 712us/step - loss: 0.0986 - acc: 0.9784 - val_loss: 0.8324 - val_acc: 0.8387\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.0929 - acc: 0.9798 - val_loss: 0.6697 - val_acc: 0.8669\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1709 - acc: 0.9717 - val_loss: 0.6292 - val_acc: 0.8871\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.1428 - acc: 0.9663 - val_loss: 0.7380 - val_acc: 0.8710\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.0706 - acc: 0.9825 - val_loss: 0.6050 - val_acc: 0.8911\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.0478 - acc: 0.9865 - val_loss: 0.7207 - val_acc: 0.8629\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.0768 - acc: 0.9865 - val_loss: 0.6354 - val_acc: 0.8468\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 1s 736us/step - loss: 0.1715 - acc: 0.9717 - val_loss: 0.5212 - val_acc: 0.8750\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.2053 - acc: 0.9690 - val_loss: 0.7432 - val_acc: 0.8669\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 1s 710us/step - loss: 0.1472 - acc: 0.9798 - val_loss: 0.5978 - val_acc: 0.8750\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1103 - acc: 0.9757 - val_loss: 0.6399 - val_acc: 0.8629\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1328 - acc: 0.9757 - val_loss: 0.6488 - val_acc: 0.8669\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 1s 709us/step - loss: 0.0929 - acc: 0.9798 - val_loss: 0.8307 - val_acc: 0.8468\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.2360 - acc: 0.9582 - val_loss: 0.6288 - val_acc: 0.8468\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.1593 - acc: 0.9650 - val_loss: 0.5758 - val_acc: 0.8790\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.0934 - acc: 0.9838 - val_loss: 0.6990 - val_acc: 0.8508\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1828 - acc: 0.9636 - val_loss: 0.5998 - val_acc: 0.8669\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.2396 - acc: 0.9555 - val_loss: 0.7222 - val_acc: 0.8508\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1233 - acc: 0.9730 - val_loss: 0.7066 - val_acc: 0.8306\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1592 - acc: 0.9730 - val_loss: 0.5971 - val_acc: 0.8589\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 1s 774us/step - loss: 0.1215 - acc: 0.9771 - val_loss: 0.6442 - val_acc: 0.8669\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 1s 734us/step - loss: 0.1673 - acc: 0.9690 - val_loss: 0.5009 - val_acc: 0.8871\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1902 - acc: 0.9730 - val_loss: 0.7938 - val_acc: 0.8185\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2032 - acc: 0.9650 - val_loss: 0.5285 - val_acc: 0.8750\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1524 - acc: 0.9771 - val_loss: 0.6318 - val_acc: 0.8548\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.1393 - acc: 0.9717 - val_loss: 0.5442 - val_acc: 0.8750\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1286 - acc: 0.9717 - val_loss: 0.5887 - val_acc: 0.8548\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 1s 700us/step - loss: 0.1145 - acc: 0.9744 - val_loss: 0.5074 - val_acc: 0.8790\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.0772 - acc: 0.9798 - val_loss: 0.5992 - val_acc: 0.8427\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.0976 - acc: 0.9838 - val_loss: 0.7950 - val_acc: 0.8508\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 1s 707us/step - loss: 0.2196 - acc: 0.9650 - val_loss: 0.5261 - val_acc: 0.8871\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 1s 730us/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.4994 - val_acc: 0.8952\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1371 - acc: 0.9663 - val_loss: 0.6509 - val_acc: 0.8468\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1844 - acc: 0.9596 - val_loss: 0.6219 - val_acc: 0.8750\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.0527 - acc: 0.9892 - val_loss: 0.7384 - val_acc: 0.8468\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 0.2768 - acc: 0.9623 - val_loss: 0.5868 - val_acc: 0.8387\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1390 - acc: 0.9784 - val_loss: 0.6088 - val_acc: 0.8669\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1552 - acc: 0.9690 - val_loss: 0.4689 - val_acc: 0.8710\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1886 - acc: 0.9677 - val_loss: 0.6424 - val_acc: 0.8548\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.0891 - acc: 0.9838 - val_loss: 0.5226 - val_acc: 0.8871\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.1311 - acc: 0.9798 - val_loss: 0.4627 - val_acc: 0.8669\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.1005 - acc: 0.9757 - val_loss: 0.5814 - val_acc: 0.8710\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 1s 715us/step - loss: 0.1653 - acc: 0.9690 - val_loss: 0.5765 - val_acc: 0.8508\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.1334 - acc: 0.9744 - val_loss: 0.5586 - val_acc: 0.8387\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1527 - acc: 0.9690 - val_loss: 0.5729 - val_acc: 0.8427\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.3357 - acc: 0.9542 - val_loss: 0.6428 - val_acc: 0.8589\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 1s 782us/step - loss: 0.1575 - acc: 0.9757 - val_loss: 0.6221 - val_acc: 0.8508\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1094 - acc: 0.9744 - val_loss: 0.6163 - val_acc: 0.8629\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1284 - acc: 0.9771 - val_loss: 0.5463 - val_acc: 0.8790\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 719us/step - loss: 0.1472 - acc: 0.9771 - val_loss: 0.5582 - val_acc: 0.8589\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.1277 - acc: 0.9717 - val_loss: 0.5872 - val_acc: 0.8589\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1114 - acc: 0.9784 - val_loss: 0.5112 - val_acc: 0.8710\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.1665 - acc: 0.9717 - val_loss: 0.5217 - val_acc: 0.8629\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 1s 776us/step - loss: 0.1660 - acc: 0.9717 - val_loss: 0.6678 - val_acc: 0.8427\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1596 - acc: 0.9717 - val_loss: 0.6171 - val_acc: 0.8306\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 1s 693us/step - loss: 0.0950 - acc: 0.9744 - val_loss: 0.5532 - val_acc: 0.8548\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1005 - acc: 0.9811 - val_loss: 0.8328 - val_acc: 0.8548\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1551 - acc: 0.9744 - val_loss: 0.6167 - val_acc: 0.8589\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.2112 - acc: 0.9690 - val_loss: 0.8224 - val_acc: 0.8185\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 1s 727us/step - loss: 0.1412 - acc: 0.9784 - val_loss: 0.6123 - val_acc: 0.8508\n",
      "Epoch 721/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.0758 - acc: 0.9798 - val_loss: 0.5942 - val_acc: 0.8468\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.2433 - acc: 0.9555 - val_loss: 0.6703 - val_acc: 0.8387\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.1778 - acc: 0.9717 - val_loss: 0.6998 - val_acc: 0.8427\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 1s 706us/step - loss: 0.1596 - acc: 0.9730 - val_loss: 0.6090 - val_acc: 0.8790\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 1s 696us/step - loss: 0.2508 - acc: 0.9636 - val_loss: 0.5491 - val_acc: 0.8669\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.1292 - acc: 0.9677 - val_loss: 0.5623 - val_acc: 0.8710\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 1s 703us/step - loss: 0.1384 - acc: 0.9757 - val_loss: 0.5006 - val_acc: 0.8548\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1552 - acc: 0.9704 - val_loss: 0.4667 - val_acc: 0.8790\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 1s 729us/step - loss: 0.1415 - acc: 0.9704 - val_loss: 0.5671 - val_acc: 0.8831\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 1s 698us/step - loss: 0.1817 - acc: 0.9677 - val_loss: 0.4905 - val_acc: 0.8710\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 1s 708us/step - loss: 0.1996 - acc: 0.9704 - val_loss: 0.4916 - val_acc: 0.8750\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 1s 754us/step - loss: 0.0853 - acc: 0.9811 - val_loss: 0.5326 - val_acc: 0.8831\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.978 - 1s 683us/step - loss: 0.1120 - acc: 0.9798 - val_loss: 0.4994 - val_acc: 0.8710\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2046 - acc: 0.9704 - val_loss: 0.4195 - val_acc: 0.9032\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.2173 - acc: 0.9690 - val_loss: 0.5373 - val_acc: 0.8750\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 1s 698us/step - loss: 0.1508 - acc: 0.9744 - val_loss: 0.5965 - val_acc: 0.8589\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1362 - acc: 0.9744 - val_loss: 0.4884 - val_acc: 0.8629\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.2125 - acc: 0.9730 - val_loss: 0.4103 - val_acc: 0.8952\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 1s 695us/step - loss: 0.1994 - acc: 0.9690 - val_loss: 0.6427 - val_acc: 0.8790\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1020 - acc: 0.9798 - val_loss: 0.5395 - val_acc: 0.8750\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.1523 - acc: 0.9717 - val_loss: 0.6216 - val_acc: 0.8468\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1402 - acc: 0.9744 - val_loss: 0.5066 - val_acc: 0.8710\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1454 - acc: 0.9717 - val_loss: 0.5864 - val_acc: 0.8669\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 1s 736us/step - loss: 0.1909 - acc: 0.9636 - val_loss: 0.5809 - val_acc: 0.8548\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 1s 721us/step - loss: 0.2256 - acc: 0.9717 - val_loss: 0.4587 - val_acc: 0.8669\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.2431 - acc: 0.9677 - val_loss: 0.5606 - val_acc: 0.8589\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.1342 - acc: 0.9784 - val_loss: 0.4328 - val_acc: 0.8710\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1481 - acc: 0.9771 - val_loss: 0.5123 - val_acc: 0.8669\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.1592 - acc: 0.9771 - val_loss: 0.5975 - val_acc: 0.8548\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1519 - acc: 0.9744 - val_loss: 0.5641 - val_acc: 0.8589\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1255 - acc: 0.9757 - val_loss: 0.5259 - val_acc: 0.8589\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 0.2173 - acc: 0.9663 - val_loss: 0.4954 - val_acc: 0.8669\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1656 - acc: 0.9744 - val_loss: 0.5041 - val_acc: 0.8508\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1841 - acc: 0.9730 - val_loss: 0.4988 - val_acc: 0.8508\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1271 - acc: 0.9744 - val_loss: 0.3660 - val_acc: 0.8911\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.2182 - acc: 0.9704 - val_loss: 0.4357 - val_acc: 0.8871\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1338 - acc: 0.9798 - val_loss: 0.4579 - val_acc: 0.8831\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.1426 - acc: 0.9730 - val_loss: 0.6156 - val_acc: 0.8347\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.1562 - acc: 0.9784 - val_loss: 0.4170 - val_acc: 0.8831\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 1s 736us/step - loss: 0.0923 - acc: 0.9798 - val_loss: 0.4476 - val_acc: 0.8831\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.1856 - acc: 0.9730 - val_loss: 0.4741 - val_acc: 0.8669\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 1s 755us/step - loss: 0.1266 - acc: 0.9717 - val_loss: 0.4448 - val_acc: 0.8871\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1509 - acc: 0.9650 - val_loss: 0.7098 - val_acc: 0.8508\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.1239 - acc: 0.9744 - val_loss: 0.6824 - val_acc: 0.8589\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1683 - acc: 0.9730 - val_loss: 0.4211 - val_acc: 0.8871\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 1s 736us/step - loss: 0.1955 - acc: 0.9717 - val_loss: 0.4250 - val_acc: 0.8750\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.1462 - acc: 0.9825 - val_loss: 0.5028 - val_acc: 0.8790\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1413 - acc: 0.9744 - val_loss: 0.4224 - val_acc: 0.8750\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.2628 - acc: 0.9663 - val_loss: 0.5182 - val_acc: 0.8750\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1692 - acc: 0.9609 - val_loss: 0.4380 - val_acc: 0.8669\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.1580 - acc: 0.9704 - val_loss: 0.4366 - val_acc: 0.8750\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 1s 678us/step - loss: 0.2256 - acc: 0.9744 - val_loss: 0.4704 - val_acc: 0.8710\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.2069 - acc: 0.9730 - val_loss: 0.5068 - val_acc: 0.8992\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.2135 - acc: 0.9690 - val_loss: 0.4702 - val_acc: 0.8871\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.2327 - acc: 0.9650 - val_loss: 0.4880 - val_acc: 0.8790\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1241 - acc: 0.9798 - val_loss: 0.5416 - val_acc: 0.8831\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.1166 - acc: 0.9730 - val_loss: 0.4392 - val_acc: 0.8871\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1078 - acc: 0.9744 - val_loss: 0.4647 - val_acc: 0.8831\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.2461 - acc: 0.9717 - val_loss: 0.8511 - val_acc: 0.8468\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 1s 697us/step - loss: 0.1351 - acc: 0.9690 - val_loss: 0.5993 - val_acc: 0.8710\n",
      "Epoch 781/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.0991 - acc: 0.9798 - val_loss: 0.6776 - val_acc: 0.8427\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.2329 - acc: 0.9677 - val_loss: 0.5260 - val_acc: 0.8750\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 0.1013 - acc: 0.9825 - val_loss: 0.5981 - val_acc: 0.8548\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.1422 - acc: 0.9757 - val_loss: 0.6009 - val_acc: 0.8548\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1368 - acc: 0.9623 - val_loss: 0.5795 - val_acc: 0.8790\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 1s 716us/step - loss: 0.1489 - acc: 0.9690 - val_loss: 0.5833 - val_acc: 0.8427\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.2404 - acc: 0.9730 - val_loss: 0.5939 - val_acc: 0.8548\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 1s 724us/step - loss: 0.2033 - acc: 0.9730 - val_loss: 0.5056 - val_acc: 0.8589\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 1s 728us/step - loss: 0.1020 - acc: 0.9838 - val_loss: 0.5662 - val_acc: 0.8710\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 1s 754us/step - loss: 0.1506 - acc: 0.9771 - val_loss: 0.5304 - val_acc: 0.8669\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 1s 726us/step - loss: 0.2326 - acc: 0.9677 - val_loss: 0.6289 - val_acc: 0.8266\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.1688 - acc: 0.9757 - val_loss: 0.5475 - val_acc: 0.8790\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2923 - acc: 0.9555 - val_loss: 0.6152 - val_acc: 0.8468\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.2506 - acc: 0.9609 - val_loss: 0.5774 - val_acc: 0.8750\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1305 - acc: 0.9704 - val_loss: 0.5490 - val_acc: 0.8790\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 0.1371 - acc: 0.9730 - val_loss: 0.4883 - val_acc: 0.8831\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 1s 782us/step - loss: 0.1964 - acc: 0.9717 - val_loss: 0.5294 - val_acc: 0.8508\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 1s 794us/step - loss: 0.2189 - acc: 0.9650 - val_loss: 0.5304 - val_acc: 0.8750\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 1s 830us/step - loss: 0.1926 - acc: 0.9636 - val_loss: 0.6181 - val_acc: 0.8387\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.1512 - acc: 0.9704 - val_loss: 0.5372 - val_acc: 0.8548\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.1780 - acc: 0.9744 - val_loss: 0.4413 - val_acc: 0.8548\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.0840 - acc: 0.9811 - val_loss: 0.9615 - val_acc: 0.8185\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 1s 802us/step - loss: 0.2914 - acc: 0.9677 - val_loss: 0.6224 - val_acc: 0.8669\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 1s 723us/step - loss: 0.1923 - acc: 0.9623 - val_loss: 0.6781 - val_acc: 0.8347\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 1s 749us/step - loss: 0.2347 - acc: 0.9663 - val_loss: 0.6202 - val_acc: 0.8589\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 1s 804us/step - loss: 0.1194 - acc: 0.9757 - val_loss: 0.6401 - val_acc: 0.8508\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.1264 - acc: 0.9811 - val_loss: 0.5260 - val_acc: 0.8548\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.1013 - acc: 0.9825 - val_loss: 0.8363 - val_acc: 0.8266\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.2248 - acc: 0.9690 - val_loss: 0.7247 - val_acc: 0.8024\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1444 - acc: 0.9744 - val_loss: 0.6498 - val_acc: 0.8589\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 1s 828us/step - loss: 0.2304 - acc: 0.9650 - val_loss: 0.5439 - val_acc: 0.8629\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 1s 793us/step - loss: 0.1114 - acc: 0.9744 - val_loss: 0.8106 - val_acc: 0.8306\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 1s 773us/step - loss: 0.2032 - acc: 0.9690 - val_loss: 0.6304 - val_acc: 0.8548\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 1s 797us/step - loss: 0.1797 - acc: 0.9757 - val_loss: 0.6180 - val_acc: 0.8629\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 1s 806us/step - loss: 0.1754 - acc: 0.9784 - val_loss: 1.2305 - val_acc: 0.7782\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 1s 817us/step - loss: 0.2009 - acc: 0.9717 - val_loss: 0.5151 - val_acc: 0.8508\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 1s 859us/step - loss: 0.1955 - acc: 0.9663 - val_loss: 0.5893 - val_acc: 0.8468\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 0.3027 - acc: 0.9663 - val_loss: 0.6819 - val_acc: 0.8508\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 1s 807us/step - loss: 0.1938 - acc: 0.9677 - val_loss: 0.5497 - val_acc: 0.8306\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 0.1376 - acc: 0.9757 - val_loss: 0.6543 - val_acc: 0.8427\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.1369 - acc: 0.9771 - val_loss: 0.6796 - val_acc: 0.8065\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 1s 780us/step - loss: 0.1413 - acc: 0.9717 - val_loss: 0.6806 - val_acc: 0.8306\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 0.1452 - acc: 0.9744 - val_loss: 0.5480 - val_acc: 0.8750\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.2143 - acc: 0.9636 - val_loss: 0.5561 - val_acc: 0.8790\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 0.1944 - acc: 0.9744 - val_loss: 0.5851 - val_acc: 0.8710\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 1s 797us/step - loss: 0.1476 - acc: 0.9825 - val_loss: 0.5596 - val_acc: 0.8669\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.3598 - acc: 0.9569 - val_loss: 0.8796 - val_acc: 0.8185\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 774us/step - loss: 0.1682 - acc: 0.9757 - val_loss: 0.6321 - val_acc: 0.8427\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 1s 827us/step - loss: 0.1983 - acc: 0.9663 - val_loss: 0.5178 - val_acc: 0.8669\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 1s 775us/step - loss: 0.2526 - acc: 0.9704 - val_loss: 0.6017 - val_acc: 0.8185\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 1s 798us/step - loss: 0.2203 - acc: 0.9663 - val_loss: 0.5973 - val_acc: 0.8589\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 1s 769us/step - loss: 0.2139 - acc: 0.9704 - val_loss: 0.5967 - val_acc: 0.8710\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 1s 837us/step - loss: 0.1938 - acc: 0.9704 - val_loss: 0.4362 - val_acc: 0.8629\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 1s 783us/step - loss: 0.1733 - acc: 0.9636 - val_loss: 0.6809 - val_acc: 0.8548\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.1755 - acc: 0.9677 - val_loss: 0.4190 - val_acc: 0.8992\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 1s 784us/step - loss: 0.1020 - acc: 0.9798 - val_loss: 0.5730 - val_acc: 0.8669\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 1s 808us/step - loss: 0.1928 - acc: 0.9704 - val_loss: 0.4590 - val_acc: 0.8831\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 1s 809us/step - loss: 0.1803 - acc: 0.9636 - val_loss: 0.5431 - val_acc: 0.8468\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.2064 - acc: 0.9663 - val_loss: 0.4605 - val_acc: 0.8952\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 1s 771us/step - loss: 0.1090 - acc: 0.9757 - val_loss: 0.6085 - val_acc: 0.8548\n",
      "Epoch 841/1000\n",
      "742/742 [==============================] - 1s 777us/step - loss: 0.1759 - acc: 0.9730 - val_loss: 0.5409 - val_acc: 0.8387\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 1s 832us/step - loss: 0.2399 - acc: 0.9704 - val_loss: 0.6217 - val_acc: 0.8468\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.1466 - acc: 0.9798 - val_loss: 0.6347 - val_acc: 0.8589\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.2582 - acc: 0.9663 - val_loss: 0.6012 - val_acc: 0.8185\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.1564 - acc: 0.9690 - val_loss: 0.6360 - val_acc: 0.8589\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 1s 820us/step - loss: 0.1124 - acc: 0.9798 - val_loss: 0.5876 - val_acc: 0.8831\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 1s 795us/step - loss: 0.2092 - acc: 0.9690 - val_loss: 0.4944 - val_acc: 0.8952\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 1s 798us/step - loss: 0.2053 - acc: 0.9690 - val_loss: 0.7999 - val_acc: 0.8629\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 1s 793us/step - loss: 0.2051 - acc: 0.9677 - val_loss: 0.5668 - val_acc: 0.8992\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.2398 - acc: 0.9582 - val_loss: 0.6103 - val_acc: 0.8669\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 1s 794us/step - loss: 0.0916 - acc: 0.9811 - val_loss: 0.4388 - val_acc: 0.8750\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 1s 798us/step - loss: 0.1204 - acc: 0.9811 - val_loss: 0.6202 - val_acc: 0.8750\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 1s 784us/step - loss: 0.1746 - acc: 0.9704 - val_loss: 0.5386 - val_acc: 0.8750\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 1s 811us/step - loss: 0.1605 - acc: 0.9784 - val_loss: 0.4733 - val_acc: 0.8790\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 1s 814us/step - loss: 0.1955 - acc: 0.9677 - val_loss: 0.5554 - val_acc: 0.8790\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 1s 779us/step - loss: 0.2228 - acc: 0.9569 - val_loss: 0.4839 - val_acc: 0.8589\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.2441 - acc: 0.9663 - val_loss: 0.5110 - val_acc: 0.8669\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.0920 - acc: 0.9811 - val_loss: 0.4719 - val_acc: 0.8790\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 1s 847us/step - loss: 0.1382 - acc: 0.9784 - val_loss: 0.5350 - val_acc: 0.8669\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 1s 790us/step - loss: 0.1436 - acc: 0.9771 - val_loss: 0.5146 - val_acc: 0.8831\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 1s 769us/step - loss: 0.2422 - acc: 0.9704 - val_loss: 0.4423 - val_acc: 0.8992\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 1s 781us/step - loss: 0.2580 - acc: 0.9704 - val_loss: 0.6153 - val_acc: 0.8468\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 1s 791us/step - loss: 0.1555 - acc: 0.9811 - val_loss: 0.6950 - val_acc: 0.8427\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.2493 - acc: 0.9609 - val_loss: 0.6040 - val_acc: 0.8468\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.1377 - acc: 0.9730 - val_loss: 0.4635 - val_acc: 0.8427\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 1s 760us/step - loss: 0.1369 - acc: 0.9811 - val_loss: 0.5093 - val_acc: 0.8710\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 1s 760us/step - loss: 0.1679 - acc: 0.9771 - val_loss: 0.5136 - val_acc: 0.8589\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 0.1095 - acc: 0.9811 - val_loss: 0.4799 - val_acc: 0.8669\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.2195 - acc: 0.9757 - val_loss: 0.4458 - val_acc: 0.8952\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1387 - acc: 0.9757 - val_loss: 0.5674 - val_acc: 0.8589\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.1323 - acc: 0.9730 - val_loss: 0.5295 - val_acc: 0.8468\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 1s 786us/step - loss: 0.1795 - acc: 0.9757 - val_loss: 0.4605 - val_acc: 0.8871\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.2046 - acc: 0.9636 - val_loss: 0.5208 - val_acc: 0.8589\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2058 - acc: 0.9744 - val_loss: 0.4901 - val_acc: 0.8750\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 1s 783us/step - loss: 0.0931 - acc: 0.9838 - val_loss: 0.5716 - val_acc: 0.8548\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 1s 770us/step - loss: 0.1726 - acc: 0.9704 - val_loss: 0.7450 - val_acc: 0.7863\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2981 - acc: 0.9623 - val_loss: 0.5030 - val_acc: 0.8871\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.2214 - acc: 0.9717 - val_loss: 0.4136 - val_acc: 0.8871\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 1s 784us/step - loss: 0.2305 - acc: 0.9650 - val_loss: 0.5433 - val_acc: 0.8427\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1681 - acc: 0.9744 - val_loss: 0.4087 - val_acc: 0.8992\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 1s 789us/step - loss: 0.1822 - acc: 0.9757 - val_loss: 0.4819 - val_acc: 0.8790\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 1s 822us/step - loss: 0.2278 - acc: 0.9690 - val_loss: 0.5049 - val_acc: 0.8468\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 1s 773us/step - loss: 0.1094 - acc: 0.9852 - val_loss: 0.4116 - val_acc: 0.8831\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 1s 760us/step - loss: 0.1689 - acc: 0.9704 - val_loss: 0.4191 - val_acc: 0.8710\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 1s 758us/step - loss: 0.3128 - acc: 0.9663 - val_loss: 0.4499 - val_acc: 0.8589\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 0.1968 - acc: 0.9663 - val_loss: 0.6257 - val_acc: 0.8387\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 0.2586 - acc: 0.9609 - val_loss: 0.5086 - val_acc: 0.8831\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 1s 790us/step - loss: 0.2592 - acc: 0.9650 - val_loss: 0.4695 - val_acc: 0.8669\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 1s 806us/step - loss: 0.1676 - acc: 0.9730 - val_loss: 0.5266 - val_acc: 0.8790\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.3015 - acc: 0.9609 - val_loss: 0.4424 - val_acc: 0.8871\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 1s 826us/step - loss: 0.2728 - acc: 0.9623 - val_loss: 0.4589 - val_acc: 0.8790\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.1748 - acc: 0.9744 - val_loss: 0.4275 - val_acc: 0.8831\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 1s 785us/step - loss: 0.2730 - acc: 0.9690 - val_loss: 0.4236 - val_acc: 0.8669\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 1s 802us/step - loss: 0.1663 - acc: 0.9690 - val_loss: 0.4066 - val_acc: 0.8669\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 0.1958 - acc: 0.9704 - val_loss: 0.4087 - val_acc: 0.8629\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2110 - acc: 0.9704 - val_loss: 0.5370 - val_acc: 0.8750\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 0.2137 - acc: 0.9717 - val_loss: 0.5108 - val_acc: 0.8790\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 1s 801us/step - loss: 0.2643 - acc: 0.9623 - val_loss: 0.5129 - val_acc: 0.8548\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.2344 - acc: 0.9677 - val_loss: 0.4557 - val_acc: 0.8750\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 1s 795us/step - loss: 0.2003 - acc: 0.9798 - val_loss: 0.6679 - val_acc: 0.8387\n",
      "Epoch 901/1000\n",
      "742/742 [==============================] - 1s 775us/step - loss: 0.2024 - acc: 0.9690 - val_loss: 0.8036 - val_acc: 0.8105\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.2221 - acc: 0.9771 - val_loss: 0.5711 - val_acc: 0.8629\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 1s 792us/step - loss: 0.2132 - acc: 0.9744 - val_loss: 0.4805 - val_acc: 0.8669\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 1s 817us/step - loss: 0.3701 - acc: 0.9596 - val_loss: 0.4332 - val_acc: 0.8710\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.2461 - acc: 0.9717 - val_loss: 0.4729 - val_acc: 0.8952\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 0.1691 - acc: 0.9717 - val_loss: 0.7262 - val_acc: 0.8105\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 1s 778us/step - loss: 0.1768 - acc: 0.9677 - val_loss: 0.4431 - val_acc: 0.8669\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1274 - acc: 0.9757 - val_loss: 0.5930 - val_acc: 0.8669\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 1s 736us/step - loss: 0.1985 - acc: 0.9663 - val_loss: 0.5757 - val_acc: 0.8468\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1644 - acc: 0.9784 - val_loss: 0.6929 - val_acc: 0.8226\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 1s 786us/step - loss: 0.2227 - acc: 0.9704 - val_loss: 0.5832 - val_acc: 0.8508\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 1s 732us/step - loss: 0.3123 - acc: 0.9623 - val_loss: 0.6804 - val_acc: 0.8266\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.1563 - acc: 0.9771 - val_loss: 0.6165 - val_acc: 0.8306\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.2013 - acc: 0.9811 - val_loss: 0.6998 - val_acc: 0.8185\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 1s 752us/step - loss: 0.1943 - acc: 0.9730 - val_loss: 0.6329 - val_acc: 0.8710\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.2551 - acc: 0.9757 - val_loss: 0.8792 - val_acc: 0.8347\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 1s 782us/step - loss: 0.2285 - acc: 0.9677 - val_loss: 0.8556 - val_acc: 0.8427\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 1s 758us/step - loss: 0.2379 - acc: 0.9690 - val_loss: 0.5923 - val_acc: 0.8508\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 1s 768us/step - loss: 0.2158 - acc: 0.9717 - val_loss: 0.6222 - val_acc: 0.8589\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.1964 - acc: 0.9798 - val_loss: 0.6061 - val_acc: 0.8589\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1913 - acc: 0.9784 - val_loss: 0.4530 - val_acc: 0.8952\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.2461 - acc: 0.9690 - val_loss: 0.4330 - val_acc: 0.8750\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.1246 - acc: 0.9838 - val_loss: 0.5276 - val_acc: 0.8508\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1621 - acc: 0.9811 - val_loss: 0.7667 - val_acc: 0.8387\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 1s 787us/step - loss: 0.2823 - acc: 0.9609 - val_loss: 0.5158 - val_acc: 0.8427\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1623 - acc: 0.9744 - val_loss: 0.5566 - val_acc: 0.8589\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.1658 - acc: 0.9730 - val_loss: 0.6775 - val_acc: 0.8508\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 1s 801us/step - loss: 0.2045 - acc: 0.9690 - val_loss: 0.5794 - val_acc: 0.8427\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 1s 747us/step - loss: 0.1674 - acc: 0.9730 - val_loss: 0.5420 - val_acc: 0.8710\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 1s 725us/step - loss: 0.3581 - acc: 0.9636 - val_loss: 0.5250 - val_acc: 0.8508\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 1s 758us/step - loss: 0.1952 - acc: 0.9704 - val_loss: 0.5830 - val_acc: 0.8589\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.1367 - acc: 0.9744 - val_loss: 0.6007 - val_acc: 0.8468\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.1348 - acc: 0.9852 - val_loss: 0.5978 - val_acc: 0.8669\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 1s 757us/step - loss: 0.2531 - acc: 0.9663 - val_loss: 0.6781 - val_acc: 0.8468\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 1s 795us/step - loss: 0.2504 - acc: 0.9717 - val_loss: 0.6749 - val_acc: 0.8468\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 1s 735us/step - loss: 0.3112 - acc: 0.9650 - val_loss: 0.8573 - val_acc: 0.8468\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 1s 722us/step - loss: 0.1457 - acc: 0.9784 - val_loss: 0.8402 - val_acc: 0.8508\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 1s 808us/step - loss: 0.3145 - acc: 0.9596 - val_loss: 0.5107 - val_acc: 0.8790\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.2125 - acc: 0.9771 - val_loss: 0.5852 - val_acc: 0.8629\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2054 - acc: 0.9717 - val_loss: 0.5382 - val_acc: 0.8669\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2328 - acc: 0.9690 - val_loss: 0.4866 - val_acc: 0.8710\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 1s 791us/step - loss: 0.1333 - acc: 0.9771 - val_loss: 0.4637 - val_acc: 0.8790\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 1s 767us/step - loss: 0.3403 - acc: 0.9596 - val_loss: 0.4623 - val_acc: 0.8589\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 1s 753us/step - loss: 0.1870 - acc: 0.9730 - val_loss: 0.5319 - val_acc: 0.8710\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 1s 779us/step - loss: 0.1492 - acc: 0.9757 - val_loss: 0.5727 - val_acc: 0.8750\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 755us/step - loss: 0.2281 - acc: 0.9677 - val_loss: 0.4872 - val_acc: 0.8831\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 1s 751us/step - loss: 0.1592 - acc: 0.9798 - val_loss: 0.4821 - val_acc: 0.8911\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1710 - acc: 0.9744 - val_loss: 0.7832 - val_acc: 0.8750\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 1s 764us/step - loss: 0.2013 - acc: 0.9744 - val_loss: 0.5655 - val_acc: 0.8831\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 1s 734us/step - loss: 0.2112 - acc: 0.9636 - val_loss: 0.6840 - val_acc: 0.8548\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 1s 748us/step - loss: 0.1803 - acc: 0.9757 - val_loss: 0.6701 - val_acc: 0.8750\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.1133 - acc: 0.9865 - val_loss: 0.5428 - val_acc: 0.8548\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 0.2006 - acc: 0.9730 - val_loss: 0.5132 - val_acc: 0.8952\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 1s 750us/step - loss: 0.2622 - acc: 0.9690 - val_loss: 0.5573 - val_acc: 0.8871\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 1s 731us/step - loss: 0.2002 - acc: 0.9798 - val_loss: 0.6715 - val_acc: 0.8750\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.3164 - acc: 0.9528 - val_loss: 0.5301 - val_acc: 0.8790\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.1195 - acc: 0.9852 - val_loss: 0.5454 - val_acc: 0.8790\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 1s 718us/step - loss: 0.2304 - acc: 0.9757 - val_loss: 0.6130 - val_acc: 0.8347\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 1s 738us/step - loss: 0.2917 - acc: 0.9609 - val_loss: 0.5548 - val_acc: 0.8508\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 1s 762us/step - loss: 0.1513 - acc: 0.9798 - val_loss: 0.5770 - val_acc: 0.8347\n",
      "Epoch 961/1000\n",
      "742/742 [==============================] - 1s 704us/step - loss: 0.1985 - acc: 0.9690 - val_loss: 0.5703 - val_acc: 0.8669\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.1070 - acc: 0.9825 - val_loss: 0.5002 - val_acc: 0.8669\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 1s 766us/step - loss: 0.1514 - acc: 0.9757 - val_loss: 0.4799 - val_acc: 0.8790\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.2130 - acc: 0.9704 - val_loss: 0.4886 - val_acc: 0.8911\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 1s 713us/step - loss: 0.2118 - acc: 0.9650 - val_loss: 0.5303 - val_acc: 0.8790\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.1035 - acc: 0.9771 - val_loss: 0.5130 - val_acc: 0.8548\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 1s 717us/step - loss: 0.1787 - acc: 0.9650 - val_loss: 0.5288 - val_acc: 0.8831\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2936 - acc: 0.9730 - val_loss: 0.6537 - val_acc: 0.8347\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2928 - acc: 0.9609 - val_loss: 0.7338 - val_acc: 0.8831\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.1926 - acc: 0.9744 - val_loss: 0.6856 - val_acc: 0.8548\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 1s 740us/step - loss: 0.2531 - acc: 0.9704 - val_loss: 0.5807 - val_acc: 0.8871\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 1s 746us/step - loss: 0.4563 - acc: 0.9582 - val_loss: 0.7986 - val_acc: 0.8387\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 1s 733us/step - loss: 0.2056 - acc: 0.9704 - val_loss: 0.4959 - val_acc: 0.8831\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.1668 - acc: 0.9650 - val_loss: 0.4884 - val_acc: 0.8750\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 1s 765us/step - loss: 0.2986 - acc: 0.9515 - val_loss: 0.5518 - val_acc: 0.8508\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.0564 - acc: 0.9892 - val_loss: 0.6511 - val_acc: 0.8790\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.1477 - acc: 0.9784 - val_loss: 0.8045 - val_acc: 0.8347\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 0.1202 - acc: 0.9825 - val_loss: 0.5935 - val_acc: 0.8589\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2195 - acc: 0.9704 - val_loss: 0.4712 - val_acc: 0.8992\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.2060 - acc: 0.9730 - val_loss: 0.6663 - val_acc: 0.8548\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.2461 - acc: 0.9690 - val_loss: 0.5164 - val_acc: 0.8911\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.1831 - acc: 0.9771 - val_loss: 0.4752 - val_acc: 0.8871\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.0766 - acc: 0.9892 - val_loss: 0.4267 - val_acc: 0.9032\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 1s 786us/step - loss: 0.1495 - acc: 0.9811 - val_loss: 0.4910 - val_acc: 0.8952\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 1s 743us/step - loss: 0.2107 - acc: 0.9757 - val_loss: 0.4565 - val_acc: 0.8669\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 1s 784us/step - loss: 0.2612 - acc: 0.9690 - val_loss: 0.6775 - val_acc: 0.8589\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.1384 - acc: 0.9744 - val_loss: 0.6362 - val_acc: 0.8548\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 1s 719us/step - loss: 0.3016 - acc: 0.9677 - val_loss: 0.7506 - val_acc: 0.8508\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 1s 744us/step - loss: 0.2088 - acc: 0.9704 - val_loss: 0.5592 - val_acc: 0.8831\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 1s 759us/step - loss: 0.1387 - acc: 0.9811 - val_loss: 0.5952 - val_acc: 0.8669\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 0.3016 - acc: 0.9690 - val_loss: 0.6548 - val_acc: 0.8871\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 1s 742us/step - loss: 0.2085 - acc: 0.9744 - val_loss: 0.5393 - val_acc: 0.8871\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 1s 737us/step - loss: 0.2816 - acc: 0.9636 - val_loss: 0.5014 - val_acc: 0.8911\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 1s 772us/step - loss: 0.1530 - acc: 0.9784 - val_loss: 0.5784 - val_acc: 0.8790\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 1s 761us/step - loss: 0.1412 - acc: 0.9798 - val_loss: 0.7672 - val_acc: 0.8427\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 1s 741us/step - loss: 0.2295 - acc: 0.9744 - val_loss: 0.4901 - val_acc: 0.8750\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 1s 739us/step - loss: 0.2981 - acc: 0.9663 - val_loss: 0.5117 - val_acc: 0.8952\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 0.3138 - acc: 0.9528 - val_loss: 0.6806 - val_acc: 0.8468\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 1s 720us/step - loss: 0.2804 - acc: 0.9717 - val_loss: 0.5226 - val_acc: 0.8710\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 1s 806us/step - loss: 0.3595 - acc: 0.9636 - val_loss: 0.5327 - val_acc: 0.8710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, \n",
    "                    epochs=1000,  \n",
    "                    validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be6c77a6a0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be6c7def98>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('loss'), 'y', label='Training loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), 'b', label='Test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果：对训练数据的拟合精度基本不受影响，但把过拟合问题给减弱了！对测试数据的预测精度又有了一点的提升。\n",
    "\n",
    "问题：对测试数据的精度还是不够满意！能不能再提高对测试数据的预测精度？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化4："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保持上一种的网络结构，此时把每个卷积层的“卷积核大小”增大（由原来的7变11）！即增大每个卷积的“感受野”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 11, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(32, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 192, 32)           384       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 192, 32)           11296     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 64, 64)            22592     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 64, 64)            45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 21, 128)           90240     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 21, 128)           180352    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 7, 256)            360704    \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 7, 256)            721152    \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 99)                25443     \n",
      "=================================================================\n",
      "Total params: 1,457,283\n",
      "Trainable params: 1,457,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 4.6058 - acc: 0.0081 - val_loss: 4.5978 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 4.6004 - acc: 0.0081 - val_loss: 4.5920 - val_acc: 0.0081\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 4.5570 - acc: 0.0175 - val_loss: 4.5718 - val_acc: 0.0081\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 1s 808us/step - loss: 4.4646 - acc: 0.0148 - val_loss: 4.3999 - val_acc: 0.0081\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 1s 805us/step - loss: 4.4445 - acc: 0.0216 - val_loss: 4.5878 - val_acc: 0.0161\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 1s 822us/step - loss: 4.3410 - acc: 0.0175 - val_loss: 4.2914 - val_acc: 0.0161\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 4.2709 - acc: 0.0148 - val_loss: 4.2811 - val_acc: 0.0202\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 4.2034 - acc: 0.0229 - val_loss: 4.2159 - val_acc: 0.0121\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 1s 806us/step - loss: 4.1676 - acc: 0.0229 - val_loss: 4.1603 - val_acc: 0.0121\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 4.1303 - acc: 0.0310 - val_loss: 4.1101 - val_acc: 0.0081\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 4.0786 - acc: 0.0175 - val_loss: 4.0874 - val_acc: 0.0161\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 3.9959 - acc: 0.0350 - val_loss: 4.1626 - val_acc: 0.0161\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 3.9381 - acc: 0.0310 - val_loss: 4.0957 - val_acc: 0.0161\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 1s 811us/step - loss: 3.8950 - acc: 0.0499 - val_loss: 4.0590 - val_acc: 0.0242\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 1s 809us/step - loss: 3.8920 - acc: 0.0391 - val_loss: 3.9422 - val_acc: 0.0161\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 1s 811us/step - loss: 3.8535 - acc: 0.0377 - val_loss: 3.8539 - val_acc: 0.0161\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 3.7597 - acc: 0.0553 - val_loss: 4.3459 - val_acc: 0.0040\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 3.7515 - acc: 0.0472 - val_loss: 3.9378 - val_acc: 0.0202\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 1s 819us/step - loss: 3.6951 - acc: 0.0458 - val_loss: 4.1723 - val_acc: 0.0202\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 1s 814us/step - loss: 3.6759 - acc: 0.0499 - val_loss: 3.7263 - val_acc: 0.0242\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 1s 793us/step - loss: 3.6330 - acc: 0.0633 - val_loss: 3.8835 - val_acc: 0.0403\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 1s 830us/step - loss: 3.5779 - acc: 0.0512 - val_loss: 4.0902 - val_acc: 0.0121\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 3.5669 - acc: 0.0458 - val_loss: 4.2047 - val_acc: 0.0121\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 3.5398 - acc: 0.0606 - val_loss: 4.4368 - val_acc: 0.0081\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 1s 802us/step - loss: 3.5666 - acc: 0.0512 - val_loss: 4.1709 - val_acc: 0.0081\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 1s 820us/step - loss: 3.5035 - acc: 0.0553 - val_loss: 4.0106 - val_acc: 0.0282\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 3.4843 - acc: 0.0539 - val_loss: 4.7050 - val_acc: 0.0121\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 3.4571 - acc: 0.0674 - val_loss: 3.9640 - val_acc: 0.0202\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 1s 801us/step - loss: 3.4261 - acc: 0.0701 - val_loss: 3.9119 - val_acc: 0.0403\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 1s 822us/step - loss: 3.4196 - acc: 0.0795 - val_loss: 4.4693 - val_acc: 0.0242\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 3.3468 - acc: 0.0822 - val_loss: 4.2215 - val_acc: 0.0121\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 1s 793us/step - loss: 3.2900 - acc: 0.0984 - val_loss: 4.4020 - val_acc: 0.0081\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 1s 829us/step - loss: 3.2576 - acc: 0.0849 - val_loss: 3.8961 - val_acc: 0.0444\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 1s 788us/step - loss: 3.2474 - acc: 0.0916 - val_loss: 4.2446 - val_acc: 0.0323\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 3.1958 - acc: 0.0984 - val_loss: 4.0181 - val_acc: 0.0282\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 1s 796us/step - loss: 3.1566 - acc: 0.0997 - val_loss: 4.4053 - val_acc: 0.0242\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 1s 824us/step - loss: 3.0997 - acc: 0.1334 - val_loss: 4.1099 - val_acc: 0.0444\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 1s 822us/step - loss: 2.9871 - acc: 0.1577 - val_loss: 4.8694 - val_acc: 0.0282\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 2.9655 - acc: 0.1496 - val_loss: 4.4776 - val_acc: 0.0403\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 1s 819us/step - loss: 2.8893 - acc: 0.1550 - val_loss: 4.1600 - val_acc: 0.0484\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 1s 818us/step - loss: 2.8064 - acc: 0.1698 - val_loss: 4.1444 - val_acc: 0.0444\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 1s 814us/step - loss: 2.7685 - acc: 0.1833 - val_loss: 3.5742 - val_acc: 0.0847\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 1s 797us/step - loss: 2.7512 - acc: 0.2156 - val_loss: 3.9405 - val_acc: 0.0968\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 2.5899 - acc: 0.2251 - val_loss: 3.5228 - val_acc: 0.1250\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 1s 817us/step - loss: 2.6157 - acc: 0.2049 - val_loss: 3.5715 - val_acc: 0.1210\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 1s 800us/step - loss: 2.4733 - acc: 0.2588 - val_loss: 4.0685 - val_acc: 0.1169: 0s - loss: 2.5554 - acc: 0.23\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 1s 809us/step - loss: 2.4391 - acc: 0.2803 - val_loss: 3.9569 - val_acc: 0.0887\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 1s 812us/step - loss: 2.3585 - acc: 0.2911 - val_loss: 3.9653 - val_acc: 0.1129\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 1s 834us/step - loss: 2.2991 - acc: 0.2776 - val_loss: 5.0440 - val_acc: 0.0766\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 1s 821us/step - loss: 2.2807 - acc: 0.3005 - val_loss: 3.1626 - val_acc: 0.1855\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 1s 795us/step - loss: 2.2266 - acc: 0.2978 - val_loss: 3.9279 - val_acc: 0.1532\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 1s 841us/step - loss: 2.1447 - acc: 0.3235 - val_loss: 3.4397 - val_acc: 0.1129\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 1s 798us/step - loss: 2.1181 - acc: 0.3235 - val_loss: 3.3960 - val_acc: 0.1613\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 1s 828us/step - loss: 2.0815 - acc: 0.3329 - val_loss: 4.4056 - val_acc: 0.1048\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 1s 824us/step - loss: 2.0017 - acc: 0.3801 - val_loss: 3.1482 - val_acc: 0.1331\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 1s 814us/step - loss: 1.9949 - acc: 0.3504 - val_loss: 3.3548 - val_acc: 0.1573\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 1s 823us/step - loss: 1.8781 - acc: 0.3976 - val_loss: 3.2772 - val_acc: 0.1694\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 1s 821us/step - loss: 1.8891 - acc: 0.3922 - val_loss: 3.3736 - val_acc: 0.1935\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 1s 811us/step - loss: 1.8281 - acc: 0.4151 - val_loss: 3.7621 - val_acc: 0.1694\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 1s 821us/step - loss: 1.7254 - acc: 0.4515 - val_loss: 3.3031 - val_acc: 0.1855\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 1.6336 - acc: 0.4690 - val_loss: 3.7973 - val_acc: 0.1694\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 1s 803us/step - loss: 1.5571 - acc: 0.4865 - val_loss: 2.9819 - val_acc: 0.2621\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 1.7485 - acc: 0.4555 - val_loss: 3.0600 - val_acc: 0.2016\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 1s 830us/step - loss: 1.5999 - acc: 0.4488 - val_loss: 3.2642 - val_acc: 0.2258\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 1s 817us/step - loss: 1.5530 - acc: 0.4879 - val_loss: 4.4702 - val_acc: 0.1573\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 1s 799us/step - loss: 1.5666 - acc: 0.4879 - val_loss: 3.4238 - val_acc: 0.2177\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 1s 831us/step - loss: 1.5435 - acc: 0.5162 - val_loss: 3.0190 - val_acc: 0.2742\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 1s 810us/step - loss: 1.4711 - acc: 0.5121 - val_loss: 2.9755 - val_acc: 0.2702\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 1s 811us/step - loss: 1.4101 - acc: 0.5310 - val_loss: 2.7598 - val_acc: 0.2782\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 1s 832us/step - loss: 1.4410 - acc: 0.5094 - val_loss: 2.5843 - val_acc: 0.3185\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 1.3623 - acc: 0.5364 - val_loss: 2.4936 - val_acc: 0.3629\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 1s 819us/step - loss: 1.3646 - acc: 0.5472 - val_loss: 2.5902 - val_acc: 0.3387\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 1s 820us/step - loss: 1.2471 - acc: 0.5930 - val_loss: 2.9141 - val_acc: 0.3629\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 1s 818us/step - loss: 1.3538 - acc: 0.5499 - val_loss: 3.4072 - val_acc: 0.2419\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 1s 819us/step - loss: 1.1961 - acc: 0.5916 - val_loss: 3.5768 - val_acc: 0.2298\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 1.2217 - acc: 0.5822 - val_loss: 3.5045 - val_acc: 0.2339\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 1s 805us/step - loss: 1.1849 - acc: 0.6415 - val_loss: 2.0786 - val_acc: 0.4194\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 1s 815us/step - loss: 1.1818 - acc: 0.6065 - val_loss: 2.0931 - val_acc: 0.4758\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 1s 834us/step - loss: 1.1509 - acc: 0.6173 - val_loss: 2.9473 - val_acc: 0.3508\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 1s 821us/step - loss: 1.1198 - acc: 0.6280 - val_loss: 2.6302 - val_acc: 0.3589\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 1s 829us/step - loss: 1.0937 - acc: 0.6415 - val_loss: 4.6725 - val_acc: 0.1694\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 1s 816us/step - loss: 1.0078 - acc: 0.6482 - val_loss: 2.7047 - val_acc: 0.3952\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 1s 813us/step - loss: 1.0409 - acc: 0.6698 - val_loss: 3.7207 - val_acc: 0.2984\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 1s 831us/step - loss: 0.9646 - acc: 0.6604 - val_loss: 2.8989 - val_acc: 0.3750\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 1s 839us/step - loss: 0.9198 - acc: 0.6941 - val_loss: 3.1200 - val_acc: 0.3185\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 1s 840us/step - loss: 0.8813 - acc: 0.7156 - val_loss: 3.8744 - val_acc: 0.2621\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 1s 830us/step - loss: 0.9116 - acc: 0.7183 - val_loss: 2.9831 - val_acc: 0.4032\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 1s 847us/step - loss: 0.9641 - acc: 0.6981 - val_loss: 2.6962 - val_acc: 0.4073\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 1s 835us/step - loss: 0.8911 - acc: 0.7022 - val_loss: 2.2157 - val_acc: 0.4516\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 1s 831us/step - loss: 0.8348 - acc: 0.7251 - val_loss: 3.6701 - val_acc: 0.2702\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 1s 854us/step - loss: 0.8129 - acc: 0.7197 - val_loss: 2.5198 - val_acc: 0.4476\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 1s 834us/step - loss: 0.8904 - acc: 0.7237 - val_loss: 2.6005 - val_acc: 0.3871\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 1s 849us/step - loss: 0.8215 - acc: 0.7022 - val_loss: 2.1095 - val_acc: 0.5040\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 1s 854us/step - loss: 0.8178 - acc: 0.7345 - val_loss: 3.4303 - val_acc: 0.3589\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.7640 - acc: 0.7493 - val_loss: 2.3153 - val_acc: 0.4798\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.7464 - acc: 0.7588 - val_loss: 3.3898 - val_acc: 0.3589\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.7181 - acc: 0.7642 - val_loss: 4.0426 - val_acc: 0.2661\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.8091 - acc: 0.7399 - val_loss: 3.7981 - val_acc: 0.3387\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.7525 - acc: 0.7426 - val_loss: 3.6605 - val_acc: 0.2782\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.6862 - acc: 0.7574 - val_loss: 3.2813 - val_acc: 0.3710\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 1s 939us/step - loss: 0.7354 - acc: 0.7642 - val_loss: 2.7566 - val_acc: 0.4113\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.6845 - acc: 0.7749 - val_loss: 3.3230 - val_acc: 0.3992\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 1s 941us/step - loss: 0.6904 - acc: 0.7722 - val_loss: 1.7448 - val_acc: 0.6089\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 1s 920us/step - loss: 0.5940 - acc: 0.8073 - val_loss: 2.4964 - val_acc: 0.4879\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.5708 - acc: 0.8194 - val_loss: 4.6672 - val_acc: 0.3347\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 1s 931us/step - loss: 0.6075 - acc: 0.7951 - val_loss: 3.0786 - val_acc: 0.4758\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 1s 941us/step - loss: 0.6252 - acc: 0.8140 - val_loss: 2.9917 - val_acc: 0.4315\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 1s 934us/step - loss: 0.6914 - acc: 0.7803 - val_loss: 1.8664 - val_acc: 0.5968\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 1s 953us/step - loss: 0.5232 - acc: 0.8302 - val_loss: 2.3978 - val_acc: 0.4758\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 1s 964us/step - loss: 0.5154 - acc: 0.8342 - val_loss: 5.3123 - val_acc: 0.2379\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 1s 960us/step - loss: 0.5858 - acc: 0.7898 - val_loss: 2.6109 - val_acc: 0.4839\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 1s 968us/step - loss: 0.5413 - acc: 0.8396 - val_loss: 3.1751 - val_acc: 0.4597\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 1s 969us/step - loss: 0.5973 - acc: 0.8100 - val_loss: 2.7162 - val_acc: 0.5081\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.6201 - acc: 0.8113 - val_loss: 2.8071 - val_acc: 0.4637\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 1s 970us/step - loss: 0.5295 - acc: 0.8208 - val_loss: 2.7440 - val_acc: 0.4839\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 1s 984us/step - loss: 0.5765 - acc: 0.8181 - val_loss: 2.2882 - val_acc: 0.5081\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.5503 - acc: 0.8154 - val_loss: 3.7316 - val_acc: 0.4274\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.4722 - acc: 0.8477 - val_loss: 2.3095 - val_acc: 0.5081\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.5214 - acc: 0.8450 - val_loss: 3.8723 - val_acc: 0.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.4458 - acc: 0.8544 - val_loss: 2.9548 - val_acc: 0.4677\n",
      "Epoch 121/1000\n",
      "742/742 [==============================] - 1s 991us/step - loss: 0.4173 - acc: 0.8544 - val_loss: 3.1684 - val_acc: 0.4677\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 1s 996us/step - loss: 0.4702 - acc: 0.8504 - val_loss: 2.2898 - val_acc: 0.5161\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.5016 - acc: 0.8315 - val_loss: 2.2048 - val_acc: 0.5403\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.4388 - acc: 0.8558 - val_loss: 2.3782 - val_acc: 0.5323\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 1s 976us/step - loss: 0.4297 - acc: 0.8652 - val_loss: 1.9080 - val_acc: 0.6250\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.3669 - acc: 0.8760 - val_loss: 2.0821 - val_acc: 0.5565\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.4276 - acc: 0.8706 - val_loss: 1.8226 - val_acc: 0.6411\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.4644 - acc: 0.8585 - val_loss: 3.0841 - val_acc: 0.4758\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 1s 923us/step - loss: 0.3632 - acc: 0.8706 - val_loss: 3.4146 - val_acc: 0.4113\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 1s 918us/step - loss: 0.3394 - acc: 0.8922 - val_loss: 2.5907 - val_acc: 0.5242\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.4327 - acc: 0.8720 - val_loss: 2.5292 - val_acc: 0.5000\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.4747 - acc: 0.8639 - val_loss: 2.6355 - val_acc: 0.5040\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.3822 - acc: 0.8854 - val_loss: 2.7497 - val_acc: 0.5202\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.3331 - acc: 0.8949 - val_loss: 2.1833 - val_acc: 0.5323\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 1s 914us/step - loss: 0.3791 - acc: 0.8935 - val_loss: 2.2848 - val_acc: 0.5484\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 1s 903us/step - loss: 0.3393 - acc: 0.9016 - val_loss: 1.7221 - val_acc: 0.6653\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 1s 888us/step - loss: 0.3527 - acc: 0.8720 - val_loss: 2.4612 - val_acc: 0.5323\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.4627 - acc: 0.8747 - val_loss: 1.8527 - val_acc: 0.6331\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.3196 - acc: 0.9097 - val_loss: 1.7761 - val_acc: 0.5806\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.3188 - acc: 0.9151 - val_loss: 2.6435 - val_acc: 0.4718\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.3406 - acc: 0.8908 - val_loss: 1.5510 - val_acc: 0.6532\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.4092 - acc: 0.8747 - val_loss: 1.8676 - val_acc: 0.5766\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 1s 924us/step - loss: 0.3407 - acc: 0.9070 - val_loss: 2.5767 - val_acc: 0.5121\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 1s 929us/step - loss: 0.3118 - acc: 0.9164 - val_loss: 2.6499 - val_acc: 0.5040\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 1s 925us/step - loss: 0.3234 - acc: 0.9016 - val_loss: 2.3338 - val_acc: 0.5605\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 1s 909us/step - loss: 0.3108 - acc: 0.8962 - val_loss: 1.8545 - val_acc: 0.5847\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.3270 - acc: 0.9030 - val_loss: 3.4102 - val_acc: 0.3952\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.3396 - acc: 0.8949 - val_loss: 2.4999 - val_acc: 0.5161\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 1s 938us/step - loss: 0.2822 - acc: 0.9043 - val_loss: 1.9872 - val_acc: 0.6250\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.3203 - acc: 0.8989 - val_loss: 2.5454 - val_acc: 0.5081\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.3058 - acc: 0.9084 - val_loss: 2.7593 - val_acc: 0.5161\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 1s 977us/step - loss: 0.2497 - acc: 0.9245 - val_loss: 1.5606 - val_acc: 0.6492\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3204 - acc: 0.9070 - val_loss: 1.3219 - val_acc: 0.6895\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3495 - acc: 0.9057 - val_loss: 1.6093 - val_acc: 0.6210\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 1s 979us/step - loss: 0.2971 - acc: 0.9137 - val_loss: 2.0621 - val_acc: 0.5605\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 1s 969us/step - loss: 0.3051 - acc: 0.9124 - val_loss: 2.7671 - val_acc: 0.4960\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 1s 951us/step - loss: 0.2192 - acc: 0.9313 - val_loss: 1.5154 - val_acc: 0.7056\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 1s 966us/step - loss: 0.2361 - acc: 0.9299 - val_loss: 1.8700 - val_acc: 0.6492\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 1s 960us/step - loss: 0.2830 - acc: 0.9326 - val_loss: 1.7359 - val_acc: 0.6613\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 1s 961us/step - loss: 0.2738 - acc: 0.9097 - val_loss: 1.7713 - val_acc: 0.6653\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 1s 974us/step - loss: 0.2339 - acc: 0.9407 - val_loss: 1.6340 - val_acc: 0.6976\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 1s 973us/step - loss: 0.3210 - acc: 0.9016 - val_loss: 1.6763 - val_acc: 0.6532\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 1s 945us/step - loss: 0.2982 - acc: 0.9205 - val_loss: 2.9390 - val_acc: 0.4274\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 1s 918us/step - loss: 0.2239 - acc: 0.9286 - val_loss: 1.3518 - val_acc: 0.7258\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 1s 949us/step - loss: 0.2641 - acc: 0.9286 - val_loss: 2.0865 - val_acc: 0.6371\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 1s 941us/step - loss: 0.3249 - acc: 0.9043 - val_loss: 1.6879 - val_acc: 0.6653\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 1s 939us/step - loss: 0.2673 - acc: 0.9191 - val_loss: 1.5211 - val_acc: 0.6694\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 1s 963us/step - loss: 0.2376 - acc: 0.9245 - val_loss: 2.5189 - val_acc: 0.5565\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 1s 935us/step - loss: 0.2496 - acc: 0.9353 - val_loss: 1.3952 - val_acc: 0.7097\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 1s 962us/step - loss: 0.1971 - acc: 0.9474 - val_loss: 3.2081 - val_acc: 0.4556\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2422 - acc: 0.9313 - val_loss: 2.5548 - val_acc: 0.5847\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2065 - acc: 0.9380 - val_loss: 1.6703 - val_acc: 0.6653\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.2197 - acc: 0.9340 - val_loss: 1.9979 - val_acc: 0.6653\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 1s 976us/step - loss: 0.2806 - acc: 0.9286 - val_loss: 1.5536 - val_acc: 0.6895\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 1s 962us/step - loss: 0.2609 - acc: 0.9272 - val_loss: 1.5747 - val_acc: 0.7016\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 1s 965us/step - loss: 0.2782 - acc: 0.9259 - val_loss: 1.2976 - val_acc: 0.7177\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 1s 992us/step - loss: 0.1962 - acc: 0.9420 - val_loss: 1.8776 - val_acc: 0.6573\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 1s 997us/step - loss: 0.2038 - acc: 0.9434 - val_loss: 2.9856 - val_acc: 0.5605\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2929 - acc: 0.9272 - val_loss: 1.2623 - val_acc: 0.7339\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 1s 999us/step - loss: 0.2106 - acc: 0.9447 - val_loss: 2.3724 - val_acc: 0.6089\n",
      "Epoch 181/1000\n",
      "742/742 [==============================] - 1s 977us/step - loss: 0.2693 - acc: 0.9313 - val_loss: 2.3799 - val_acc: 0.6008\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.2202 - acc: 0.9434 - val_loss: 1.8487 - val_acc: 0.6935\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 1s 960us/step - loss: 0.1874 - acc: 0.9394 - val_loss: 1.1267 - val_acc: 0.7742\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 1s 962us/step - loss: 0.2660 - acc: 0.9164 - val_loss: 2.1230 - val_acc: 0.6411\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 1s 932us/step - loss: 0.2002 - acc: 0.9461 - val_loss: 2.3092 - val_acc: 0.5524\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 1s 923us/step - loss: 0.2640 - acc: 0.9313 - val_loss: 2.7586 - val_acc: 0.5927\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.2071 - acc: 0.9434 - val_loss: 2.8216 - val_acc: 0.5403\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.3077 - acc: 0.9232 - val_loss: 3.7390 - val_acc: 0.4234\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 1s 913us/step - loss: 0.2034 - acc: 0.9420 - val_loss: 1.3515 - val_acc: 0.7298\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.2748 - acc: 0.9205 - val_loss: 2.6929 - val_acc: 0.5766\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.1777 - acc: 0.9434 - val_loss: 2.1136 - val_acc: 0.6573\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 1s 916us/step - loss: 0.1893 - acc: 0.9474 - val_loss: 3.0327 - val_acc: 0.5444\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 1s 910us/step - loss: 0.2243 - acc: 0.9272 - val_loss: 2.3561 - val_acc: 0.5887\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2321 - acc: 0.9313 - val_loss: 4.0588 - val_acc: 0.4637\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 1s 925us/step - loss: 0.2646 - acc: 0.9447 - val_loss: 0.8299 - val_acc: 0.8226\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 1s 914us/step - loss: 0.2529 - acc: 0.9380 - val_loss: 1.8302 - val_acc: 0.6815\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.2347 - acc: 0.9313 - val_loss: 1.9765 - val_acc: 0.6815\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 1s 916us/step - loss: 0.1669 - acc: 0.9528 - val_loss: 2.3197 - val_acc: 0.6411\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.1896 - acc: 0.9515 - val_loss: 2.1500 - val_acc: 0.6532\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 1s 918us/step - loss: 0.1624 - acc: 0.9542 - val_loss: 2.2057 - val_acc: 0.6492\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 1s 923us/step - loss: 0.2849 - acc: 0.9407 - val_loss: 1.8254 - val_acc: 0.6532\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2511 - acc: 0.9447 - val_loss: 1.2817 - val_acc: 0.7782\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 1s 917us/step - loss: 0.1267 - acc: 0.9555 - val_loss: 1.4547 - val_acc: 0.7339\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.2874 - acc: 0.9367 - val_loss: 1.3012 - val_acc: 0.7742\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.1872 - acc: 0.9569 - val_loss: 1.8737 - val_acc: 0.6371\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 1s 920us/step - loss: 0.2039 - acc: 0.9636 - val_loss: 1.2148 - val_acc: 0.7661\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.2211 - acc: 0.9501 - val_loss: 1.1999 - val_acc: 0.7621\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 1s 930us/step - loss: 0.2508 - acc: 0.9380 - val_loss: 1.7532 - val_acc: 0.6815\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.1537 - acc: 0.9582 - val_loss: 0.9304 - val_acc: 0.8065\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 1s 917us/step - loss: 0.3166 - acc: 0.9205 - val_loss: 1.9264 - val_acc: 0.6653\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 1s 913us/step - loss: 0.1765 - acc: 0.9528 - val_loss: 2.9680 - val_acc: 0.5806\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 1s 932us/step - loss: 0.1587 - acc: 0.9555 - val_loss: 1.4275 - val_acc: 0.7419\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 1s 930us/step - loss: 0.3019 - acc: 0.9286 - val_loss: 1.3017 - val_acc: 0.7419\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.2232 - acc: 0.9542 - val_loss: 0.9566 - val_acc: 0.8024\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 1s 944us/step - loss: 0.2489 - acc: 0.9380 - val_loss: 3.9996 - val_acc: 0.4677\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 1s 930us/step - loss: 0.1620 - acc: 0.9515 - val_loss: 2.5833 - val_acc: 0.5565\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 1s 917us/step - loss: 0.1326 - acc: 0.9650 - val_loss: 1.2749 - val_acc: 0.7661\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.2060 - acc: 0.9447 - val_loss: 1.7869 - val_acc: 0.6895\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 1s 931us/step - loss: 0.1634 - acc: 0.9609 - val_loss: 1.3567 - val_acc: 0.7863\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 1s 924us/step - loss: 0.2042 - acc: 0.9474 - val_loss: 1.2511 - val_acc: 0.7944\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 1s 928us/step - loss: 0.2635 - acc: 0.9245 - val_loss: 1.3404 - val_acc: 0.7540\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 1s 937us/step - loss: 0.2159 - acc: 0.9434 - val_loss: 1.4595 - val_acc: 0.7177\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.2145 - acc: 0.9420 - val_loss: 1.9332 - val_acc: 0.6411\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 1s 947us/step - loss: 0.1570 - acc: 0.9569 - val_loss: 2.1036 - val_acc: 0.6089\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.2530 - acc: 0.9488 - val_loss: 0.7854 - val_acc: 0.8266\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 1s 929us/step - loss: 0.1702 - acc: 0.9596 - val_loss: 1.6253 - val_acc: 0.6855\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.2087 - acc: 0.9501 - val_loss: 1.5053 - val_acc: 0.7339\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 1s 941us/step - loss: 0.2421 - acc: 0.9501 - val_loss: 1.5753 - val_acc: 0.7298\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 1s 931us/step - loss: 0.1565 - acc: 0.9555 - val_loss: 2.1459 - val_acc: 0.6653\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 1s 940us/step - loss: 0.2201 - acc: 0.9515 - val_loss: 1.7570 - val_acc: 0.7218\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 1s 935us/step - loss: 0.1642 - acc: 0.9528 - val_loss: 1.9165 - val_acc: 0.7016\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 1s 928us/step - loss: 0.1548 - acc: 0.9596 - val_loss: 1.9104 - val_acc: 0.6976\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 1s 954us/step - loss: 0.1244 - acc: 0.9677 - val_loss: 1.1460 - val_acc: 0.7823\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 1s 977us/step - loss: 0.1228 - acc: 0.9717 - val_loss: 2.2139 - val_acc: 0.6452\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 1s 963us/step - loss: 0.2232 - acc: 0.9555 - val_loss: 1.9016 - val_acc: 0.6815\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 1s 948us/step - loss: 0.2035 - acc: 0.9528 - val_loss: 1.2936 - val_acc: 0.7581\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 1s 937us/step - loss: 0.2002 - acc: 0.9501 - val_loss: 3.3735 - val_acc: 0.5403\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 924us/step - loss: 0.2108 - acc: 0.9555 - val_loss: 1.4560 - val_acc: 0.7258\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 1s 932us/step - loss: 0.2136 - acc: 0.9582 - val_loss: 0.9552 - val_acc: 0.7702\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 1s 912us/step - loss: 0.2079 - acc: 0.9447 - val_loss: 0.9516 - val_acc: 0.8024\n",
      "Epoch 241/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.2354 - acc: 0.9420 - val_loss: 1.8070 - val_acc: 0.6855\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.1921 - acc: 0.9474 - val_loss: 1.5499 - val_acc: 0.7218\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.2541 - acc: 0.9340 - val_loss: 1.3214 - val_acc: 0.7258\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.2269 - acc: 0.9447 - val_loss: 2.5815 - val_acc: 0.5645\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 1s 885us/step - loss: 0.2332 - acc: 0.9340 - val_loss: 1.9826 - val_acc: 0.6935\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 1s 887us/step - loss: 0.1013 - acc: 0.9704 - val_loss: 1.7150 - val_acc: 0.6976\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.1461 - acc: 0.9663 - val_loss: 1.4699 - val_acc: 0.7702\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.0984 - acc: 0.9717 - val_loss: 1.8233 - val_acc: 0.7177\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.1865 - acc: 0.9596 - val_loss: 1.7813 - val_acc: 0.7339\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2371 - acc: 0.9474 - val_loss: 2.1388 - val_acc: 0.6774\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.1992 - acc: 0.9501 - val_loss: 1.1265 - val_acc: 0.7823\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 1s 897us/step - loss: 0.1946 - acc: 0.9569 - val_loss: 2.0018 - val_acc: 0.7056\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.2128 - acc: 0.9528 - val_loss: 1.3191 - val_acc: 0.7419\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.1116 - acc: 0.9663 - val_loss: 1.3816 - val_acc: 0.7581\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.1623 - acc: 0.9636 - val_loss: 0.7545 - val_acc: 0.8306\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.1830 - acc: 0.9528 - val_loss: 1.1903 - val_acc: 0.7984\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.1531 - acc: 0.9623 - val_loss: 2.1998 - val_acc: 0.6774\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 1s 974us/step - loss: 0.1946 - acc: 0.9528 - val_loss: 2.7607 - val_acc: 0.6210\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2305 - acc: 0.9569 - val_loss: 1.1143 - val_acc: 0.8185\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1435 - acc: 0.9663 - val_loss: 1.5844 - val_acc: 0.7379\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1259 - acc: 0.9717 - val_loss: 1.7615 - val_acc: 0.7540\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 1s 985us/step - loss: 0.1715 - acc: 0.9609 - val_loss: 1.6088 - val_acc: 0.6976\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 1s 954us/step - loss: 0.1353 - acc: 0.9582 - val_loss: 1.4927 - val_acc: 0.7177\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.1745 - acc: 0.9663 - val_loss: 0.9628 - val_acc: 0.8105\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 1s 942us/step - loss: 0.1223 - acc: 0.9704 - val_loss: 2.0551 - val_acc: 0.6774\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.2002 - acc: 0.9582 - val_loss: 1.1278 - val_acc: 0.7823\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 1s 965us/step - loss: 0.2423 - acc: 0.9488 - val_loss: 1.1014 - val_acc: 0.8024\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1388 - acc: 0.9542 - val_loss: 2.2252 - val_acc: 0.6653\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1765 - acc: 0.9542 - val_loss: 1.3746 - val_acc: 0.7581\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1982 - acc: 0.9663 - val_loss: 0.7721 - val_acc: 0.8508\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 1s 987us/step - loss: 0.2408 - acc: 0.9542 - val_loss: 1.1967 - val_acc: 0.7540\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1253 - acc: 0.9636 - val_loss: 1.3076 - val_acc: 0.7863\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2179 - acc: 0.9447 - val_loss: 1.2274 - val_acc: 0.7863\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1047 - acc: 0.9744 - val_loss: 1.7265 - val_acc: 0.7137\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1341 - acc: 0.9677 - val_loss: 1.4244 - val_acc: 0.7944\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1867 - acc: 0.9569 - val_loss: 1.6392 - val_acc: 0.7460\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2396 - acc: 0.9555 - val_loss: 1.0803 - val_acc: 0.8024\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1702 - acc: 0.9636 - val_loss: 1.3641 - val_acc: 0.7581\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 1s 974us/step - loss: 0.1145 - acc: 0.9690 - val_loss: 2.0007 - val_acc: 0.6976\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2008 - acc: 0.9501 - val_loss: 0.8236 - val_acc: 0.8508\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1280 - acc: 0.9704 - val_loss: 0.9869 - val_acc: 0.8226\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 1s 957us/step - loss: 0.1408 - acc: 0.9650 - val_loss: 1.2052 - val_acc: 0.7702\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 1s 959us/step - loss: 0.1376 - acc: 0.9623 - val_loss: 0.7845 - val_acc: 0.8185\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 1s 947us/step - loss: 0.2553 - acc: 0.9542 - val_loss: 1.1294 - val_acc: 0.7863\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 1s 968us/step - loss: 0.2303 - acc: 0.9474 - val_loss: 1.3766 - val_acc: 0.7298\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.1714 - acc: 0.9596 - val_loss: 1.1180 - val_acc: 0.8226\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 1s 968us/step - loss: 0.1336 - acc: 0.9663 - val_loss: 1.2376 - val_acc: 0.7863\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 1s 949us/step - loss: 0.0868 - acc: 0.9771 - val_loss: 1.1038 - val_acc: 0.8185\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 1s 933us/step - loss: 0.1721 - acc: 0.9663 - val_loss: 1.1517 - val_acc: 0.8024\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 1s 950us/step - loss: 0.2368 - acc: 0.9461 - val_loss: 0.9748 - val_acc: 0.8347\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 1s 960us/step - loss: 0.2396 - acc: 0.9461 - val_loss: 0.8994 - val_acc: 0.8226\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 1s 976us/step - loss: 0.1412 - acc: 0.9636 - val_loss: 1.3682 - val_acc: 0.7460\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 1s 963us/step - loss: 0.1737 - acc: 0.9609 - val_loss: 0.9994 - val_acc: 0.7984\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 1s 964us/step - loss: 0.1551 - acc: 0.9582 - val_loss: 0.9847 - val_acc: 0.8306\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 1s 951us/step - loss: 0.1352 - acc: 0.9730 - val_loss: 1.5345 - val_acc: 0.7379\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 1s 962us/step - loss: 0.1336 - acc: 0.9677 - val_loss: 0.9463 - val_acc: 0.8266\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 1s 955us/step - loss: 0.2872 - acc: 0.9447 - val_loss: 0.6702 - val_acc: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "742/742 [==============================] - 1s 977us/step - loss: 0.1934 - acc: 0.9569 - val_loss: 0.9903 - val_acc: 0.8024\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 1s 942us/step - loss: 0.2285 - acc: 0.9407 - val_loss: 1.4918 - val_acc: 0.7621\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.2439 - acc: 0.9515 - val_loss: 0.6993 - val_acc: 0.8347\n",
      "Epoch 301/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.1390 - acc: 0.9623 - val_loss: 0.8275 - val_acc: 0.8347\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 1s 916us/step - loss: 0.2268 - acc: 0.9488 - val_loss: 1.2828 - val_acc: 0.7702\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.1718 - acc: 0.9677 - val_loss: 1.2446 - val_acc: 0.7661\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 1s 914us/step - loss: 0.1681 - acc: 0.9663 - val_loss: 0.9148 - val_acc: 0.7984\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 1s 933us/step - loss: 0.2222 - acc: 0.9488 - val_loss: 1.2379 - val_acc: 0.7540\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 1s 909us/step - loss: 0.2801 - acc: 0.9407 - val_loss: 1.2209 - val_acc: 0.7419\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 1s 944us/step - loss: 0.1639 - acc: 0.9542 - val_loss: 0.9654 - val_acc: 0.7903\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.1617 - acc: 0.9677 - val_loss: 1.0744 - val_acc: 0.7903\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 1s 968us/step - loss: 0.1539 - acc: 0.9704 - val_loss: 0.9921 - val_acc: 0.7984\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 1s 955us/step - loss: 0.1976 - acc: 0.9542 - val_loss: 1.6962 - val_acc: 0.7500\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 1s 939us/step - loss: 0.1839 - acc: 0.9582 - val_loss: 1.2592 - val_acc: 0.7621\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.1876 - acc: 0.9609 - val_loss: 1.8409 - val_acc: 0.6573\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 1s 930us/step - loss: 0.2355 - acc: 0.9528 - val_loss: 1.1092 - val_acc: 0.7702\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.1707 - acc: 0.9663 - val_loss: 1.0343 - val_acc: 0.7621\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 1s 945us/step - loss: 0.0976 - acc: 0.9690 - val_loss: 1.1882 - val_acc: 0.7944\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.1804 - acc: 0.9596 - val_loss: 1.2575 - val_acc: 0.7540\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 1s 935us/step - loss: 0.2312 - acc: 0.9528 - val_loss: 1.0070 - val_acc: 0.8024\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.2915 - acc: 0.9501 - val_loss: 0.8220 - val_acc: 0.8306\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 1s 920us/step - loss: 0.1654 - acc: 0.9542 - val_loss: 0.8909 - val_acc: 0.8306\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 1s 925us/step - loss: 0.1371 - acc: 0.9704 - val_loss: 0.9693 - val_acc: 0.8347\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 1s 979us/step - loss: 0.1576 - acc: 0.9663 - val_loss: 0.8432 - val_acc: 0.8185\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1502 - acc: 0.9636 - val_loss: 1.0563 - val_acc: 0.8024\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 1s 998us/step - loss: 0.1839 - acc: 0.9677 - val_loss: 1.1620 - val_acc: 0.7823\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 1s 959us/step - loss: 0.2143 - acc: 0.9596 - val_loss: 1.5817 - val_acc: 0.7460\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 1s 930us/step - loss: 0.1494 - acc: 0.9636 - val_loss: 1.0372 - val_acc: 0.7863\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 1s 958us/step - loss: 0.2601 - acc: 0.9501 - val_loss: 2.0416 - val_acc: 0.6976\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 1s 923us/step - loss: 0.2418 - acc: 0.9420 - val_loss: 2.0123 - val_acc: 0.6492\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.1814 - acc: 0.9650 - val_loss: 1.2653 - val_acc: 0.7621\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2478 - acc: 0.9569 - val_loss: 1.4925 - val_acc: 0.6976\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.2078 - acc: 0.9542 - val_loss: 1.7441 - val_acc: 0.7137\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 1s 911us/step - loss: 0.1326 - acc: 0.9650 - val_loss: 0.8835 - val_acc: 0.7944\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.2053 - acc: 0.9515 - val_loss: 1.0369 - val_acc: 0.8226\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 1s 941us/step - loss: 0.1513 - acc: 0.9744 - val_loss: 1.0204 - val_acc: 0.8427\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.1916 - acc: 0.9596 - val_loss: 1.0031 - val_acc: 0.8105\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.1459 - acc: 0.9677 - val_loss: 1.0531 - val_acc: 0.7984\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 1s 913us/step - loss: 0.1997 - acc: 0.9623 - val_loss: 1.1434 - val_acc: 0.8145\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.1752 - acc: 0.966 - 1s 920us/step - loss: 0.1761 - acc: 0.9650 - val_loss: 1.3464 - val_acc: 0.7419\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.2053 - acc: 0.9542 - val_loss: 0.8734 - val_acc: 0.8266\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 1s 939us/step - loss: 0.0848 - acc: 0.9730 - val_loss: 1.1423 - val_acc: 0.8145\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.1073 - acc: 0.9744 - val_loss: 0.7765 - val_acc: 0.8508\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 1s 939us/step - loss: 0.2313 - acc: 0.9582 - val_loss: 0.8032 - val_acc: 0.8347\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.1319 - acc: 0.9717 - val_loss: 1.0336 - val_acc: 0.8065\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 1s 972us/step - loss: 0.1342 - acc: 0.9663 - val_loss: 1.7454 - val_acc: 0.7540\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 1s 991us/step - loss: 0.1868 - acc: 0.9569 - val_loss: 0.4663 - val_acc: 0.8952\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 1s 956us/step - loss: 0.2012 - acc: 0.9582 - val_loss: 0.7767 - val_acc: 0.8347\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.1982 - acc: 0.9663 - val_loss: 1.4107 - val_acc: 0.7500\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 1s 965us/step - loss: 0.2034 - acc: 0.9650 - val_loss: 1.0118 - val_acc: 0.7984\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.2580 - acc: 0.9501 - val_loss: 1.4125 - val_acc: 0.7339\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 1s 954us/step - loss: 0.2208 - acc: 0.9623 - val_loss: 1.1411 - val_acc: 0.8145\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 1s 938us/step - loss: 0.1564 - acc: 0.9690 - val_loss: 1.4178 - val_acc: 0.7702\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.1953 - acc: 0.9677 - val_loss: 0.8288 - val_acc: 0.8226\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.1800 - acc: 0.9623 - val_loss: 1.0214 - val_acc: 0.8024\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 1s 955us/step - loss: 0.1885 - acc: 0.9596 - val_loss: 1.4994 - val_acc: 0.7863\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 1s 928us/step - loss: 0.3084 - acc: 0.9569 - val_loss: 0.7344 - val_acc: 0.8710\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.1456 - acc: 0.9596 - val_loss: 0.8041 - val_acc: 0.8347\n",
      "Epoch 356/1000\n",
      "742/742 [==============================] - 1s 922us/step - loss: 0.1244 - acc: 0.9704 - val_loss: 1.1161 - val_acc: 0.8024\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 920us/step - loss: 0.1132 - acc: 0.9784 - val_loss: 0.8658 - val_acc: 0.8347\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.0754 - acc: 0.9811 - val_loss: 1.5937 - val_acc: 0.7782\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2836 - acc: 0.9555 - val_loss: 0.7999 - val_acc: 0.8589\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1862 - acc: 0.9623 - val_loss: 0.9107 - val_acc: 0.8105\n",
      "Epoch 361/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2292 - acc: 0.9569 - val_loss: 0.8793 - val_acc: 0.8185\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1882 - acc: 0.9677 - val_loss: 1.2353 - val_acc: 0.7863\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1820 - acc: 0.9650 - val_loss: 1.0955 - val_acc: 0.7823\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1884 - acc: 0.9582 - val_loss: 0.9774 - val_acc: 0.8427\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 1s 975us/step - loss: 0.2124 - acc: 0.9650 - val_loss: 1.3328 - val_acc: 0.7782\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 1s 996us/step - loss: 0.2156 - acc: 0.9582 - val_loss: 1.0194 - val_acc: 0.8468\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2096 - acc: 0.9636 - val_loss: 0.9996 - val_acc: 0.8347\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 1s 985us/step - loss: 0.2058 - acc: 0.9596 - val_loss: 0.9161 - val_acc: 0.8306\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2249 - acc: 0.9528 - val_loss: 1.3431 - val_acc: 0.7742\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.2133 - acc: 0.9569 - val_loss: 1.1244 - val_acc: 0.8105\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2375 - acc: 0.9528 - val_loss: 1.2705 - val_acc: 0.7742\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.2108 - acc: 0.9542 - val_loss: 0.7257 - val_acc: 0.8468\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2127 - acc: 0.9582 - val_loss: 0.9311 - val_acc: 0.8185\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 1s 978us/step - loss: 0.2243 - acc: 0.9461 - val_loss: 1.5014 - val_acc: 0.7500\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 1s 947us/step - loss: 0.1026 - acc: 0.9757 - val_loss: 0.7277 - val_acc: 0.8750\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2280 - acc: 0.9677 - val_loss: 0.7992 - val_acc: 0.8508\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 1s 988us/step - loss: 0.1137 - acc: 0.9690 - val_loss: 1.0053 - val_acc: 0.7903\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2089 - acc: 0.9623 - val_loss: 1.9299 - val_acc: 0.7379\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 1s 986us/step - loss: 0.2975 - acc: 0.9555 - val_loss: 1.7687 - val_acc: 0.7056\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 1s 958us/step - loss: 0.2469 - acc: 0.9434 - val_loss: 1.5313 - val_acc: 0.7500\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2407 - acc: 0.9542 - val_loss: 0.8832 - val_acc: 0.8024\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 1s 974us/step - loss: 0.1299 - acc: 0.9609 - val_loss: 0.9284 - val_acc: 0.8145\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 1s 984us/step - loss: 0.1570 - acc: 0.9690 - val_loss: 0.6326 - val_acc: 0.8790\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 1s 985us/step - loss: 0.2796 - acc: 0.9609 - val_loss: 1.1019 - val_acc: 0.7702\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1908 - acc: 0.9569 - val_loss: 1.0192 - val_acc: 0.8105\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1901 - acc: 0.9582 - val_loss: 0.9104 - val_acc: 0.7782\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2082 - acc: 0.9542 - val_loss: 0.9092 - val_acc: 0.8024\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 1s 964us/step - loss: 0.1503 - acc: 0.9690 - val_loss: 1.0072 - val_acc: 0.8105\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 1s 964us/step - loss: 0.1953 - acc: 0.9677 - val_loss: 0.7844 - val_acc: 0.8387\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 1s 957us/step - loss: 0.1218 - acc: 0.9690 - val_loss: 0.6685 - val_acc: 0.8468\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1906 - acc: 0.9690 - val_loss: 0.9101 - val_acc: 0.8427\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 1s 955us/step - loss: 0.1849 - acc: 0.9663 - val_loss: 0.8097 - val_acc: 0.8468\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1964 - acc: 0.9609 - val_loss: 0.8975 - val_acc: 0.8105\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1076 - acc: 0.9677 - val_loss: 1.3718 - val_acc: 0.7984\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3269 - acc: 0.9542 - val_loss: 0.8807 - val_acc: 0.8306\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2646 - acc: 0.9569 - val_loss: 0.7771 - val_acc: 0.8468\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.1734 - acc: 0.9650 - val_loss: 1.2057 - val_acc: 0.8105\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 1s 992us/step - loss: 0.2179 - acc: 0.9636 - val_loss: 0.6546 - val_acc: 0.8750\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 1s 968us/step - loss: 0.1904 - acc: 0.9555 - val_loss: 1.3409 - val_acc: 0.7702\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1885 - acc: 0.9677 - val_loss: 2.4965 - val_acc: 0.6653\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1883 - acc: 0.9704 - val_loss: 0.9255 - val_acc: 0.8145\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1714 - acc: 0.9757 - val_loss: 0.7717 - val_acc: 0.8508\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1983 - acc: 0.9609 - val_loss: 0.7720 - val_acc: 0.8508\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 1s 987us/step - loss: 0.2013 - acc: 0.9623 - val_loss: 0.9929 - val_acc: 0.8226\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2543 - acc: 0.9596 - val_loss: 1.3833 - val_acc: 0.7540\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 1s 973us/step - loss: 0.1635 - acc: 0.9690 - val_loss: 1.3318 - val_acc: 0.7823\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1541 - acc: 0.9690 - val_loss: 0.7659 - val_acc: 0.8427\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 1s 928us/step - loss: 0.2921 - acc: 0.9515 - val_loss: 0.8717 - val_acc: 0.8266\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3239 - acc: 0.9501 - val_loss: 1.1680 - val_acc: 0.8105\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 1s 958us/step - loss: 0.1857 - acc: 0.9690 - val_loss: 0.8360 - val_acc: 0.8387\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.1970 - acc: 0.9663 - val_loss: 1.1061 - val_acc: 0.7581\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.2532 - acc: 0.9488 - val_loss: 0.6648 - val_acc: 0.8548\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 1s 947us/step - loss: 0.2229 - acc: 0.9582 - val_loss: 0.9502 - val_acc: 0.8266\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 1s 965us/step - loss: 0.2432 - acc: 0.9582 - val_loss: 1.1537 - val_acc: 0.7702\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 1s 960us/step - loss: 0.3884 - acc: 0.9367 - val_loss: 1.6368 - val_acc: 0.7298\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1849 - acc: 0.9582 - val_loss: 0.8910 - val_acc: 0.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000\n",
      "742/742 [==============================] - 1s 971us/step - loss: 0.1906 - acc: 0.9569 - val_loss: 0.9191 - val_acc: 0.8387\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 1s 970us/step - loss: 0.2412 - acc: 0.9596 - val_loss: 0.8795 - val_acc: 0.8105\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1736 - acc: 0.9730 - val_loss: 0.9830 - val_acc: 0.8306\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 1s 981us/step - loss: 0.1739 - acc: 0.9704 - val_loss: 1.6603 - val_acc: 0.7863\n",
      "Epoch 421/1000\n",
      "742/742 [==============================] - 1s 994us/step - loss: 0.2348 - acc: 0.9569 - val_loss: 1.0235 - val_acc: 0.8145\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 1s 983us/step - loss: 0.2544 - acc: 0.9582 - val_loss: 1.0905 - val_acc: 0.7863\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1277 - acc: 0.9757 - val_loss: 0.7429 - val_acc: 0.8387\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 1s 953us/step - loss: 0.1661 - acc: 0.9744 - val_loss: 1.2324 - val_acc: 0.7984\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1615 - acc: 0.9690 - val_loss: 0.8937 - val_acc: 0.8306\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3090 - acc: 0.9569 - val_loss: 1.3196 - val_acc: 0.7944\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2027 - acc: 0.9650 - val_loss: 0.7262 - val_acc: 0.8347\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2061 - acc: 0.9663 - val_loss: 0.8858 - val_acc: 0.8065\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3067 - acc: 0.9623 - val_loss: 0.7647 - val_acc: 0.8306\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2306 - acc: 0.9596 - val_loss: 0.7712 - val_acc: 0.8548\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2557 - acc: 0.9596 - val_loss: 0.8440 - val_acc: 0.7903\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 1s 954us/step - loss: 0.2418 - acc: 0.9555 - val_loss: 1.0004 - val_acc: 0.8306\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 1s 996us/step - loss: 0.1754 - acc: 0.9690 - val_loss: 0.9770 - val_acc: 0.8024\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 1s 983us/step - loss: 0.2678 - acc: 0.9542 - val_loss: 1.3053 - val_acc: 0.7581\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2052 - acc: 0.9609 - val_loss: 1.0065 - val_acc: 0.8024\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 1s 984us/step - loss: 0.1701 - acc: 0.9569 - val_loss: 0.9018 - val_acc: 0.8306\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 1s 962us/step - loss: 0.2572 - acc: 0.9609 - val_loss: 0.8321 - val_acc: 0.8548\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 1s 946us/step - loss: 0.2235 - acc: 0.9596 - val_loss: 1.0277 - val_acc: 0.8185\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 1s 970us/step - loss: 0.2422 - acc: 0.9623 - val_loss: 0.9585 - val_acc: 0.8024\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 1s 966us/step - loss: 0.1987 - acc: 0.9596 - val_loss: 0.7291 - val_acc: 0.8710\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1761 - acc: 0.9730 - val_loss: 0.6920 - val_acc: 0.8427\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 1s 987us/step - loss: 0.2411 - acc: 0.9636 - val_loss: 0.7367 - val_acc: 0.8387\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 1s 975us/step - loss: 0.1676 - acc: 0.9717 - val_loss: 1.3485 - val_acc: 0.7984\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 1s 977us/step - loss: 0.2430 - acc: 0.9677 - val_loss: 1.1701 - val_acc: 0.8145\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 1s 969us/step - loss: 0.1472 - acc: 0.9650 - val_loss: 1.3013 - val_acc: 0.7903\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 1s 986us/step - loss: 0.2729 - acc: 0.9609 - val_loss: 0.9583 - val_acc: 0.8427\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2119 - acc: 0.9555 - val_loss: 0.9499 - val_acc: 0.8145\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 1s 974us/step - loss: 0.2406 - acc: 0.9555 - val_loss: 1.1151 - val_acc: 0.7903\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 1s 961us/step - loss: 0.2892 - acc: 0.9515 - val_loss: 0.6124 - val_acc: 0.8790\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1246 - acc: 0.9717 - val_loss: 1.0830 - val_acc: 0.8105\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 1s 984us/step - loss: 0.1494 - acc: 0.9704 - val_loss: 1.1643 - val_acc: 0.7863\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2997 - acc: 0.9515 - val_loss: 1.0368 - val_acc: 0.8306\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.1608 - acc: 0.9690 - val_loss: 1.0879 - val_acc: 0.8185\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 1s 932us/step - loss: 0.1429 - acc: 0.9677 - val_loss: 1.2073 - val_acc: 0.8065\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 1s 970us/step - loss: 0.2082 - acc: 0.9650 - val_loss: 1.5388 - val_acc: 0.7460\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.3789 - acc: 0.9488 - val_loss: 1.0238 - val_acc: 0.8226\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 1s 942us/step - loss: 0.1721 - acc: 0.9636 - val_loss: 0.8371 - val_acc: 0.8508\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 1s 951us/step - loss: 0.1587 - acc: 0.9744 - val_loss: 1.1879 - val_acc: 0.7984\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 1s 936us/step - loss: 0.2533 - acc: 0.9623 - val_loss: 0.9993 - val_acc: 0.8347\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 1s 966us/step - loss: 0.2252 - acc: 0.9650 - val_loss: 1.1632 - val_acc: 0.8266\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.2176 - acc: 0.9690 - val_loss: 0.9199 - val_acc: 0.8468\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 1s 943us/step - loss: 0.3897 - acc: 0.9542 - val_loss: 1.0212 - val_acc: 0.8145\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.2045 - acc: 0.9677 - val_loss: 1.0538 - val_acc: 0.8226\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 1s 993us/step - loss: 0.2313 - acc: 0.9582 - val_loss: 1.1188 - val_acc: 0.8266\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 1s 967us/step - loss: 0.2514 - acc: 0.9515 - val_loss: 0.9122 - val_acc: 0.8427\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 1s 971us/step - loss: 0.2433 - acc: 0.9623 - val_loss: 1.3765 - val_acc: 0.7944\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 1s 999us/step - loss: 0.2547 - acc: 0.9663 - val_loss: 1.0669 - val_acc: 0.8347\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 1s 880us/step - loss: 0.2370 - acc: 0.9663 - val_loss: 1.2921 - val_acc: 0.7823\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 1s 980us/step - loss: 0.3577 - acc: 0.9569 - val_loss: 0.8551 - val_acc: 0.8508\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 1s 948us/step - loss: 0.2289 - acc: 0.9650 - val_loss: 0.9697 - val_acc: 0.8105\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1855 - acc: 0.9609 - val_loss: 1.1827 - val_acc: 0.8105\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.2117 - acc: 0.9636 - val_loss: 1.1869 - val_acc: 0.7984\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 1s 947us/step - loss: 0.1783 - acc: 0.9623 - val_loss: 1.3526 - val_acc: 0.7903\n",
      "Epoch 474/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.3225 - acc: 0.9542 - val_loss: 1.5156 - val_acc: 0.7782\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.2034 - acc: 0.9704 - val_loss: 0.8169 - val_acc: 0.8266\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 1s 911us/step - loss: 0.2682 - acc: 0.9623 - val_loss: 1.4003 - val_acc: 0.7339\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2315 - acc: 0.9569 - val_loss: 0.7008 - val_acc: 0.8589\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.1776 - acc: 0.9663 - val_loss: 0.9374 - val_acc: 0.8145\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.1268 - acc: 0.9704 - val_loss: 1.1432 - val_acc: 0.7863\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.2233 - acc: 0.9596 - val_loss: 1.1385 - val_acc: 0.7944\n",
      "Epoch 481/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.1768 - acc: 0.9677 - val_loss: 0.7614 - val_acc: 0.8347\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2458 - acc: 0.9690 - val_loss: 0.9645 - val_acc: 0.8266\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 1s 850us/step - loss: 0.1989 - acc: 0.9636 - val_loss: 0.6943 - val_acc: 0.8589\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 1s 918us/step - loss: 0.2465 - acc: 0.9609 - val_loss: 0.7847 - val_acc: 0.8468\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1862 - acc: 0.9609 - val_loss: 1.1642 - val_acc: 0.7661\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 1s 896us/step - loss: 0.1766 - acc: 0.9650 - val_loss: 0.7731 - val_acc: 0.8750\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.3252 - acc: 0.9474 - val_loss: 0.6572 - val_acc: 0.8750\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2459 - acc: 0.9569 - val_loss: 0.6792 - val_acc: 0.8750\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2607 - acc: 0.9609 - val_loss: 0.9315 - val_acc: 0.8306\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 1s 888us/step - loss: 0.2763 - acc: 0.9582 - val_loss: 1.3098 - val_acc: 0.7903\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2466 - acc: 0.9677 - val_loss: 1.0316 - val_acc: 0.8347\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 1s 862us/step - loss: 0.1885 - acc: 0.9677 - val_loss: 0.9100 - val_acc: 0.8306\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 1s 882us/step - loss: 0.2704 - acc: 0.9515 - val_loss: 1.1026 - val_acc: 0.8347\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2777 - acc: 0.9650 - val_loss: 1.2257 - val_acc: 0.7782\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 1s 889us/step - loss: 0.3013 - acc: 0.9555 - val_loss: 0.8929 - val_acc: 0.8347\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.2565 - acc: 0.9461 - val_loss: 0.7709 - val_acc: 0.8347\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2559 - acc: 0.9609 - val_loss: 0.8403 - val_acc: 0.8548\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 1s 897us/step - loss: 0.1877 - acc: 0.9690 - val_loss: 1.2593 - val_acc: 0.7903\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3069 - acc: 0.9582 - val_loss: 1.3493 - val_acc: 0.8024\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.1997 - acc: 0.9582 - val_loss: 0.7166 - val_acc: 0.8468\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.1885 - acc: 0.9730 - val_loss: 1.1788 - val_acc: 0.8185\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2510 - acc: 0.9609 - val_loss: 0.9871 - val_acc: 0.8185\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.1944 - acc: 0.9650 - val_loss: 0.8351 - val_acc: 0.8629\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.1710 - acc: 0.9636 - val_loss: 1.6077 - val_acc: 0.7782\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2694 - acc: 0.9582 - val_loss: 1.0559 - val_acc: 0.7903\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2649 - acc: 0.9569 - val_loss: 1.4487 - val_acc: 0.7782\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.2527 - acc: 0.9609 - val_loss: 0.9606 - val_acc: 0.8226\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1888 - acc: 0.9650 - val_loss: 0.8865 - val_acc: 0.8065\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 1s 882us/step - loss: 0.2507 - acc: 0.9542 - val_loss: 0.9577 - val_acc: 0.8185\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.2856 - acc: 0.9461 - val_loss: 0.6006 - val_acc: 0.8669\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2490 - acc: 0.9582 - val_loss: 0.6993 - val_acc: 0.8629\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.3364 - acc: 0.9501 - val_loss: 0.6673 - val_acc: 0.8750\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2120 - acc: 0.9609 - val_loss: 0.9884 - val_acc: 0.8024\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2195 - acc: 0.9677 - val_loss: 0.7126 - val_acc: 0.8629\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 1s 880us/step - loss: 0.2517 - acc: 0.9663 - val_loss: 0.7232 - val_acc: 0.8387\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 1s 897us/step - loss: 0.1991 - acc: 0.9596 - val_loss: 0.9143 - val_acc: 0.8347\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2642 - acc: 0.9636 - val_loss: 0.9828 - val_acc: 0.8427\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.1848 - acc: 0.9636 - val_loss: 0.7039 - val_acc: 0.8669\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.1567 - acc: 0.9730 - val_loss: 1.0721 - val_acc: 0.8548\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3447 - acc: 0.9609 - val_loss: 1.5265 - val_acc: 0.7339\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.2686 - acc: 0.9515 - val_loss: 0.9892 - val_acc: 0.8427\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 1s 867us/step - loss: 0.2478 - acc: 0.9650 - val_loss: 1.0445 - val_acc: 0.8065\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.1652 - acc: 0.9650 - val_loss: 1.2989 - val_acc: 0.7702\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.2500 - acc: 0.9677 - val_loss: 1.1760 - val_acc: 0.8024\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3338 - acc: 0.9461 - val_loss: 0.8388 - val_acc: 0.8427\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2875 - acc: 0.9555 - val_loss: 1.5583 - val_acc: 0.7540\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.3916 - acc: 0.9569 - val_loss: 1.1717 - val_acc: 0.8226\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.2787 - acc: 0.9650 - val_loss: 1.2560 - val_acc: 0.8185\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2421 - acc: 0.9623 - val_loss: 0.7247 - val_acc: 0.8589\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.2745 - acc: 0.9636 - val_loss: 0.8362 - val_acc: 0.8750\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.3474 - acc: 0.9555 - val_loss: 1.0789 - val_acc: 0.8347\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2499 - acc: 0.9690 - val_loss: 0.9383 - val_acc: 0.8589\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 1s 927us/step - loss: 0.2932 - acc: 0.9596 - val_loss: 0.7933 - val_acc: 0.8387\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3313 - acc: 0.9555 - val_loss: 0.8017 - val_acc: 0.8750\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 877us/step - loss: 0.1517 - acc: 0.9717 - val_loss: 0.8276 - val_acc: 0.8911\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.3596 - acc: 0.9447 - val_loss: 0.7216 - val_acc: 0.8790\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2611 - acc: 0.9650 - val_loss: 0.8046 - val_acc: 0.8508\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 1s 868us/step - loss: 0.2407 - acc: 0.9555 - val_loss: 0.9102 - val_acc: 0.8548\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.3777 - acc: 0.9582 - val_loss: 1.6590 - val_acc: 0.7742\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2893 - acc: 0.9528 - val_loss: 0.8162 - val_acc: 0.8427\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.2535 - acc: 0.9609 - val_loss: 0.6061 - val_acc: 0.8710\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.1786 - acc: 0.9730 - val_loss: 1.1565 - val_acc: 0.8185\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.2598 - acc: 0.9663 - val_loss: 0.9523 - val_acc: 0.8387\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 1s 858us/step - loss: 0.2447 - acc: 0.9636 - val_loss: 0.8527 - val_acc: 0.8427\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.2822 - acc: 0.9582 - val_loss: 0.8010 - val_acc: 0.8790\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2373 - acc: 0.9636 - val_loss: 1.6002 - val_acc: 0.7944\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.3252 - acc: 0.9542 - val_loss: 0.9824 - val_acc: 0.8185\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 1s 897us/step - loss: 0.1680 - acc: 0.9730 - val_loss: 0.9046 - val_acc: 0.8266\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2965 - acc: 0.9596 - val_loss: 0.7089 - val_acc: 0.8468\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.2085 - acc: 0.9582 - val_loss: 0.5868 - val_acc: 0.8750\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 1s 867us/step - loss: 0.3031 - acc: 0.9609 - val_loss: 1.3197 - val_acc: 0.8065\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1846 - acc: 0.9677 - val_loss: 0.6910 - val_acc: 0.8629\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2314 - acc: 0.9744 - val_loss: 0.5319 - val_acc: 0.8831\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.2317 - acc: 0.9596 - val_loss: 0.8359 - val_acc: 0.8347\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2507 - acc: 0.9636 - val_loss: 0.5387 - val_acc: 0.8831\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.1479 - acc: 0.9717 - val_loss: 0.8982 - val_acc: 0.8427\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.1905 - acc: 0.9690 - val_loss: 0.9045 - val_acc: 0.8266\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2347 - acc: 0.9650 - val_loss: 0.7232 - val_acc: 0.8508\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.2190 - acc: 0.9744 - val_loss: 0.7597 - val_acc: 0.8589\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.3081 - acc: 0.9569 - val_loss: 0.8820 - val_acc: 0.8427\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1961 - acc: 0.9771 - val_loss: 1.2935 - val_acc: 0.8065\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 1s 850us/step - loss: 0.2263 - acc: 0.9596 - val_loss: 1.0986 - val_acc: 0.8266\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3827 - acc: 0.9569 - val_loss: 0.8506 - val_acc: 0.8226\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 1s 880us/step - loss: 0.3452 - acc: 0.9609 - val_loss: 0.5119 - val_acc: 0.8790\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.2124 - acc: 0.9690 - val_loss: 0.9047 - val_acc: 0.8508\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3024 - acc: 0.9555 - val_loss: 0.7214 - val_acc: 0.8548\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.3592 - acc: 0.9609 - val_loss: 0.6551 - val_acc: 0.8750\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.2435 - acc: 0.9636 - val_loss: 1.1308 - val_acc: 0.8468\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3194 - acc: 0.9596 - val_loss: 0.8599 - val_acc: 0.8427\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2561 - acc: 0.9650 - val_loss: 0.8731 - val_acc: 0.8548\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.2270 - acc: 0.9623 - val_loss: 0.8669 - val_acc: 0.8548\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4046 - acc: 0.9515 - val_loss: 0.9424 - val_acc: 0.8468\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.4081 - acc: 0.9569 - val_loss: 1.0562 - val_acc: 0.8266\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 1s 856us/step - loss: 0.2465 - acc: 0.9663 - val_loss: 0.8856 - val_acc: 0.8306\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3148 - acc: 0.9542 - val_loss: 0.5646 - val_acc: 0.8710\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.2742 - acc: 0.9650 - val_loss: 0.8972 - val_acc: 0.8226\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.3422 - acc: 0.9623 - val_loss: 0.8001 - val_acc: 0.8347\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2718 - acc: 0.9528 - val_loss: 0.6392 - val_acc: 0.8669\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 1s 903us/step - loss: 0.3261 - acc: 0.9596 - val_loss: 1.0258 - val_acc: 0.8266\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.2694 - acc: 0.9623 - val_loss: 1.4301 - val_acc: 0.7460\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.2299 - acc: 0.9609 - val_loss: 0.6939 - val_acc: 0.8669\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.2542 - acc: 0.9650 - val_loss: 0.5784 - val_acc: 0.8871\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.2308 - acc: 0.9690 - val_loss: 1.3403 - val_acc: 0.7863\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3430 - acc: 0.9474 - val_loss: 0.6473 - val_acc: 0.8387\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.1321 - acc: 0.9717 - val_loss: 1.0088 - val_acc: 0.8589\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 1s 862us/step - loss: 0.2466 - acc: 0.9650 - val_loss: 0.7854 - val_acc: 0.8427\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2210 - acc: 0.9650 - val_loss: 0.8410 - val_acc: 0.8468\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.3147 - acc: 0.9528 - val_loss: 0.8111 - val_acc: 0.8508\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3709 - acc: 0.9515 - val_loss: 0.7713 - val_acc: 0.8468\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2629 - acc: 0.9596 - val_loss: 0.9493 - val_acc: 0.8306\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.1535 - acc: 0.9730 - val_loss: 0.7051 - val_acc: 0.8387\n",
      "Epoch 592/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2814 - acc: 0.9569 - val_loss: 0.9616 - val_acc: 0.8548\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 1s 854us/step - loss: 0.3443 - acc: 0.9650 - val_loss: 1.0011 - val_acc: 0.8589\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.1669 - acc: 0.9757 - val_loss: 0.6024 - val_acc: 0.8790\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 1s 907us/step - loss: 0.1622 - acc: 0.9757 - val_loss: 0.9622 - val_acc: 0.8629\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.1875 - acc: 0.9690 - val_loss: 0.8471 - val_acc: 0.8589\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3399 - acc: 0.9596 - val_loss: 0.9889 - val_acc: 0.8710\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3073 - acc: 0.9650 - val_loss: 0.5488 - val_acc: 0.8790\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.3237 - acc: 0.9636 - val_loss: 0.8386 - val_acc: 0.8508\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 1s 839us/step - loss: 0.3654 - acc: 0.9555 - val_loss: 0.9950 - val_acc: 0.8347\n",
      "Epoch 601/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2613 - acc: 0.9569 - val_loss: 0.8338 - val_acc: 0.8669\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.1734 - acc: 0.9784 - val_loss: 1.0449 - val_acc: 0.8589\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.2038 - acc: 0.9730 - val_loss: 0.8670 - val_acc: 0.8629\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2828 - acc: 0.9690 - val_loss: 0.7442 - val_acc: 0.8589\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2855 - acc: 0.9663 - val_loss: 1.1889 - val_acc: 0.7782\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.3121 - acc: 0.9582 - val_loss: 1.7271 - val_acc: 0.7661\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2220 - acc: 0.9717 - val_loss: 0.9570 - val_acc: 0.8468\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 1s 856us/step - loss: 0.3848 - acc: 0.9555 - val_loss: 0.9843 - val_acc: 0.8387\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.2511 - acc: 0.9663 - val_loss: 0.8591 - val_acc: 0.8589\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1714 - acc: 0.9771 - val_loss: 0.8778 - val_acc: 0.8548\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.2810 - acc: 0.9596 - val_loss: 0.6956 - val_acc: 0.8589\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.1906 - acc: 0.9717 - val_loss: 0.7502 - val_acc: 0.8548\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2905 - acc: 0.9636 - val_loss: 0.9235 - val_acc: 0.8427\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.2069 - acc: 0.9704 - val_loss: 0.8270 - val_acc: 0.8710\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.3054 - acc: 0.9663 - val_loss: 1.0297 - val_acc: 0.8266\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3266 - acc: 0.9515 - val_loss: 1.0766 - val_acc: 0.8105\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3398 - acc: 0.9569 - val_loss: 0.9302 - val_acc: 0.8306\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3903 - acc: 0.9596 - val_loss: 1.0975 - val_acc: 0.8589\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 1s 859us/step - loss: 0.1948 - acc: 0.9730 - val_loss: 1.2858 - val_acc: 0.8105\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.3276 - acc: 0.9623 - val_loss: 0.9405 - val_acc: 0.8508\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.2614 - acc: 0.9636 - val_loss: 1.0766 - val_acc: 0.8387\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.3606 - acc: 0.9528 - val_loss: 1.0974 - val_acc: 0.7782\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.2814 - acc: 0.9515 - val_loss: 0.7521 - val_acc: 0.8266\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2993 - acc: 0.9650 - val_loss: 0.8245 - val_acc: 0.8347\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.1622 - acc: 0.9650 - val_loss: 0.6407 - val_acc: 0.8750\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 1s 921us/step - loss: 0.2767 - acc: 0.9555 - val_loss: 1.0916 - val_acc: 0.8347\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2818 - acc: 0.9582 - val_loss: 0.7577 - val_acc: 0.8589\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 1s 899us/step - loss: 0.2548 - acc: 0.9690 - val_loss: 0.8213 - val_acc: 0.8589\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 1s 870us/step - loss: 0.3071 - acc: 0.9555 - val_loss: 1.0380 - val_acc: 0.8468\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.3855 - acc: 0.9555 - val_loss: 0.8814 - val_acc: 0.8710\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2788 - acc: 0.9663 - val_loss: 0.9641 - val_acc: 0.8589\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 1s 885us/step - loss: 0.3332 - acc: 0.9555 - val_loss: 1.1063 - val_acc: 0.8427\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 1s 948us/step - loss: 0.2757 - acc: 0.9690 - val_loss: 0.9348 - val_acc: 0.8790\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3378 - acc: 0.9569 - val_loss: 1.1412 - val_acc: 0.8065\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.2378 - acc: 0.9636 - val_loss: 0.9763 - val_acc: 0.8266\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.1875 - acc: 0.9730 - val_loss: 1.0556 - val_acc: 0.8468\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.4019 - acc: 0.9542 - val_loss: 0.6972 - val_acc: 0.8831\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 1s 851us/step - loss: 0.1960 - acc: 0.9784 - val_loss: 0.8876 - val_acc: 0.8185\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2746 - acc: 0.9690 - val_loss: 0.7745 - val_acc: 0.8226\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.2283 - acc: 0.9677 - val_loss: 1.0151 - val_acc: 0.8145\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 1s 855us/step - loss: 0.2595 - acc: 0.9663 - val_loss: 0.8922 - val_acc: 0.8266\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3310 - acc: 0.9609 - val_loss: 0.7943 - val_acc: 0.8669\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 1s 859us/step - loss: 0.2961 - acc: 0.9690 - val_loss: 0.9107 - val_acc: 0.8508\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.3362 - acc: 0.9623 - val_loss: 0.8140 - val_acc: 0.8790\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2602 - acc: 0.9663 - val_loss: 0.9895 - val_acc: 0.8548\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.2831 - acc: 0.9636 - val_loss: 1.0288 - val_acc: 0.8105\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.3021 - acc: 0.9569 - val_loss: 1.1966 - val_acc: 0.7984\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.4186 - acc: 0.9474 - val_loss: 0.8549 - val_acc: 0.7984\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.2154 - acc: 0.9677 - val_loss: 0.7446 - val_acc: 0.8468\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 1s 942us/step - loss: 0.3286 - acc: 0.9636 - val_loss: 0.8947 - val_acc: 0.8145\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2725 - acc: 0.9636 - val_loss: 0.9127 - val_acc: 0.8548\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 1s 910us/step - loss: 0.4129 - acc: 0.9515 - val_loss: 0.9934 - val_acc: 0.8185\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 847us/step - loss: 0.3373 - acc: 0.9596 - val_loss: 1.0222 - val_acc: 0.7903\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.3495 - acc: 0.9596 - val_loss: 1.1795 - val_acc: 0.7984\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.5315 - acc: 0.9394 - val_loss: 0.8958 - val_acc: 0.8185\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.2896 - acc: 0.9582 - val_loss: 0.8381 - val_acc: 0.8629\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.1950 - acc: 0.9744 - val_loss: 0.9577 - val_acc: 0.8145\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.3655 - acc: 0.9501 - val_loss: 0.8240 - val_acc: 0.8347\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.2869 - acc: 0.9704 - val_loss: 0.9086 - val_acc: 0.8629\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2163 - acc: 0.9663 - val_loss: 0.5468 - val_acc: 0.8831\n",
      "Epoch 661/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.2451 - acc: 0.9677 - val_loss: 0.9047 - val_acc: 0.8024\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2183 - acc: 0.9771 - val_loss: 0.7052 - val_acc: 0.8790\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.4262 - acc: 0.9501 - val_loss: 1.3511 - val_acc: 0.7742\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.2188 - acc: 0.9650 - val_loss: 1.0739 - val_acc: 0.8185\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2663 - acc: 0.9663 - val_loss: 1.1702 - val_acc: 0.8065\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.1982 - acc: 0.9663 - val_loss: 0.9411 - val_acc: 0.8226\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 1s 883us/step - loss: 0.2860 - acc: 0.9730 - val_loss: 1.1065 - val_acc: 0.8427\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.1744 - acc: 0.9757 - val_loss: 0.9661 - val_acc: 0.8589\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 1s 856us/step - loss: 0.3189 - acc: 0.9623 - val_loss: 0.9508 - val_acc: 0.8427\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 1s 913us/step - loss: 0.3774 - acc: 0.9488 - val_loss: 1.2262 - val_acc: 0.7984\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4240 - acc: 0.9474 - val_loss: 1.0246 - val_acc: 0.8387\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.3126 - acc: 0.9582 - val_loss: 0.9556 - val_acc: 0.8387\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.4067 - acc: 0.9528 - val_loss: 0.8242 - val_acc: 0.8548\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.1776 - acc: 0.9730 - val_loss: 1.0808 - val_acc: 0.8306\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.2539 - acc: 0.9704 - val_loss: 0.8319 - val_acc: 0.8589\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 1s 925us/step - loss: 0.3591 - acc: 0.9596 - val_loss: 0.7631 - val_acc: 0.8750\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.2775 - acc: 0.9582 - val_loss: 0.9278 - val_acc: 0.8306\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 1s 945us/step - loss: 0.2288 - acc: 0.9704 - val_loss: 1.0372 - val_acc: 0.7863\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.2248 - acc: 0.9663 - val_loss: 0.6250 - val_acc: 0.8790\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.2650 - acc: 0.9623 - val_loss: 0.6677 - val_acc: 0.8629\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.1949 - acc: 0.9690 - val_loss: 0.8954 - val_acc: 0.8226\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1916 - acc: 0.9811 - val_loss: 1.1676 - val_acc: 0.8347\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2945 - acc: 0.9677 - val_loss: 1.1784 - val_acc: 0.8024\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2920 - acc: 0.9636 - val_loss: 0.9353 - val_acc: 0.8427\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 0.2566 - acc: 0.9650 - val_loss: 1.0817 - val_acc: 0.8226\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3313 - acc: 0.9677 - val_loss: 0.9356 - val_acc: 0.8508\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.4647 - acc: 0.9542 - val_loss: 0.9049 - val_acc: 0.8145\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 1s 855us/step - loss: 0.2883 - acc: 0.9542 - val_loss: 0.9813 - val_acc: 0.7984\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3936 - acc: 0.9353 - val_loss: 0.8162 - val_acc: 0.8548\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.3294 - acc: 0.9569 - val_loss: 0.9474 - val_acc: 0.8266\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 1s 913us/step - loss: 0.2255 - acc: 0.9757 - val_loss: 0.9302 - val_acc: 0.8427\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.3484 - acc: 0.963 - 1s 905us/step - loss: 0.3366 - acc: 0.9623 - val_loss: 1.5168 - val_acc: 0.7621\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 1s 945us/step - loss: 0.2704 - acc: 0.9690 - val_loss: 0.6386 - val_acc: 0.8710\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 1s 959us/step - loss: 0.4167 - acc: 0.9555 - val_loss: 1.1802 - val_acc: 0.8347\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 1s 972us/step - loss: 0.3757 - acc: 0.9623 - val_loss: 1.1117 - val_acc: 0.8266\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3398 - acc: 0.9677 - val_loss: 1.2817 - val_acc: 0.8145\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.3227 - acc: 0.9677 - val_loss: 0.9585 - val_acc: 0.8306\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.2755 - acc: 0.9704 - val_loss: 0.8163 - val_acc: 0.8710\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1969 - acc: 0.9663 - val_loss: 0.9739 - val_acc: 0.8508\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 0.1798 - acc: 0.9757 - val_loss: 1.3008 - val_acc: 0.8266\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 1s 989us/step - loss: 0.2932 - acc: 0.9704 - val_loss: 1.2994 - val_acc: 0.8306\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 1s 918us/step - loss: 0.2676 - acc: 0.9717 - val_loss: 1.1543 - val_acc: 0.8387\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2709 - acc: 0.9690 - val_loss: 1.0629 - val_acc: 0.8548\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 1s 889us/step - loss: 0.3237 - acc: 0.9650 - val_loss: 0.9562 - val_acc: 0.8548\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 1s 897us/step - loss: 0.4289 - acc: 0.9528 - val_loss: 1.5598 - val_acc: 0.8065\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4473 - acc: 0.9542 - val_loss: 1.2559 - val_acc: 0.8306\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.1811 - acc: 0.9704 - val_loss: 1.1427 - val_acc: 0.8226\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 1s 868us/step - loss: 0.3621 - acc: 0.9609 - val_loss: 1.0764 - val_acc: 0.8185\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3121 - acc: 0.9582 - val_loss: 0.8925 - val_acc: 0.8589\n",
      "Epoch 710/1000\n",
      "742/742 [==============================] - 1s 877us/step - loss: 0.2335 - acc: 0.9609 - val_loss: 0.7529 - val_acc: 0.8468\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.2892 - acc: 0.9677 - val_loss: 0.7313 - val_acc: 0.8750\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.1886 - acc: 0.9811 - val_loss: 0.7763 - val_acc: 0.8710\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 1s 858us/step - loss: 0.4160 - acc: 0.9569 - val_loss: 0.9281 - val_acc: 0.8508\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.3930 - acc: 0.9488 - val_loss: 0.8860 - val_acc: 0.8266\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4337 - acc: 0.9461 - val_loss: 0.9005 - val_acc: 0.8266\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.2646 - acc: 0.9663 - val_loss: 0.9806 - val_acc: 0.8145\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.2759 - acc: 0.9609 - val_loss: 0.7122 - val_acc: 0.8589\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2534 - acc: 0.9771 - val_loss: 0.6461 - val_acc: 0.8871\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3197 - acc: 0.9663 - val_loss: 1.1005 - val_acc: 0.8387\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2455 - acc: 0.9757 - val_loss: 1.1081 - val_acc: 0.8347\n",
      "Epoch 721/1000\n",
      "742/742 [==============================] - 1s 868us/step - loss: 0.0863 - acc: 0.9825 - val_loss: 1.0997 - val_acc: 0.8306\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.3171 - acc: 0.9582 - val_loss: 1.1284 - val_acc: 0.8347\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3374 - acc: 0.9623 - val_loss: 1.1403 - val_acc: 0.8629\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.2802 - acc: 0.9677 - val_loss: 0.9687 - val_acc: 0.8911\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.3484 - acc: 0.9596 - val_loss: 0.8637 - val_acc: 0.8710\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2879 - acc: 0.9704 - val_loss: 0.8681 - val_acc: 0.8831\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.3418 - acc: 0.9623 - val_loss: 0.8339 - val_acc: 0.8629\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 1s 857us/step - loss: 0.2743 - acc: 0.9650 - val_loss: 0.8299 - val_acc: 0.8750\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2594 - acc: 0.9650 - val_loss: 1.0291 - val_acc: 0.8427\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.2863 - acc: 0.9717 - val_loss: 1.0242 - val_acc: 0.8589\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 0.3689 - acc: 0.9582 - val_loss: 1.3044 - val_acc: 0.8669\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.1667 - acc: 0.9757 - val_loss: 1.1180 - val_acc: 0.8589\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.2600 - acc: 0.9690 - val_loss: 0.9691 - val_acc: 0.8427\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2759 - acc: 0.9744 - val_loss: 1.1691 - val_acc: 0.8226\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 1s 865us/step - loss: 0.2519 - acc: 0.9704 - val_loss: 1.6194 - val_acc: 0.7863\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.4598 - acc: 0.9528 - val_loss: 1.4354 - val_acc: 0.7702\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2914 - acc: 0.9677 - val_loss: 2.8537 - val_acc: 0.6895\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.5688 - acc: 0.9515 - val_loss: 1.2222 - val_acc: 0.8468\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.4511 - acc: 0.9542 - val_loss: 0.8071 - val_acc: 0.8750\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3482 - acc: 0.9609 - val_loss: 0.5972 - val_acc: 0.8750\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 1s 924us/step - loss: 0.4300 - acc: 0.9609 - val_loss: 1.3015 - val_acc: 0.8145\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.2526 - acc: 0.9704 - val_loss: 0.9388 - val_acc: 0.8185\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2111 - acc: 0.9704 - val_loss: 1.3083 - val_acc: 0.8185\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 1s 891us/step - loss: 0.4855 - acc: 0.9461 - val_loss: 0.7684 - val_acc: 0.8548\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.3363 - acc: 0.9677 - val_loss: 1.2511 - val_acc: 0.8024\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2571 - acc: 0.9717 - val_loss: 1.2120 - val_acc: 0.8347\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4328 - acc: 0.9542 - val_loss: 1.1826 - val_acc: 0.8185\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 1s 868us/step - loss: 0.3724 - acc: 0.9501 - val_loss: 0.8560 - val_acc: 0.8669\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.3233 - acc: 0.9677 - val_loss: 0.5956 - val_acc: 0.8952\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.2480 - acc: 0.9704 - val_loss: 1.0022 - val_acc: 0.8306\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 1s 920us/step - loss: 0.2738 - acc: 0.9757 - val_loss: 0.7505 - val_acc: 0.9032\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4733 - acc: 0.9596 - val_loss: 0.7546 - val_acc: 0.8831\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 1s 914us/step - loss: 0.3824 - acc: 0.9528 - val_loss: 0.9763 - val_acc: 0.8427\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.3300 - acc: 0.9677 - val_loss: 1.1236 - val_acc: 0.8508\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3363 - acc: 0.9663 - val_loss: 1.2108 - val_acc: 0.8710\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 1s 855us/step - loss: 0.2907 - acc: 0.9730 - val_loss: 0.7273 - val_acc: 0.8871\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 1s 912us/step - loss: 0.4639 - acc: 0.9596 - val_loss: 1.3993 - val_acc: 0.8306\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5547 - acc: 0.9515 - val_loss: 1.1645 - val_acc: 0.8508\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 1s 882us/step - loss: 0.3991 - acc: 0.9663 - val_loss: 1.1726 - val_acc: 0.8427\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 1s 870us/step - loss: 0.4868 - acc: 0.9528 - val_loss: 1.5057 - val_acc: 0.8105\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 1s 887us/step - loss: 0.3812 - acc: 0.9650 - val_loss: 0.9426 - val_acc: 0.8750\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.3661 - acc: 0.9636 - val_loss: 0.7026 - val_acc: 0.9032\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3897 - acc: 0.9582 - val_loss: 1.1389 - val_acc: 0.8306\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.3927 - acc: 0.9515 - val_loss: 1.0900 - val_acc: 0.8024\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 1s 917us/step - loss: 0.2963 - acc: 0.9677 - val_loss: 0.7343 - val_acc: 0.8871\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2128 - acc: 0.9717 - val_loss: 1.3328 - val_acc: 0.7903\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.2532 - acc: 0.9704 - val_loss: 0.7686 - val_acc: 0.8589\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 1s 887us/step - loss: 0.3430 - acc: 0.9623 - val_loss: 1.2849 - val_acc: 0.8105\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.1998 - acc: 0.9677 - val_loss: 1.2204 - val_acc: 0.8468\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.3617 - acc: 0.9636 - val_loss: 0.8384 - val_acc: 0.8347\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 896us/step - loss: 0.2660 - acc: 0.9677 - val_loss: 1.2089 - val_acc: 0.8266\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3085 - acc: 0.9636 - val_loss: 1.0602 - val_acc: 0.8548\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3705 - acc: 0.9596 - val_loss: 1.4556 - val_acc: 0.8226\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 1s 882us/step - loss: 0.3756 - acc: 0.9596 - val_loss: 0.7729 - val_acc: 0.8589\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4421 - acc: 0.9528 - val_loss: 1.0358 - val_acc: 0.8427\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 1s 854us/step - loss: 0.4242 - acc: 0.9596 - val_loss: 0.8419 - val_acc: 0.8468\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 1s 840us/step - loss: 0.4116 - acc: 0.9623 - val_loss: 0.8631 - val_acc: 0.8790\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.2206 - acc: 0.9784 - val_loss: 1.2241 - val_acc: 0.8347\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.3923 - acc: 0.9582 - val_loss: 1.3815 - val_acc: 0.7944\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.4449 - acc: 0.9488 - val_loss: 0.8325 - val_acc: 0.8629\n",
      "Epoch 781/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3111 - acc: 0.9650 - val_loss: 0.8622 - val_acc: 0.8548\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.3846 - acc: 0.9582 - val_loss: 0.9192 - val_acc: 0.8226\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.3947 - acc: 0.9596 - val_loss: 0.5927 - val_acc: 0.8871\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.4146 - acc: 0.9569 - val_loss: 0.8134 - val_acc: 0.8589\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 1s 851us/step - loss: 0.2238 - acc: 0.9771 - val_loss: 0.7731 - val_acc: 0.8589\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.5051 - acc: 0.9555 - val_loss: 1.0145 - val_acc: 0.8347\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3699 - acc: 0.9650 - val_loss: 1.1516 - val_acc: 0.8226\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.3472 - acc: 0.9663 - val_loss: 1.0647 - val_acc: 0.8226\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 1s 850us/step - loss: 0.3832 - acc: 0.9636 - val_loss: 1.0750 - val_acc: 0.8669\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 1s 908us/step - loss: 0.3980 - acc: 0.9650 - val_loss: 1.0956 - val_acc: 0.8629\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.4749 - acc: 0.9542 - val_loss: 1.1085 - val_acc: 0.8589\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4559 - acc: 0.9636 - val_loss: 1.6073 - val_acc: 0.7944\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 1s 870us/step - loss: 0.4298 - acc: 0.9650 - val_loss: 1.5141 - val_acc: 0.7742\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.4314 - acc: 0.9528 - val_loss: 1.3832 - val_acc: 0.8347\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.4421 - acc: 0.9555 - val_loss: 1.1662 - val_acc: 0.8427\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.5297 - acc: 0.9474 - val_loss: 0.9452 - val_acc: 0.8387\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.3385 - acc: 0.9690 - val_loss: 1.1320 - val_acc: 0.8226\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3976 - acc: 0.9542 - val_loss: 1.0652 - val_acc: 0.8347\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 1s 900us/step - loss: 0.4288 - acc: 0.9542 - val_loss: 1.1747 - val_acc: 0.8065\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 1s 846us/step - loss: 0.3564 - acc: 0.9515 - val_loss: 0.9042 - val_acc: 0.8629\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3497 - acc: 0.9663 - val_loss: 1.4947 - val_acc: 0.8024\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.2704 - acc: 0.9663 - val_loss: 1.5490 - val_acc: 0.7944\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 1s 901us/step - loss: 0.5241 - acc: 0.9501 - val_loss: 0.8028 - val_acc: 0.8952\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4718 - acc: 0.9542 - val_loss: 1.2190 - val_acc: 0.8508\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 1s 911us/step - loss: 0.3146 - acc: 0.9717 - val_loss: 1.2560 - val_acc: 0.8629\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 1s 854us/step - loss: 0.2675 - acc: 0.9730 - val_loss: 1.3792 - val_acc: 0.8508\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3573 - acc: 0.9636 - val_loss: 1.0424 - val_acc: 0.8468\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 1s 860us/step - loss: 0.3234 - acc: 0.9677 - val_loss: 0.7385 - val_acc: 0.8710\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.1844 - acc: 0.9730 - val_loss: 0.9481 - val_acc: 0.8589\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.2332 - acc: 0.9744 - val_loss: 0.8506 - val_acc: 0.9032\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.3184 - acc: 0.9663 - val_loss: 1.0741 - val_acc: 0.8669\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 1s 880us/step - loss: 0.6723 - acc: 0.9447 - val_loss: 0.9635 - val_acc: 0.8952\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3544 - acc: 0.9690 - val_loss: 0.7322 - val_acc: 0.8831\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.5409 - acc: 0.9569 - val_loss: 0.8208 - val_acc: 0.8992\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.4614 - acc: 0.9596 - val_loss: 0.9308 - val_acc: 0.8911\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4216 - acc: 0.9636 - val_loss: 0.9325 - val_acc: 0.8952\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.4942 - acc: 0.9542 - val_loss: 1.1964 - val_acc: 0.8710\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.4714 - acc: 0.9650 - val_loss: 0.9817 - val_acc: 0.8952\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 0.5318 - acc: 0.9582 - val_loss: 1.2325 - val_acc: 0.8790\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 1s 862us/step - loss: 0.4197 - acc: 0.9623 - val_loss: 1.6036 - val_acc: 0.7944\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3453 - acc: 0.9663 - val_loss: 1.1680 - val_acc: 0.8790\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.4630 - acc: 0.9609 - val_loss: 2.0217 - val_acc: 0.7903\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.4596 - acc: 0.9582 - val_loss: 0.9444 - val_acc: 0.9032\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.3934 - acc: 0.9663 - val_loss: 0.9377 - val_acc: 0.9032\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.7210 - acc: 0.9420 - val_loss: 1.1835 - val_acc: 0.8911\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 1s 859us/step - loss: 0.4178 - acc: 0.9569 - val_loss: 1.0624 - val_acc: 0.8911\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.6458 - acc: 0.9474 - val_loss: 1.4686 - val_acc: 0.8266\n",
      "Epoch 828/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.4053 - acc: 0.9596 - val_loss: 0.8741 - val_acc: 0.8750\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.5034 - acc: 0.9582 - val_loss: 0.8654 - val_acc: 0.9113\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.3787 - acc: 0.9704 - val_loss: 0.9268 - val_acc: 0.8831\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.5774 - acc: 0.9461 - val_loss: 0.9553 - val_acc: 0.8669\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.3925 - acc: 0.9636 - val_loss: 1.0856 - val_acc: 0.8589\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4842 - acc: 0.9582 - val_loss: 0.8999 - val_acc: 0.8831\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.5299 - acc: 0.9501 - val_loss: 1.4166 - val_acc: 0.8669\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 1s 857us/step - loss: 0.4661 - acc: 0.9596 - val_loss: 0.9828 - val_acc: 0.8871\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.4436 - acc: 0.9596 - val_loss: 1.5667 - val_acc: 0.8669\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.5989 - acc: 0.9555 - val_loss: 1.3131 - val_acc: 0.8669\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.3789 - acc: 0.9636 - val_loss: 1.3356 - val_acc: 0.8548\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4351 - acc: 0.9555 - val_loss: 0.9000 - val_acc: 0.8871\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3978 - acc: 0.9677 - val_loss: 0.8930 - val_acc: 0.8911\n",
      "Epoch 841/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.5487 - acc: 0.9501 - val_loss: 0.6941 - val_acc: 0.8911\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.1799 - acc: 0.9784 - val_loss: 0.8650 - val_acc: 0.8790\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 1s 915us/step - loss: 0.2658 - acc: 0.9744 - val_loss: 0.9484 - val_acc: 0.8831\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 1s 859us/step - loss: 0.3704 - acc: 0.9596 - val_loss: 0.9020 - val_acc: 0.8831\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 1s 836us/step - loss: 0.2244 - acc: 0.9730 - val_loss: 1.1596 - val_acc: 0.8629\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.5681 - acc: 0.9501 - val_loss: 1.6064 - val_acc: 0.8226\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5576 - acc: 0.9447 - val_loss: 1.2006 - val_acc: 0.8427\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.2534 - acc: 0.9730 - val_loss: 0.9931 - val_acc: 0.8952\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.3828 - acc: 0.9690 - val_loss: 0.9767 - val_acc: 0.8710\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.4028 - acc: 0.9569 - val_loss: 1.2701 - val_acc: 0.8669\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 1s 837us/step - loss: 0.3670 - acc: 0.9636 - val_loss: 0.9921 - val_acc: 0.8669\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 1s 896us/step - loss: 0.5146 - acc: 0.9596 - val_loss: 1.4372 - val_acc: 0.8387\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4400 - acc: 0.9650 - val_loss: 1.6339 - val_acc: 0.8347\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 1s 866us/step - loss: 0.6187 - acc: 0.9501 - val_loss: 2.0221 - val_acc: 0.8145\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 1s 886us/step - loss: 0.5471 - acc: 0.9582 - val_loss: 1.1486 - val_acc: 0.8911\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.5663 - acc: 0.9501 - val_loss: 1.4900 - val_acc: 0.8387\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 1s 906us/step - loss: 0.4348 - acc: 0.9677 - val_loss: 1.4283 - val_acc: 0.8508\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3275 - acc: 0.9730 - val_loss: 1.4670 - val_acc: 0.8589\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3174 - acc: 0.9690 - val_loss: 1.3353 - val_acc: 0.8548\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.5318 - acc: 0.9569 - val_loss: 1.3913 - val_acc: 0.8669\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 1s 916us/step - loss: 0.3836 - acc: 0.9677 - val_loss: 1.2717 - val_acc: 0.8790\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4499 - acc: 0.9636 - val_loss: 1.3591 - val_acc: 0.8669\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.5105 - acc: 0.9623 - val_loss: 2.2770 - val_acc: 0.8024\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.7864 - acc: 0.9420 - val_loss: 1.7671 - val_acc: 0.8306\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.6930 - acc: 0.9474 - val_loss: 1.3129 - val_acc: 0.8750\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.6092 - acc: 0.9515 - val_loss: 1.3788 - val_acc: 0.8750\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4669 - acc: 0.9569 - val_loss: 1.6726 - val_acc: 0.8347\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.5779 - acc: 0.9501 - val_loss: 1.1158 - val_acc: 0.8750\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.3540 - acc: 0.9704 - val_loss: 1.0654 - val_acc: 0.8548\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4191 - acc: 0.9663 - val_loss: 1.0640 - val_acc: 0.8629\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 1s 889us/step - loss: 0.3510 - acc: 0.9704 - val_loss: 1.1874 - val_acc: 0.8831\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 1s 843us/step - loss: 0.3414 - acc: 0.9690 - val_loss: 0.8688 - val_acc: 0.8548\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5097 - acc: 0.9528 - val_loss: 1.2802 - val_acc: 0.8548\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 1s 911us/step - loss: 0.4768 - acc: 0.9609 - val_loss: 1.2486 - val_acc: 0.8669\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 1s 868us/step - loss: 0.2208 - acc: 0.9730 - val_loss: 1.3274 - val_acc: 0.8710\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.5106 - acc: 0.9609 - val_loss: 1.3472 - val_acc: 0.8669\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.5186 - acc: 0.9542 - val_loss: 1.1510 - val_acc: 0.8831\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3446 - acc: 0.9717 - val_loss: 1.4413 - val_acc: 0.8589\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3792 - acc: 0.9677 - val_loss: 1.1835 - val_acc: 0.8750\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.4411 - acc: 0.9596 - val_loss: 1.1834 - val_acc: 0.8831\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.3887 - acc: 0.9663 - val_loss: 1.2443 - val_acc: 0.8750\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.5144 - acc: 0.9636 - val_loss: 1.1841 - val_acc: 0.8508\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.4660 - acc: 0.9582 - val_loss: 1.4871 - val_acc: 0.8589\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.5946 - acc: 0.9488 - val_loss: 1.5313 - val_acc: 0.8750\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 1s 850us/step - loss: 0.3609 - acc: 0.9690 - val_loss: 1.2791 - val_acc: 0.8750\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 1s 858us/step - loss: 0.3119 - acc: 0.9744 - val_loss: 1.3371 - val_acc: 0.8831\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.2701 - acc: 0.9757 - val_loss: 1.7400 - val_acc: 0.8347\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 1s 860us/step - loss: 0.4171 - acc: 0.9663 - val_loss: 1.4024 - val_acc: 0.8871\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 1s 881us/step - loss: 0.4508 - acc: 0.9623 - val_loss: 1.6721 - val_acc: 0.8669\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.6535 - acc: 0.9461 - val_loss: 1.3675 - val_acc: 0.8750\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 1s 870us/step - loss: 0.4066 - acc: 0.9650 - val_loss: 1.2536 - val_acc: 0.8871\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.4678 - acc: 0.9582 - val_loss: 1.3952 - val_acc: 0.8710\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3446 - acc: 0.9717 - val_loss: 1.2336 - val_acc: 0.8669\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.2603 - acc: 0.9744 - val_loss: 1.1388 - val_acc: 0.8831\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.3828 - acc: 0.9677 - val_loss: 1.9407 - val_acc: 0.8347\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3433 - acc: 0.9704 - val_loss: 1.4195 - val_acc: 0.8427\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 1s 869us/step - loss: 0.3796 - acc: 0.9690 - val_loss: 1.4961 - val_acc: 0.8589\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 1s 844us/step - loss: 0.4925 - acc: 0.9569 - val_loss: 1.7673 - val_acc: 0.8548\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.2367 - acc: 0.9771 - val_loss: 1.4109 - val_acc: 0.8669\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 0.3201 - acc: 0.9771 - val_loss: 1.3420 - val_acc: 0.8669\n",
      "Epoch 901/1000\n",
      "742/742 [==============================] - 1s 919us/step - loss: 0.7950 - acc: 0.9380 - val_loss: 1.4159 - val_acc: 0.8710\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4009 - acc: 0.9690 - val_loss: 1.0824 - val_acc: 0.8911\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.2959 - acc: 0.9757 - val_loss: 1.1964 - val_acc: 0.9032\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 1s 890us/step - loss: 0.5723 - acc: 0.9596 - val_loss: 0.8658 - val_acc: 0.9113\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3155 - acc: 0.9784 - val_loss: 1.2836 - val_acc: 0.8911\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.4978 - acc: 0.9623 - val_loss: 1.2416 - val_acc: 0.8871\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.5599 - acc: 0.9582 - val_loss: 1.2045 - val_acc: 0.8871\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.6186 - acc: 0.9528 - val_loss: 1.2117 - val_acc: 0.8790\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.3983 - acc: 0.9623 - val_loss: 1.3613 - val_acc: 0.8790\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3366 - acc: 0.9677 - val_loss: 1.3912 - val_acc: 0.8589\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 1s 850us/step - loss: 0.4247 - acc: 0.9636 - val_loss: 1.4331 - val_acc: 0.8589\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 1s 894us/step - loss: 0.5937 - acc: 0.9542 - val_loss: 1.2248 - val_acc: 0.8871\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4887 - acc: 0.9690 - val_loss: 1.1302 - val_acc: 0.8669\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.5332 - acc: 0.9555 - val_loss: 1.6428 - val_acc: 0.8629\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 1s 844us/step - loss: 0.3008 - acc: 0.9744 - val_loss: 1.6060 - val_acc: 0.8548\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.3638 - acc: 0.9704 - val_loss: 1.8974 - val_acc: 0.8306\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 1s 845us/step - loss: 0.5445 - acc: 0.9528 - val_loss: 1.6761 - val_acc: 0.8468\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.4612 - acc: 0.9623 - val_loss: 1.9899 - val_acc: 0.8226\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.4790 - acc: 0.9596 - val_loss: 1.4259 - val_acc: 0.8790\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 1s 860us/step - loss: 0.7032 - acc: 0.9447 - val_loss: 1.6865 - val_acc: 0.8427\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 1s 895us/step - loss: 0.5931 - acc: 0.9569 - val_loss: 1.8045 - val_acc: 0.8387\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.6321 - acc: 0.9501 - val_loss: 1.2534 - val_acc: 0.8871\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.4799 - acc: 0.9623 - val_loss: 1.2194 - val_acc: 0.8790\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 1s 840us/step - loss: 0.3635 - acc: 0.9650 - val_loss: 1.0398 - val_acc: 0.9032\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.6876 - acc: 0.9501 - val_loss: 1.8320 - val_acc: 0.8306\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 1s 851us/step - loss: 0.5337 - acc: 0.9582 - val_loss: 1.6391 - val_acc: 0.8306\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.3422 - acc: 0.9677 - val_loss: 1.1941 - val_acc: 0.8710\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 1s 867us/step - loss: 0.2018 - acc: 0.9852 - val_loss: 1.8133 - val_acc: 0.8266\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 1s 879us/step - loss: 0.4968 - acc: 0.9650 - val_loss: 1.1859 - val_acc: 0.9032\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5790 - acc: 0.9596 - val_loss: 1.9424 - val_acc: 0.8548\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 1s 883us/step - loss: 0.4202 - acc: 0.9704 - val_loss: 1.4916 - val_acc: 0.8750\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 1s 872us/step - loss: 0.6153 - acc: 0.9555 - val_loss: 1.6687 - val_acc: 0.8589\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.7846 - acc: 0.9434 - val_loss: 1.5053 - val_acc: 0.8710\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.5400 - acc: 0.9555 - val_loss: 1.4280 - val_acc: 0.8871\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 1s 860us/step - loss: 0.3748 - acc: 0.9730 - val_loss: 1.6106 - val_acc: 0.8669\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.7038 - acc: 0.9501 - val_loss: 2.1304 - val_acc: 0.8065\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.5338 - acc: 0.9555 - val_loss: 1.2723 - val_acc: 0.8710\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.5417 - acc: 0.9555 - val_loss: 1.2146 - val_acc: 0.8750\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.5873 - acc: 0.9555 - val_loss: 1.5977 - val_acc: 0.8468\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.6278 - acc: 0.9488 - val_loss: 1.8952 - val_acc: 0.8508\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 1s 910us/step - loss: 0.9329 - acc: 0.9353 - val_loss: 1.4083 - val_acc: 0.8831\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4104 - acc: 0.9677 - val_loss: 1.4134 - val_acc: 0.8790\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 1s 880us/step - loss: 0.5456 - acc: 0.9623 - val_loss: 1.5179 - val_acc: 0.8710\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.9464 - acc: 0.9299 - val_loss: 2.2815 - val_acc: 0.8185\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.8157 - acc: 0.9461 - val_loss: 1.7826 - val_acc: 0.8589\n",
      "Epoch 946/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.6769 - acc: 0.9528 - val_loss: 2.1384 - val_acc: 0.8306\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 1s 893us/step - loss: 0.4918 - acc: 0.9636 - val_loss: 1.3063 - val_acc: 0.8750\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.5153 - acc: 0.9609 - val_loss: 1.7943 - val_acc: 0.8589\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.7196 - acc: 0.9488 - val_loss: 1.7247 - val_acc: 0.8669\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 1s 885us/step - loss: 0.6565 - acc: 0.9528 - val_loss: 2.0299 - val_acc: 0.8427\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 1s 871us/step - loss: 0.3773 - acc: 0.9690 - val_loss: 1.6157 - val_acc: 0.8710\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.5063 - acc: 0.9650 - val_loss: 1.6785 - val_acc: 0.8508\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.7075 - acc: 0.9447 - val_loss: 1.5228 - val_acc: 0.8750\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.5350 - acc: 0.9636 - val_loss: 2.1147 - val_acc: 0.8266\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 1s 902us/step - loss: 0.6330 - acc: 0.9528 - val_loss: 2.0042 - val_acc: 0.8427\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5968 - acc: 0.9569 - val_loss: 1.6365 - val_acc: 0.8669\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 1s 896us/step - loss: 0.4238 - acc: 0.9717 - val_loss: 1.8206 - val_acc: 0.8589\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 1s 846us/step - loss: 0.6106 - acc: 0.9555 - val_loss: 2.1727 - val_acc: 0.8427\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 1s 926us/step - loss: 0.7621 - acc: 0.9461 - val_loss: 1.8804 - val_acc: 0.8508\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 1s 857us/step - loss: 0.6118 - acc: 0.9501 - val_loss: 1.7972 - val_acc: 0.8669\n",
      "Epoch 961/1000\n",
      "742/742 [==============================] - 1s 883us/step - loss: 0.5386 - acc: 0.9609 - val_loss: 1.7582 - val_acc: 0.8508\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5861 - acc: 0.9515 - val_loss: 1.7280 - val_acc: 0.8750\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 1s 903us/step - loss: 0.5042 - acc: 0.9609 - val_loss: 2.4292 - val_acc: 0.8306\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 1s 845us/step - loss: 0.4789 - acc: 0.9650 - val_loss: 2.1168 - val_acc: 0.8306\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.7209 - acc: 0.9488 - val_loss: 2.1363 - val_acc: 0.8145\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 1s 855us/step - loss: 0.4886 - acc: 0.9636 - val_loss: 1.6666 - val_acc: 0.8589\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.6476 - acc: 0.9542 - val_loss: 1.9632 - val_acc: 0.8266\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5911 - acc: 0.9596 - val_loss: 1.8044 - val_acc: 0.8427\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 1s 881us/step - loss: 0.9163 - acc: 0.9353 - val_loss: 1.2771 - val_acc: 0.8710\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 1s 875us/step - loss: 0.5324 - acc: 0.9623 - val_loss: 1.3091 - val_acc: 0.8911\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.9163 - acc: 0.9380 - val_loss: 1.8101 - val_acc: 0.8468\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 1s 873us/step - loss: 0.4695 - acc: 0.9623 - val_loss: 1.1161 - val_acc: 0.8992\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4511 - acc: 0.9690 - val_loss: 1.1945 - val_acc: 0.8831\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 1s 864us/step - loss: 0.4581 - acc: 0.9663 - val_loss: 1.6160 - val_acc: 0.8750\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 1s 889us/step - loss: 0.5185 - acc: 0.9636 - val_loss: 1.9343 - val_acc: 0.8629\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.4361 - acc: 0.9690 - val_loss: 1.7158 - val_acc: 0.8790\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 1s 862us/step - loss: 0.5803 - acc: 0.9569 - val_loss: 1.8496 - val_acc: 0.8629\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 1s 896us/step - loss: 0.7316 - acc: 0.9488 - val_loss: 1.9536 - val_acc: 0.8629\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 1s 842us/step - loss: 0.6866 - acc: 0.9528 - val_loss: 1.4108 - val_acc: 0.8871\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 1s 898us/step - loss: 0.4238 - acc: 0.9690 - val_loss: 1.3487 - val_acc: 0.8911\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 1s 853us/step - loss: 0.9531 - acc: 0.9353 - val_loss: 2.6563 - val_acc: 0.8065\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.5701 - acc: 0.9609 - val_loss: 2.0769 - val_acc: 0.8427\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 1s 876us/step - loss: 0.6499 - acc: 0.9569 - val_loss: 2.0017 - val_acc: 0.8508\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.5875 - acc: 0.9569 - val_loss: 2.5288 - val_acc: 0.8226\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.9356 - acc: 0.9380 - val_loss: 2.0829 - val_acc: 0.8427\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 1s 905us/step - loss: 0.8155 - acc: 0.9461 - val_loss: 2.1196 - val_acc: 0.8427\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 1s 852us/step - loss: 0.6290 - acc: 0.9542 - val_loss: 1.7708 - val_acc: 0.8710\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.7208 - acc: 0.9488 - val_loss: 1.7684 - val_acc: 0.8710\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 1s 874us/step - loss: 1.0629 - acc: 0.9299 - val_loss: 1.9110 - val_acc: 0.8710\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 1s 878us/step - loss: 0.8675 - acc: 0.9394 - val_loss: 2.1579 - val_acc: 0.8387\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.9908 - acc: 0.9340 - val_loss: 2.5871 - val_acc: 0.8185\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 1s 892us/step - loss: 0.7043 - acc: 0.9528 - val_loss: 2.0298 - val_acc: 0.8508\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 1s 896us/step - loss: 0.8094 - acc: 0.9474 - val_loss: 2.9186 - val_acc: 0.7702\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 1s 877us/step - loss: 0.7541 - acc: 0.9488 - val_loss: 1.8801 - val_acc: 0.8427\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 1s 904us/step - loss: 0.6641 - acc: 0.9528 - val_loss: 1.5358 - val_acc: 0.8952\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 1s 861us/step - loss: 0.7225 - acc: 0.9501 - val_loss: 1.9155 - val_acc: 0.8589\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 1s 884us/step - loss: 0.5427 - acc: 0.9596 - val_loss: 2.2007 - val_acc: 0.8306\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.7684 - acc: 0.9474 - val_loss: 2.8156 - val_acc: 0.7984\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 1s 863us/step - loss: 0.6575 - acc: 0.9569 - val_loss: 2.4936 - val_acc: 0.8145\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 1s 912us/step - loss: 0.7678 - acc: 0.9461 - val_loss: 1.9207 - val_acc: 0.8629\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, \n",
    "                    epochs=1000,  \n",
    "                    validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be6e907ac8>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果：精度确实又高了！过拟合问题也不明显。\n",
    "\n",
    "问题：既然增大每个卷积核的“感受野”有效，那是不是再多增加一些这样的卷积核能看到更多的特征呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化5："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存上一种模型结构不变，进一步加大每层的卷积核数(还是用大感受野的卷积核)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(512, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(512, 11, activation='relu', padding='same'))  # 卷积核数进一步加大！\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 7s 9ms/step - loss: 4.7777 - acc: 0.0135 - val_loss: 4.5977 - val_acc: 0.0081\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5955 - acc: 0.0081 - val_loss: 4.5997 - val_acc: 0.0081\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5957 - acc: 0.0067 - val_loss: 4.6018 - val_acc: 0.0081\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5949 - acc: 0.0094 - val_loss: 4.6036 - val_acc: 0.0040\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5934 - acc: 0.0081 - val_loss: 5.0594 - val_acc: 0.0040\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6026 - acc: 0.0148 - val_loss: 4.5616 - val_acc: 0.0121\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5343 - acc: 0.0121 - val_loss: 4.5163 - val_acc: 0.0121\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4077 - acc: 0.0175 - val_loss: 4.4881 - val_acc: 0.0202\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2645 - acc: 0.0202 - val_loss: 4.3365 - val_acc: 0.0081\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1377 - acc: 0.0256 - val_loss: 4.3674 - val_acc: 0.0121\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0987 - acc: 0.0243 - val_loss: 4.2155 - val_acc: 0.0161\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0308 - acc: 0.0243 - val_loss: 4.7469 - val_acc: 0.0081\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9894 - acc: 0.0296 - val_loss: 4.0320 - val_acc: 0.0121\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9103 - acc: 0.0364 - val_loss: 3.9694 - val_acc: 0.0282\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8021 - acc: 0.0593 - val_loss: 4.3560 - val_acc: 0.0282\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6967 - acc: 0.0620 - val_loss: 3.9289 - val_acc: 0.0605\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5325 - acc: 0.0782 - val_loss: 3.6758 - val_acc: 0.0685\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3821 - acc: 0.0916 - val_loss: 3.3042 - val_acc: 0.0927\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3333 - acc: 0.0957 - val_loss: 3.2459 - val_acc: 0.0968\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1889 - acc: 0.1173 - val_loss: 3.0756 - val_acc: 0.1573\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0569 - acc: 0.1173 - val_loss: 3.0703 - val_acc: 0.1613\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9559 - acc: 0.1644 - val_loss: 3.0739 - val_acc: 0.1371\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8512 - acc: 0.1779 - val_loss: 4.0371 - val_acc: 0.0403\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8288 - acc: 0.1995 - val_loss: 3.3536 - val_acc: 0.1210\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6696 - acc: 0.1927 - val_loss: 2.6269 - val_acc: 0.2097\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5627 - acc: 0.2237 - val_loss: 2.5391 - val_acc: 0.1815\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4928 - acc: 0.2237 - val_loss: 3.3087 - val_acc: 0.0766\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3283 - acc: 0.2844 - val_loss: 2.7169 - val_acc: 0.1573\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3074 - acc: 0.2844 - val_loss: 2.4564 - val_acc: 0.2218\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2675 - acc: 0.2992 - val_loss: 2.7092 - val_acc: 0.2097\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0570 - acc: 0.3518 - val_loss: 2.4722 - val_acc: 0.2863\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0641 - acc: 0.3450 - val_loss: 2.3139 - val_acc: 0.3226\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0572 - acc: 0.3491 - val_loss: 2.3380 - val_acc: 0.3306\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9010 - acc: 0.4057 - val_loss: 2.2406 - val_acc: 0.2984\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7438 - acc: 0.4191 - val_loss: 2.0246 - val_acc: 0.3790\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7621 - acc: 0.4299 - val_loss: 2.1942 - val_acc: 0.3629\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6744 - acc: 0.4569 - val_loss: 1.8794 - val_acc: 0.4194\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6572 - acc: 0.4744 - val_loss: 2.0877 - val_acc: 0.4073\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5175 - acc: 0.5040 - val_loss: 2.0772 - val_acc: 0.3952\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4143 - acc: 0.5499 - val_loss: 1.7228 - val_acc: 0.4879\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3842 - acc: 0.5445 - val_loss: 1.8253 - val_acc: 0.4395\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2704 - acc: 0.5782 - val_loss: 2.3659 - val_acc: 0.3710\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2786 - acc: 0.5930 - val_loss: 1.9510 - val_acc: 0.4274\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1854 - acc: 0.6213 - val_loss: 1.8219 - val_acc: 0.4798\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1401 - acc: 0.6280 - val_loss: 1.4314 - val_acc: 0.5645\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9991 - acc: 0.6631 - val_loss: 1.8947 - val_acc: 0.4718\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0217 - acc: 0.6833 - val_loss: 1.5034 - val_acc: 0.5524\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0004 - acc: 0.6725 - val_loss: 1.7426 - val_acc: 0.5524\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9749 - acc: 0.6819 - val_loss: 1.4806 - val_acc: 0.5605\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9103 - acc: 0.7008 - val_loss: 1.7177 - val_acc: 0.5363\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7260 - acc: 0.7574 - val_loss: 1.6038 - val_acc: 0.6210\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8050 - acc: 0.7480 - val_loss: 1.4774 - val_acc: 0.5645\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7604 - acc: 0.7628 - val_loss: 1.6407 - val_acc: 0.5766\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7022 - acc: 0.7534 - val_loss: 1.3656 - val_acc: 0.6573\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7485 - acc: 0.7844 - val_loss: 0.9001 - val_acc: 0.7258\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5625 - acc: 0.8302 - val_loss: 1.7404 - val_acc: 0.6089\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5733 - acc: 0.7992 - val_loss: 1.0174 - val_acc: 0.7298\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5031 - acc: 0.8356 - val_loss: 2.1403 - val_acc: 0.4960\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6251 - acc: 0.8059 - val_loss: 1.1435 - val_acc: 0.6976\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5466 - acc: 0.8396 - val_loss: 1.3675 - val_acc: 0.6452\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5179 - acc: 0.8383 - val_loss: 1.3960 - val_acc: 0.6250\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5050 - acc: 0.8531 - val_loss: 1.6272 - val_acc: 0.5726\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4815 - acc: 0.8477 - val_loss: 1.1491 - val_acc: 0.6774\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4133 - acc: 0.8612 - val_loss: 0.9115 - val_acc: 0.7661\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4271 - acc: 0.8720 - val_loss: 0.8784 - val_acc: 0.7500\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4273 - acc: 0.8652 - val_loss: 0.9767 - val_acc: 0.7056\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3808 - acc: 0.8908 - val_loss: 1.0135 - val_acc: 0.7702\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4210 - acc: 0.8774 - val_loss: 1.0731 - val_acc: 0.7500\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3524 - acc: 0.8976 - val_loss: 0.8530 - val_acc: 0.7944\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3136 - acc: 0.8976 - val_loss: 0.7871 - val_acc: 0.8024\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3715 - acc: 0.9043 - val_loss: 1.1060 - val_acc: 0.7258\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3540 - acc: 0.9016 - val_loss: 1.0228 - val_acc: 0.7621\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3370 - acc: 0.9043 - val_loss: 0.9626 - val_acc: 0.7742\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2314 - acc: 0.9218 - val_loss: 1.0817 - val_acc: 0.7419\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3621 - acc: 0.9084 - val_loss: 2.0135 - val_acc: 0.5685\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3462 - acc: 0.8908 - val_loss: 1.1849 - val_acc: 0.7540\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2538 - acc: 0.9232 - val_loss: 0.8878 - val_acc: 0.7661\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3161 - acc: 0.9111 - val_loss: 0.8841 - val_acc: 0.7944\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2345 - acc: 0.9205 - val_loss: 0.9317 - val_acc: 0.7863\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2448 - acc: 0.9272 - val_loss: 0.7486 - val_acc: 0.8306\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2928 - acc: 0.9070 - val_loss: 0.7285 - val_acc: 0.8387\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2051 - acc: 0.9340 - val_loss: 1.2328 - val_acc: 0.7500\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3769 - acc: 0.9124 - val_loss: 1.0717 - val_acc: 0.7823\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2059 - acc: 0.9474 - val_loss: 0.7661 - val_acc: 0.8306\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2013 - acc: 0.9447 - val_loss: 1.0286 - val_acc: 0.7903\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2791 - acc: 0.9286 - val_loss: 0.7246 - val_acc: 0.8145\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1739 - acc: 0.9434 - val_loss: 0.9032 - val_acc: 0.8065\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3039 - acc: 0.9326 - val_loss: 1.1740 - val_acc: 0.7298\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 3s 4ms/step - loss: 0.2020 - acc: 0.9461 - val_loss: 0.7972 - val_acc: 0.8105\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 3s 4ms/step - loss: 0.1455 - acc: 0.9582 - val_loss: 1.0108 - val_acc: 0.7823\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3001 - acc: 0.9178 - val_loss: 0.7390 - val_acc: 0.8306\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1364 - acc: 0.9596 - val_loss: 1.1971 - val_acc: 0.73791363 - acc: 0.\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2013 - acc: 0.9515 - val_loss: 0.8269 - val_acc: 0.8065\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2417 - acc: 0.9299 - val_loss: 0.9713 - val_acc: 0.7742\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2096 - acc: 0.9434 - val_loss: 0.8654 - val_acc: 0.8226\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1728 - acc: 0.9488 - val_loss: 0.9656 - val_acc: 0.7944\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1798 - acc: 0.9515 - val_loss: 0.7686 - val_acc: 0.8468\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1868 - acc: 0.9501 - val_loss: 0.9929 - val_acc: 0.7944\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9690 - val_loss: 0.9150 - val_acc: 0.8105\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2378 - acc: 0.9394 - val_loss: 0.7277 - val_acc: 0.8185\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1307 - acc: 0.9730 - val_loss: 0.9917 - val_acc: 0.7984\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2791 - acc: 0.9394 - val_loss: 0.9480 - val_acc: 0.8306\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1950 - acc: 0.9582 - val_loss: 0.7665 - val_acc: 0.8548\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1620 - acc: 0.9663 - val_loss: 0.9851 - val_acc: 0.7984\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2173 - acc: 0.9434 - val_loss: 0.8549 - val_acc: 0.8387\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1552 - acc: 0.9596 - val_loss: 0.7968 - val_acc: 0.8306\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1327 - acc: 0.9663 - val_loss: 0.9933 - val_acc: 0.8226\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.2421 - acc: 0.948 - 2s 3ms/step - loss: 0.2404 - acc: 0.9488 - val_loss: 0.5992 - val_acc: 0.8589\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1547 - acc: 0.9609 - val_loss: 1.0652 - val_acc: 0.7944\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0948 - acc: 0.9730 - val_loss: 1.5003 - val_acc: 0.7581\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1935 - acc: 0.9596 - val_loss: 1.4671 - val_acc: 0.7379\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1839 - acc: 0.9596 - val_loss: 0.6978 - val_acc: 0.8589\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1425 - acc: 0.9636 - val_loss: 0.7943 - val_acc: 0.8145\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1419 - acc: 0.9663 - val_loss: 0.6981 - val_acc: 0.8548\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2094 - acc: 0.9515 - val_loss: 0.9533 - val_acc: 0.8185\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1015 - acc: 0.9730 - val_loss: 0.9952 - val_acc: 0.7984\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1043 - acc: 0.9784 - val_loss: 0.6690 - val_acc: 0.8750\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2780 - acc: 0.9623 - val_loss: 0.7573 - val_acc: 0.8226\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1311 - acc: 0.9744 - val_loss: 0.9237 - val_acc: 0.8347\n",
      "Epoch 120/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1476 - acc: 0.9677 - val_loss: 0.7561 - val_acc: 0.8306\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1464 - acc: 0.9704 - val_loss: 0.9100 - val_acc: 0.8427\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1252 - acc: 0.9663 - val_loss: 1.3231 - val_acc: 0.7540\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1303 - acc: 0.9663 - val_loss: 0.8901 - val_acc: 0.8387\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1128 - acc: 0.9730 - val_loss: 0.6754 - val_acc: 0.8387\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1435 - acc: 0.9704 - val_loss: 0.8714 - val_acc: 0.8427\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9717 - val_loss: 1.0712 - val_acc: 0.8145\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2076 - acc: 0.9609 - val_loss: 0.7443 - val_acc: 0.8427\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1621 - acc: 0.9704 - val_loss: 0.7383 - val_acc: 0.8589\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1735 - acc: 0.9596 - val_loss: 0.5602 - val_acc: 0.8750\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1556 - acc: 0.9623 - val_loss: 0.9882 - val_acc: 0.8226\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9704 - val_loss: 0.8913 - val_acc: 0.8306\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1370 - acc: 0.9704 - val_loss: 0.7709 - val_acc: 0.8508\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2053 - acc: 0.9609 - val_loss: 1.0189 - val_acc: 0.8185\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2050 - acc: 0.9569 - val_loss: 0.5458 - val_acc: 0.8871\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1264 - acc: 0.9744 - val_loss: 0.7276 - val_acc: 0.8790\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1402 - acc: 0.9677 - val_loss: 1.0408 - val_acc: 0.8226\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1532 - acc: 0.9650 - val_loss: 0.6661 - val_acc: 0.8669\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1010 - acc: 0.9825 - val_loss: 1.2108 - val_acc: 0.8145\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1869 - acc: 0.9636 - val_loss: 0.5204 - val_acc: 0.8871\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1324 - acc: 0.9650 - val_loss: 0.7942 - val_acc: 0.8548\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3074 - acc: 0.9501 - val_loss: 0.6690 - val_acc: 0.8548\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1777 - acc: 0.9663 - val_loss: 0.6415 - val_acc: 0.8629\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9757 - val_loss: 0.6517 - val_acc: 0.8589\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0649 - acc: 0.9811 - val_loss: 0.8412 - val_acc: 0.8468\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1333 - acc: 0.9730 - val_loss: 0.6218 - val_acc: 0.8548\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0664 - acc: 0.9879 - val_loss: 0.6950 - val_acc: 0.9032\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1965 - acc: 0.9609 - val_loss: 1.0704 - val_acc: 0.8065\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1341 - acc: 0.9650 - val_loss: 0.8910 - val_acc: 0.8548\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1698 - acc: 0.9717 - val_loss: 0.7233 - val_acc: 0.8629\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1392 - acc: 0.9690 - val_loss: 0.6947 - val_acc: 0.8710\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1642 - acc: 0.9677 - val_loss: 0.7125 - val_acc: 0.8589\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1557 - acc: 0.9677 - val_loss: 0.6377 - val_acc: 0.8629\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2467 - acc: 0.9636 - val_loss: 1.0996 - val_acc: 0.8387\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1267 - acc: 0.9717 - val_loss: 0.6361 - val_acc: 0.8710\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1564 - acc: 0.9704 - val_loss: 0.8252 - val_acc: 0.8669\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0837 - acc: 0.9798 - val_loss: 0.9394 - val_acc: 0.8306\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2708 - acc: 0.9636 - val_loss: 0.9515 - val_acc: 0.8347\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0674 - acc: 0.9838 - val_loss: 0.9870 - val_acc: 0.8468\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1769 - acc: 0.9757 - val_loss: 0.7384 - val_acc: 0.8669\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2156 - acc: 0.9704 - val_loss: 0.9238 - val_acc: 0.8629\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1826 - acc: 0.9717 - val_loss: 0.7941 - val_acc: 0.8750\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1108 - acc: 0.9838 - val_loss: 0.9534 - val_acc: 0.8508\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2624 - acc: 0.9569 - val_loss: 1.2467 - val_acc: 0.7944\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0969 - acc: 0.9730 - val_loss: 1.2133 - val_acc: 0.8387\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1915 - acc: 0.9663 - val_loss: 0.9221 - val_acc: 0.8790\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2781 - acc: 0.9582 - val_loss: 0.8179 - val_acc: 0.8669\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2162 - acc: 0.9569 - val_loss: 0.8926 - val_acc: 0.8589\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1694 - acc: 0.9623 - val_loss: 0.6402 - val_acc: 0.8629\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1328 - acc: 0.9798 - val_loss: 0.9160 - val_acc: 0.8468\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2948 - acc: 0.9582 - val_loss: 0.6711 - val_acc: 0.8669\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1554 - acc: 0.9650 - val_loss: 0.8739 - val_acc: 0.8589\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1890 - acc: 0.9690 - val_loss: 0.6009 - val_acc: 0.8750\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1744 - acc: 0.9704 - val_loss: 0.9222 - val_acc: 0.8468\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0764 - acc: 0.9852 - val_loss: 0.6657 - val_acc: 0.8790\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1879 - acc: 0.9690 - val_loss: 0.5923 - val_acc: 0.8992\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1691 - acc: 0.9784 - val_loss: 0.5719 - val_acc: 0.8750\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0857 - acc: 0.9798 - val_loss: 0.9816 - val_acc: 0.8226\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2392 - acc: 0.9609 - val_loss: 0.6977 - val_acc: 0.8790\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1289 - acc: 0.9744 - val_loss: 0.6413 - val_acc: 0.8952\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1351 - acc: 0.9757 - val_loss: 0.5982 - val_acc: 0.8750\n",
      "Epoch 181/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1665 - acc: 0.9623 - val_loss: 0.6301 - val_acc: 0.8750\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9717 - val_loss: 1.1236 - val_acc: 0.8468\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1409 - acc: 0.9798 - val_loss: 1.0150 - val_acc: 0.8266\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1676 - acc: 0.9771 - val_loss: 0.9260 - val_acc: 0.8589\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1861 - acc: 0.9690 - val_loss: 0.7907 - val_acc: 0.8952\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1098 - acc: 0.9744 - val_loss: 0.6297 - val_acc: 0.8831\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1010 - acc: 0.9798 - val_loss: 0.7487 - val_acc: 0.8710\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2319 - acc: 0.9650 - val_loss: 0.9241 - val_acc: 0.8669\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0803 - acc: 0.9852 - val_loss: 1.3100 - val_acc: 0.8306\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1413 - acc: 0.9838 - val_loss: 0.6973 - val_acc: 0.8831\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1935 - acc: 0.9730 - val_loss: 0.8752 - val_acc: 0.8710\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2471 - acc: 0.9704 - val_loss: 0.9729 - val_acc: 0.8508\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1381 - acc: 0.9717 - val_loss: 0.6933 - val_acc: 0.8952\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1511 - acc: 0.9798 - val_loss: 0.9527 - val_acc: 0.8266\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2034 - acc: 0.9677 - val_loss: 0.7919 - val_acc: 0.8669\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1156 - acc: 0.9811 - val_loss: 0.6328 - val_acc: 0.8871\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1054 - acc: 0.9879 - val_loss: 0.9863 - val_acc: 0.8387\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1325 - acc: 0.9811 - val_loss: 0.7519 - val_acc: 0.8629\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0956 - acc: 0.9879 - val_loss: 0.9734 - val_acc: 0.8589\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0876 - acc: 0.9879 - val_loss: 0.8203 - val_acc: 0.8911\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1857 - acc: 0.9744 - val_loss: 1.4223 - val_acc: 0.8226\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2135 - acc: 0.9717 - val_loss: 0.9730 - val_acc: 0.8468\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1534 - acc: 0.9798 - val_loss: 1.1443 - val_acc: 0.8427\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1232 - acc: 0.9811 - val_loss: 0.9565 - val_acc: 0.8831\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1757 - acc: 0.9730 - val_loss: 0.6658 - val_acc: 0.8911\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2092 - acc: 0.9650 - val_loss: 0.6983 - val_acc: 0.8669\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0635 - acc: 0.9838 - val_loss: 0.7845 - val_acc: 0.8669\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1334 - acc: 0.9757 - val_loss: 0.8806 - val_acc: 0.8750\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9838 - val_loss: 1.0071 - val_acc: 0.8790\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2377 - acc: 0.9690 - val_loss: 0.9530 - val_acc: 0.8790\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2136 - acc: 0.9704 - val_loss: 0.9413 - val_acc: 0.8508\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1465 - acc: 0.9852 - val_loss: 0.8511 - val_acc: 0.8790\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2571 - acc: 0.9677 - val_loss: 1.4336 - val_acc: 0.8548\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9771 - val_loss: 1.2188 - val_acc: 0.8589\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1875 - acc: 0.9677 - val_loss: 1.0789 - val_acc: 0.8669\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1863 - acc: 0.9717 - val_loss: 0.7665 - val_acc: 0.8669\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.9771 - val_loss: 0.8737 - val_acc: 0.8871\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0668 - acc: 0.9825 - val_loss: 0.9943 - val_acc: 0.8750\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1015 - acc: 0.9811 - val_loss: 1.2087 - val_acc: 0.8468\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1473 - acc: 0.9744 - val_loss: 1.1768 - val_acc: 0.8710\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0867 - acc: 0.9825 - val_loss: 1.1944 - val_acc: 0.8508\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1613 - acc: 0.9784 - val_loss: 1.5056 - val_acc: 0.8387\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0963 - acc: 0.9825 - val_loss: 0.8389 - val_acc: 0.8952\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0902 - acc: 0.9811 - val_loss: 1.2853 - val_acc: 0.8548\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1669 - acc: 0.9744 - val_loss: 1.3154 - val_acc: 0.8347\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2139 - acc: 0.9704 - val_loss: 0.9462 - val_acc: 0.8750\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1065 - acc: 0.9825 - val_loss: 1.1943 - val_acc: 0.8427\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1362 - acc: 0.9771 - val_loss: 0.8546 - val_acc: 0.8710\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0904 - acc: 0.9838 - val_loss: 1.0778 - val_acc: 0.8669\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2256 - acc: 0.9757 - val_loss: 0.7414 - val_acc: 0.8790\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1080 - acc: 0.9838 - val_loss: 0.8875 - val_acc: 0.8952\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1706 - acc: 0.9784 - val_loss: 0.7864 - val_acc: 0.8952\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1708 - acc: 0.9757 - val_loss: 1.7773 - val_acc: 0.8306\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1934 - acc: 0.9784 - val_loss: 1.2419 - val_acc: 0.8508\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1426 - acc: 0.9798 - val_loss: 0.9913 - val_acc: 0.8548\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1511 - acc: 0.9757 - val_loss: 0.7543 - val_acc: 0.8710\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1707 - acc: 0.9663 - val_loss: 0.9691 - val_acc: 0.8871\n",
      "Epoch 238/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9838 - val_loss: 0.9345 - val_acc: 0.8911\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0805 - acc: 0.9865 - val_loss: 1.2377 - val_acc: 0.8710\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1879 - acc: 0.9784 - val_loss: 1.1303 - val_acc: 0.8427\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2171 - acc: 0.9704 - val_loss: 0.9823 - val_acc: 0.8750\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1884 - acc: 0.9757 - val_loss: 0.8796 - val_acc: 0.8871\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1973 - acc: 0.9730 - val_loss: 1.0676 - val_acc: 0.8669\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1589 - acc: 0.9744 - val_loss: 0.8986 - val_acc: 0.8790\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0789 - acc: 0.9852 - val_loss: 1.1140 - val_acc: 0.8831\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3191 - acc: 0.9582 - val_loss: 0.8235 - val_acc: 0.8669\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2938 - acc: 0.9677 - val_loss: 0.6063 - val_acc: 0.8992\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0977 - acc: 0.9879 - val_loss: 0.9695 - val_acc: 0.8871\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1071 - acc: 0.9757 - val_loss: 0.8062 - val_acc: 0.8871\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0259 - acc: 0.9973 - val_loss: 0.8687 - val_acc: 0.8831\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1734 - acc: 0.9771 - val_loss: 0.8536 - val_acc: 0.8750\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1147 - acc: 0.9838 - val_loss: 0.8747 - val_acc: 0.8911\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0274 - acc: 0.9960 - val_loss: 0.6747 - val_acc: 0.9073\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2590 - acc: 0.9730 - val_loss: 1.0102 - val_acc: 0.8710\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1248 - acc: 0.9825 - val_loss: 0.8658 - val_acc: 0.8750\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1198 - acc: 0.9825 - val_loss: 1.3151 - val_acc: 0.8589\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1853 - acc: 0.9757 - val_loss: 0.8908 - val_acc: 0.8710\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1070 - acc: 0.9798 - val_loss: 0.7523 - val_acc: 0.8911\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1040 - acc: 0.9865 - val_loss: 0.6204 - val_acc: 0.9153\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1638 - acc: 0.9771 - val_loss: 0.7846 - val_acc: 0.8790\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0946 - acc: 0.9865 - val_loss: 0.8885 - val_acc: 0.8911\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2303 - acc: 0.9704 - val_loss: 1.1005 - val_acc: 0.8629\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1944 - acc: 0.9825 - val_loss: 0.7679 - val_acc: 0.9032\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1347 - acc: 0.9825 - val_loss: 1.2903 - val_acc: 0.8629\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2115 - acc: 0.9704 - val_loss: 1.1388 - val_acc: 0.8629\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1135 - acc: 0.9825 - val_loss: 1.1463 - val_acc: 0.8548\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2246 - acc: 0.9730 - val_loss: 1.2624 - val_acc: 0.8790\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2357 - acc: 0.9717 - val_loss: 1.0376 - val_acc: 0.8468\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2238 - acc: 0.9757 - val_loss: 1.1666 - val_acc: 0.8831\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1812 - acc: 0.9798 - val_loss: 0.9621 - val_acc: 0.8589\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0586 - acc: 0.9879 - val_loss: 1.9628 - val_acc: 0.8226\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3104 - acc: 0.9717 - val_loss: 1.2816 - val_acc: 0.8669\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2068 - acc: 0.9757 - val_loss: 1.3718 - val_acc: 0.8669\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3412 - acc: 0.9650 - val_loss: 0.9770 - val_acc: 0.8669\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1949 - acc: 0.9771 - val_loss: 1.3773 - val_acc: 0.8710\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2588 - acc: 0.9609 - val_loss: 1.0654 - val_acc: 0.8831\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2461 - acc: 0.9704 - val_loss: 1.6211 - val_acc: 0.8226\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3019 - acc: 0.9650 - val_loss: 1.2076 - val_acc: 0.8508\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1144 - acc: 0.9852 - val_loss: 1.0173 - val_acc: 0.8790\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2031 - acc: 0.9784 - val_loss: 1.1069 - val_acc: 0.8871\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1821 - acc: 0.9771 - val_loss: 1.1599 - val_acc: 0.8629\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1688 - acc: 0.9825 - val_loss: 1.1478 - val_acc: 0.8871\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0954 - acc: 0.9879 - val_loss: 0.9149 - val_acc: 0.9153\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2520 - acc: 0.9744 - val_loss: 0.7768 - val_acc: 0.9194\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1537 - acc: 0.9811 - val_loss: 1.4751 - val_acc: 0.8589\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1103 - acc: 0.9865 - val_loss: 0.9038 - val_acc: 0.8911\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2712 - acc: 0.9704 - val_loss: 0.5100 - val_acc: 0.9073\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1159 - acc: 0.9784 - val_loss: 0.6184 - val_acc: 0.9153\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1448 - acc: 0.9811 - val_loss: 0.9395 - val_acc: 0.8871\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1421 - acc: 0.9798 - val_loss: 0.7856 - val_acc: 0.8992\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9811 - val_loss: 0.9336 - val_acc: 0.9113\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1861 - acc: 0.9784 - val_loss: 0.7206 - val_acc: 0.9194\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2851 - acc: 0.9663 - val_loss: 0.8513 - val_acc: 0.8992\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2121 - acc: 0.9798 - val_loss: 0.9776 - val_acc: 0.9032\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2703 - acc: 0.9730 - val_loss: 0.9570 - val_acc: 0.8790\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4161 - acc: 0.9596 - val_loss: 1.6506 - val_acc: 0.8306\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1881 - acc: 0.9757 - val_loss: 1.2619 - val_acc: 0.8911\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1453 - acc: 0.9865 - val_loss: 1.1736 - val_acc: 0.8871\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1658 - acc: 0.9825 - val_loss: 1.3457 - val_acc: 0.8710\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1768 - acc: 0.9825 - val_loss: 1.1052 - val_acc: 0.8790\n",
      "Epoch 301/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2301 - acc: 0.9784 - val_loss: 1.6302 - val_acc: 0.8548\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2590 - acc: 0.9798 - val_loss: 1.4215 - val_acc: 0.8589\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2433 - acc: 0.9730 - val_loss: 1.1641 - val_acc: 0.8871\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2231 - acc: 0.9744 - val_loss: 1.4307 - val_acc: 0.8831\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2018 - acc: 0.9811 - val_loss: 1.4082 - val_acc: 0.8589\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2167 - acc: 0.9771 - val_loss: 0.9980 - val_acc: 0.9032\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2897 - acc: 0.9690 - val_loss: 1.0871 - val_acc: 0.8871\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3651 - acc: 0.9663 - val_loss: 1.5444 - val_acc: 0.8427\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2943 - acc: 0.9744 - val_loss: 1.1304 - val_acc: 0.8911\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1958 - acc: 0.9838 - val_loss: 1.1435 - val_acc: 0.8952\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1536 - acc: 0.9892 - val_loss: 1.4055 - val_acc: 0.8871\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2710 - acc: 0.9784 - val_loss: 1.1369 - val_acc: 0.8911\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2596 - acc: 0.9784 - val_loss: 1.3069 - val_acc: 0.8629\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2736 - acc: 0.9730 - val_loss: 1.7931 - val_acc: 0.8629\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2855 - acc: 0.9771 - val_loss: 1.4531 - val_acc: 0.8589\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3591 - acc: 0.9717 - val_loss: 1.0195 - val_acc: 0.9194\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2260 - acc: 0.9784 - val_loss: 1.3171 - val_acc: 0.8871\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3866 - acc: 0.9636 - val_loss: 1.8709 - val_acc: 0.8427\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1665 - acc: 0.9798 - val_loss: 1.2170 - val_acc: 0.8790\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1887 - acc: 0.9852 - val_loss: 2.7697 - val_acc: 0.7621\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3258 - acc: 0.9730 - val_loss: 1.9963 - val_acc: 0.8387\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2782 - acc: 0.9757 - val_loss: 1.6546 - val_acc: 0.8629\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2224 - acc: 0.9784 - val_loss: 1.4565 - val_acc: 0.8911\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1117 - acc: 0.9906 - val_loss: 1.3605 - val_acc: 0.8952\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3222 - acc: 0.9704 - val_loss: 1.3594 - val_acc: 0.8790\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2916 - acc: 0.9717 - val_loss: 1.4290 - val_acc: 0.8710\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2980 - acc: 0.9771 - val_loss: 1.0720 - val_acc: 0.9153\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2677 - acc: 0.9757 - val_loss: 1.1195 - val_acc: 0.9032\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9825 - val_loss: 1.3931 - val_acc: 0.8831\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2138 - acc: 0.9798 - val_loss: 1.5110 - val_acc: 0.8710\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1839 - acc: 0.9811 - val_loss: 2.5201 - val_acc: 0.7944\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2931 - acc: 0.9784 - val_loss: 2.7126 - val_acc: 0.7823\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2246 - acc: 0.9811 - val_loss: 1.9175 - val_acc: 0.8669\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4165 - acc: 0.9609 - val_loss: 1.5900 - val_acc: 0.8831\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1417 - acc: 0.9865 - val_loss: 1.4819 - val_acc: 0.8911\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3775 - acc: 0.9717 - val_loss: 1.6987 - val_acc: 0.8710\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3909 - acc: 0.9677 - val_loss: 1.8092 - val_acc: 0.8629\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2509 - acc: 0.9784 - val_loss: 1.2351 - val_acc: 0.8992\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1403 - acc: 0.9865 - val_loss: 1.3806 - val_acc: 0.8871\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.0713 - acc: 0.9906 - val_loss: 1.2091 - val_acc: 0.9073\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2588 - acc: 0.9771 - val_loss: 1.6463 - val_acc: 0.8710\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.3086 - acc: 0.975 - 2s 3ms/step - loss: 0.3061 - acc: 0.9757 - val_loss: 1.7672 - val_acc: 0.8669\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4623 - acc: 0.9609 - val_loss: 1.4804 - val_acc: 0.8831\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2009 - acc: 0.9825 - val_loss: 1.3788 - val_acc: 0.8952\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3746 - acc: 0.9730 - val_loss: 1.3851 - val_acc: 0.8871\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3019 - acc: 0.9784 - val_loss: 1.5641 - val_acc: 0.8790\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4735 - acc: 0.9636 - val_loss: 1.0125 - val_acc: 0.9234\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4244 - acc: 0.9663 - val_loss: 1.1090 - val_acc: 0.9032\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2201 - acc: 0.9784 - val_loss: 1.5096 - val_acc: 0.8911\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1535 - acc: 0.9852 - val_loss: 1.8187 - val_acc: 0.8629\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2790 - acc: 0.9744 - val_loss: 1.6693 - val_acc: 0.8750\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3266 - acc: 0.9717 - val_loss: 2.0184 - val_acc: 0.8548\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2476 - acc: 0.9798 - val_loss: 1.4505 - val_acc: 0.9032\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9879 - val_loss: 1.3671 - val_acc: 0.8992\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1710 - acc: 0.9838 - val_loss: 1.8404 - val_acc: 0.8750\n",
      "Epoch 356/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3569 - acc: 0.9690 - val_loss: 1.9177 - val_acc: 0.8589\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1738 - acc: 0.9892 - val_loss: 1.6733 - val_acc: 0.8750\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3717 - acc: 0.9704 - val_loss: 1.7105 - val_acc: 0.8790\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4756 - acc: 0.9677 - val_loss: 1.4388 - val_acc: 0.8911\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5562 - acc: 0.9623 - val_loss: 1.4600 - val_acc: 0.9032\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4517 - acc: 0.9623 - val_loss: 1.4859 - val_acc: 0.8952\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2623 - acc: 0.9784 - val_loss: 1.9000 - val_acc: 0.8629\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4907 - acc: 0.9636 - val_loss: 1.6235 - val_acc: 0.8710\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4513 - acc: 0.9650 - val_loss: 1.6743 - val_acc: 0.8790\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3919 - acc: 0.9730 - val_loss: 2.1117 - val_acc: 0.8548\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3541 - acc: 0.9730 - val_loss: 1.4154 - val_acc: 0.8992\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4277 - acc: 0.9717 - val_loss: 1.6035 - val_acc: 0.8831\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4111 - acc: 0.9690 - val_loss: 1.5269 - val_acc: 0.8911\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3118 - acc: 0.9744 - val_loss: 2.1522 - val_acc: 0.8508\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4184 - acc: 0.9690 - val_loss: 1.6350 - val_acc: 0.8710\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3584 - acc: 0.9771 - val_loss: 1.7477 - val_acc: 0.8790\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8362 - acc: 0.9394 - val_loss: 2.1405 - val_acc: 0.8387\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5880 - acc: 0.9596 - val_loss: 1.5294 - val_acc: 0.8952\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6310 - acc: 0.9569 - val_loss: 2.6266 - val_acc: 0.8185\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6199 - acc: 0.9569 - val_loss: 2.3197 - val_acc: 0.8427\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5802 - acc: 0.9555 - val_loss: 2.1258 - val_acc: 0.8548\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2482 - acc: 0.9811 - val_loss: 1.5644 - val_acc: 0.8911\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4112 - acc: 0.9744 - val_loss: 1.8040 - val_acc: 0.8831\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7243 - acc: 0.9501 - val_loss: 2.2338 - val_acc: 0.8508\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6087 - acc: 0.9582 - val_loss: 2.1660 - val_acc: 0.8387\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4881 - acc: 0.9650 - val_loss: 1.9761 - val_acc: 0.8710\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4455 - acc: 0.9690 - val_loss: 2.3194 - val_acc: 0.8427\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5523 - acc: 0.9636 - val_loss: 2.3493 - val_acc: 0.8468\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5208 - acc: 0.9609 - val_loss: 2.7171 - val_acc: 0.8105\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8485 - acc: 0.9407 - val_loss: 2.6428 - val_acc: 0.8226\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6349 - acc: 0.9569 - val_loss: 2.1848 - val_acc: 0.8589\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1851 - acc: 0.9218 - val_loss: 3.0201 - val_acc: 0.8024\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9384 - acc: 0.9353 - val_loss: 2.2692 - val_acc: 0.8508\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7092 - acc: 0.9542 - val_loss: 2.4338 - val_acc: 0.8427\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2592 - acc: 0.9191 - val_loss: 3.1303 - val_acc: 0.7863\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5289 - acc: 0.9636 - val_loss: 1.8608 - val_acc: 0.8710\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6442 - acc: 0.9569 - val_loss: 2.1513 - val_acc: 0.8629\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6652 - acc: 0.9555 - val_loss: 2.0779 - val_acc: 0.8589\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7058 - acc: 0.9501 - val_loss: 3.3293 - val_acc: 0.7782\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6778 - acc: 0.9555 - val_loss: 2.6088 - val_acc: 0.8306\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7219 - acc: 0.9515 - val_loss: 2.3054 - val_acc: 0.8508\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1896 - acc: 0.9218 - val_loss: 2.2649 - val_acc: 0.8468\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0474 - acc: 0.9326 - val_loss: 2.9557 - val_acc: 0.8065\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6676 - acc: 0.9528 - val_loss: 2.2340 - val_acc: 0.8589\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7682 - acc: 0.9501 - val_loss: 2.2562 - val_acc: 0.8508\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9708 - acc: 0.9340 - val_loss: 2.0392 - val_acc: 0.8629\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7647 - acc: 0.9501 - val_loss: 1.7201 - val_acc: 0.8831\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5306 - acc: 0.9636 - val_loss: 1.9685 - val_acc: 0.8669\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6378 - acc: 0.9582 - val_loss: 2.2684 - val_acc: 0.8548\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7306 - acc: 0.9515 - val_loss: 2.4163 - val_acc: 0.8468\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9282 - acc: 0.9394 - val_loss: 2.6142 - val_acc: 0.8347\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0277 - acc: 0.9299 - val_loss: 2.1927 - val_acc: 0.8589\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4944 - acc: 0.9663 - val_loss: 1.7362 - val_acc: 0.8831\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3054 - acc: 0.9798 - val_loss: 2.0666 - val_acc: 0.8629\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5031 - acc: 0.9677 - val_loss: 2.7067 - val_acc: 0.8185\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6297 - acc: 0.9569 - val_loss: 1.8643 - val_acc: 0.8831\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8412 - acc: 0.9461 - val_loss: 2.0907 - val_acc: 0.8468\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6523 - acc: 0.9582 - val_loss: 2.0541 - val_acc: 0.8669\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5953 - acc: 0.9609 - val_loss: 1.7539 - val_acc: 0.8790\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5711 - acc: 0.9596 - val_loss: 2.6502 - val_acc: 0.8266\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6689 - acc: 0.9569 - val_loss: 2.1232 - val_acc: 0.8629\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8734 - acc: 0.9447 - val_loss: 1.9779 - val_acc: 0.8750\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2028 - acc: 0.9245 - val_loss: 2.0612 - val_acc: 0.8669\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5746 - acc: 0.8949 - val_loss: 2.0190 - val_acc: 0.8710\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9429 - acc: 0.9380 - val_loss: 2.8921 - val_acc: 0.8145\n",
      "Epoch 421/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2442 - acc: 0.9205 - val_loss: 3.0923 - val_acc: 0.7984\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8745 - acc: 0.9434 - val_loss: 2.7404 - val_acc: 0.8145\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9099 - acc: 0.9407 - val_loss: 2.7560 - val_acc: 0.8185\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0301 - acc: 0.9340 - val_loss: 2.6233 - val_acc: 0.8226\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7724 - acc: 0.9474 - val_loss: 2.0702 - val_acc: 0.8629\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5608 - acc: 0.9609 - val_loss: 2.3688 - val_acc: 0.8468\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7467 - acc: 0.9501 - val_loss: 2.0686 - val_acc: 0.8548\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6747 - acc: 0.9569 - val_loss: 1.8268 - val_acc: 0.8790\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3281 - acc: 0.9784 - val_loss: 2.0651 - val_acc: 0.8629\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4034 - acc: 0.9744 - val_loss: 1.8496 - val_acc: 0.8790\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6363 - acc: 0.9569 - val_loss: 2.0166 - val_acc: 0.8710\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4697 - acc: 0.9677 - val_loss: 2.0321 - val_acc: 0.8669\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4887 - acc: 0.9690 - val_loss: 2.1304 - val_acc: 0.8629\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6820 - acc: 0.9555 - val_loss: 2.6414 - val_acc: 0.8266\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0300 - acc: 0.9353 - val_loss: 2.6742 - val_acc: 0.8306\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9250 - acc: 0.9407 - val_loss: 2.5322 - val_acc: 0.8347\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0580 - acc: 0.9340 - val_loss: 2.8974 - val_acc: 0.8105\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6288 - acc: 0.9582 - val_loss: 1.8849 - val_acc: 0.8831\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8139 - acc: 0.9488 - val_loss: 1.8853 - val_acc: 0.8831\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1542 - acc: 0.9245 - val_loss: 2.7910 - val_acc: 0.8226\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0893 - acc: 0.9299 - val_loss: 2.5546 - val_acc: 0.8347\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7594 - acc: 0.9488 - val_loss: 1.9662 - val_acc: 0.8750\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7819 - acc: 0.9447 - val_loss: 1.9469 - val_acc: 0.8790\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4781 - acc: 0.9690 - val_loss: 2.5513 - val_acc: 0.8387\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2436 - acc: 0.9205 - val_loss: 2.7485 - val_acc: 0.8266\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2368 - acc: 0.9205 - val_loss: 2.5383 - val_acc: 0.8387\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2155 - acc: 0.9232 - val_loss: 4.0322 - val_acc: 0.7419\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1444 - acc: 0.9245 - val_loss: 2.9074 - val_acc: 0.8105\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9175 - acc: 0.9420 - val_loss: 2.4719 - val_acc: 0.8468\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7766 - acc: 0.9501 - val_loss: 2.0328 - val_acc: 0.8710\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0857 - acc: 0.9299 - val_loss: 2.5675 - val_acc: 0.8387\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9516 - acc: 0.9394 - val_loss: 2.6729 - val_acc: 0.8266\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5877 - acc: 0.8976 - val_loss: 1.9384 - val_acc: 0.8629\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6870 - acc: 0.9569 - val_loss: 2.1227 - val_acc: 0.8629\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7626 - acc: 0.9501 - val_loss: 3.8323 - val_acc: 0.7621\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6606 - acc: 0.8949 - val_loss: 3.7751 - val_acc: 0.7581\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2203 - acc: 0.9151 - val_loss: 2.7484 - val_acc: 0.8266\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8188 - acc: 0.9461 - val_loss: 2.8726 - val_acc: 0.8185\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9827 - acc: 0.9380 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9065 - acc: 0.9434 - val_loss: 2.0420 - val_acc: 0.8710\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4574 - acc: 0.9704 - val_loss: 2.3260 - val_acc: 0.8508\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8881 - acc: 0.9434 - val_loss: 2.6830 - val_acc: 0.8306\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8037 - acc: 0.9501 - val_loss: 2.6172 - val_acc: 0.8306\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1879 - acc: 0.9245 - val_loss: 3.9607 - val_acc: 0.7500\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7795 - acc: 0.9501 - val_loss: 2.9520 - val_acc: 0.8145\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5742 - acc: 0.8989 - val_loss: 3.2503 - val_acc: 0.7984\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3473 - acc: 0.9151 - val_loss: 2.9818 - val_acc: 0.8105\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1594 - acc: 0.8639 - val_loss: 3.2242 - val_acc: 0.7984\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4521 - acc: 0.9070 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9894 - acc: 0.9367 - val_loss: 2.3867 - val_acc: 0.8468\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0143 - acc: 0.9340 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7461 - acc: 0.9528 - val_loss: 2.1448 - val_acc: 0.8669\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9058 - acc: 0.9407 - val_loss: 2.2747 - val_acc: 0.8589\n",
      "Epoch 474/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7722 - acc: 0.9515 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6894 - acc: 0.9569 - val_loss: 1.8872 - val_acc: 0.8831\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9715 - acc: 0.9353 - val_loss: 2.6823 - val_acc: 0.8306\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8904 - acc: 0.9434 - val_loss: 2.8909 - val_acc: 0.8185\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8608 - acc: 0.9447 - val_loss: 2.6367 - val_acc: 0.8306\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9614 - acc: 0.9380 - val_loss: 2.2414 - val_acc: 0.8548\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9534 - acc: 0.9407 - val_loss: 3.5539 - val_acc: 0.7742\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1143 - acc: 0.9299 - val_loss: 2.5955 - val_acc: 0.8387\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6746 - acc: 0.9569 - val_loss: 3.1593 - val_acc: 0.8024\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2546 - acc: 0.9191 - val_loss: 3.4227 - val_acc: 0.7863\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6101 - acc: 0.8989 - val_loss: 3.2021 - val_acc: 0.7944\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0861 - acc: 0.9326 - val_loss: 3.1210 - val_acc: 0.8065\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0140 - acc: 0.9367 - val_loss: 2.4063 - val_acc: 0.8468\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1639 - acc: 0.9272 - val_loss: 2.2100 - val_acc: 0.8629\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2540 - acc: 0.9205 - val_loss: 3.0471 - val_acc: 0.8024\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1412 - acc: 0.9286 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6755 - acc: 0.8949 - val_loss: 4.5868 - val_acc: 0.7137\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4310 - acc: 0.8491 - val_loss: 3.1817 - val_acc: 0.8024\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0503 - acc: 0.9340 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1581 - acc: 0.9272 - val_loss: 3.1499 - val_acc: 0.8024\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1932 - acc: 0.9232 - val_loss: 2.0419 - val_acc: 0.8710\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4977 - acc: 0.9663 - val_loss: 3.1219 - val_acc: 0.8024\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5204 - acc: 0.9057 - val_loss: 1.9699 - val_acc: 0.8750\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6301 - acc: 0.9609 - val_loss: 1.9501 - val_acc: 0.8790\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9614 - acc: 0.9380 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5865 - acc: 0.9636 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8529 - acc: 0.9447 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6912 - acc: 0.9555 - val_loss: 2.5124 - val_acc: 0.8427\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8852 - acc: 0.9447 - val_loss: 2.2915 - val_acc: 0.8548\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0004 - acc: 0.9367 - val_loss: 2.7801 - val_acc: 0.8226\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4996 - acc: 0.9690 - val_loss: 2.7624 - val_acc: 0.8266\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8307 - acc: 0.9461 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8177 - acc: 0.8854 - val_loss: 4.1145 - val_acc: 0.7419\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3260 - acc: 0.9164 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4037 - acc: 0.9124 - val_loss: 2.8598 - val_acc: 0.8226\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3482 - acc: 0.9151 - val_loss: 3.0549 - val_acc: 0.8105\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0861 - acc: 0.9326 - val_loss: 3.0550 - val_acc: 0.8105\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0991 - acc: 0.9299 - val_loss: 3.3505 - val_acc: 0.7903\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1952 - acc: 0.9259 - val_loss: 2.6315 - val_acc: 0.8347\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0659 - acc: 0.9326 - val_loss: 4.2119 - val_acc: 0.7298\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8075 - acc: 0.8868 - val_loss: 4.6153 - val_acc: 0.7137\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7454 - acc: 0.8895 - val_loss: 2.8140 - val_acc: 0.8185\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7963 - acc: 0.8868 - val_loss: 2.6798 - val_acc: 0.8306\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6644 - acc: 0.9582 - val_loss: 2.3856 - val_acc: 0.8508\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1805 - acc: 0.9259 - val_loss: 2.7881 - val_acc: 0.8266\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9541 - acc: 0.9407 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1743 - acc: 0.9259 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3468 - acc: 0.9164 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1513 - acc: 0.9286 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0126 - acc: 0.9367 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9780 - acc: 0.9394 - val_loss: 2.6778 - val_acc: 0.8306\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2525 - acc: 0.8585 - val_loss: 2.6655 - val_acc: 0.8347\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3777 - acc: 0.9137 - val_loss: 3.1411 - val_acc: 0.8024\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1730 - acc: 0.9272 - val_loss: 3.1411 - val_acc: 0.8024\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2886 - acc: 0.9178 - val_loss: 3.7047 - val_acc: 0.7702\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5787 - acc: 0.9016 - val_loss: 2.9688 - val_acc: 0.8145\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3848 - acc: 0.9137 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3903 - acc: 0.9137 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0244 - acc: 0.9353 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1330 - acc: 0.9286 - val_loss: 4.5522 - val_acc: 0.7177\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5601 - acc: 0.9016 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4120 - acc: 0.9124 - val_loss: 3.0922 - val_acc: 0.8024\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2379 - acc: 0.9218 - val_loss: 2.3778 - val_acc: 0.8508\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9341 - acc: 0.9420 - val_loss: 2.3722 - val_acc: 0.8508\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1964 - acc: 0.9245 - val_loss: 2.7949 - val_acc: 0.8266\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5824 - acc: 0.9003 - val_loss: 3.8888 - val_acc: 0.7581\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6075 - acc: 0.9003 - val_loss: 3.8258 - val_acc: 0.7621\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4851 - acc: 0.9057 - val_loss: 3.0547 - val_acc: 0.8105\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0427 - acc: 0.9353 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8722 - acc: 0.8827 - val_loss: 3.5419 - val_acc: 0.7782\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2485 - acc: 0.9218 - val_loss: 3.6504 - val_acc: 0.7702\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1296 - acc: 0.9299 - val_loss: 3.6504 - val_acc: 0.7702\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8037 - acc: 0.9501 - val_loss: 3.6327 - val_acc: 0.7742\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7375 - acc: 0.8908 - val_loss: 2.9549 - val_acc: 0.8145\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2476 - acc: 0.9218 - val_loss: 2.7648 - val_acc: 0.8266\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2118 - acc: 0.9232 - val_loss: 2.4697 - val_acc: 0.8468\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0043 - acc: 0.9353 - val_loss: 2.0799 - val_acc: 0.8710\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6661 - acc: 0.9582 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3244 - acc: 0.9151 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2858 - acc: 0.9178 - val_loss: 2.1448 - val_acc: 0.8669\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9992 - acc: 0.9380 - val_loss: 2.1448 - val_acc: 0.8669\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4255 - acc: 0.9111 - val_loss: 2.9703 - val_acc: 0.8065\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1837 - acc: 0.9232 - val_loss: 2.6131 - val_acc: 0.8347\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1457 - acc: 0.9286 - val_loss: 2.2302 - val_acc: 0.8589\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1079 - acc: 0.9313 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1513 - acc: 0.9286 - val_loss: 2.2748 - val_acc: 0.8589\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4556 - acc: 0.9097 - val_loss: 3.5086 - val_acc: 0.7782\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7116 - acc: 0.8908 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6475 - acc: 0.8962 - val_loss: 2.7771 - val_acc: 0.8226\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2165 - acc: 0.9245 - val_loss: 2.7771 - val_acc: 0.8226\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4086 - acc: 0.9097 - val_loss: 3.2069 - val_acc: 0.7984\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8905 - acc: 0.8801 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6957 - acc: 0.8949 - val_loss: 4.0194 - val_acc: 0.7460\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1506 - acc: 0.8666 - val_loss: 3.6463 - val_acc: 0.7702\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0204 - acc: 0.8747 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3356 - acc: 0.8518 - val_loss: 3.4357 - val_acc: 0.7823\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1730 - acc: 0.9272 - val_loss: 3.4357 - val_acc: 0.7823\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5670 - acc: 0.9016 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2336 - acc: 0.8598 - val_loss: 4.0951 - val_acc: 0.7460\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1723 - acc: 0.8652 - val_loss: 3.9377 - val_acc: 0.7540\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1324 - acc: 0.8666 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8681 - acc: 0.8841 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9768 - acc: 0.8774 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0398 - acc: 0.8733 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8138 - acc: 0.8868 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6445 - acc: 0.8962 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7377 - acc: 0.8908 - val_loss: 3.3629 - val_acc: 0.7903\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2599 - acc: 0.9218 - val_loss: 3.4443 - val_acc: 0.7863\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1685 - acc: 0.8652 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9333 - acc: 0.8801 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8424 - acc: 0.8854 - val_loss: 4.3420 - val_acc: 0.7298\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5300 - acc: 0.8396 - val_loss: 5.9793 - val_acc: 0.6290\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4147 - acc: 0.8491 - val_loss: 4.2406 - val_acc: 0.7339\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1940 - acc: 0.8639 - val_loss: 4.2406 - val_acc: 0.7339\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2769 - acc: 0.7951 - val_loss: 4.9707 - val_acc: 0.6895\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1314 - acc: 0.8666 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9762 - acc: 0.8760 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8899 - acc: 0.8827 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 592/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3412 - acc: 0.8544 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6784 - acc: 0.8329 - val_loss: 4.4225 - val_acc: 0.7218\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6280 - acc: 0.8369 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2395 - acc: 0.8598 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2571 - acc: 0.7951 - val_loss: 4.7682 - val_acc: 0.7016\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5625 - acc: 0.7790 - val_loss: 4.6640 - val_acc: 0.7097\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6775 - acc: 0.7709 - val_loss: 4.6195 - val_acc: 0.7097\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2142 - acc: 0.8005 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9847 - acc: 0.8760 - val_loss: 2.7070 - val_acc: 0.8306\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1582 - acc: 0.8019 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1661 - acc: 0.8612 - val_loss: 3.4609 - val_acc: 0.7823\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3500 - acc: 0.8531 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0718 - acc: 0.7453 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1064 - acc: 0.8073 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8022 - acc: 0.8261 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4134 - acc: 0.8491 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5979 - acc: 0.8356 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2948 - acc: 0.8571 - val_loss: 3.4334 - val_acc: 0.7863\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9593 - acc: 0.8774 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1510 - acc: 0.8666 - val_loss: 3.4784 - val_acc: 0.7823\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8452 - acc: 0.8841 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9797 - acc: 0.8760 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1940 - acc: 0.8639 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9110 - acc: 0.8801 - val_loss: 2.8000 - val_acc: 0.8226\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6700 - acc: 0.8962 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6813 - acc: 0.8949 - val_loss: 3.3149 - val_acc: 0.7944\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9899 - acc: 0.8760 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8299 - acc: 0.8854 - val_loss: 3.2520 - val_acc: 0.7984\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1071 - acc: 0.8693 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5448 - acc: 0.9030 - val_loss: 3.1148 - val_acc: 0.8065\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3200 - acc: 0.8558 - val_loss: 2.9529 - val_acc: 0.8145\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8247 - acc: 0.8868 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7805 - acc: 0.8881 - val_loss: 3.4447 - val_acc: 0.7863\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0732 - acc: 0.8693 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8247 - acc: 0.8868 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8776 - acc: 0.8827 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6726 - acc: 0.8962 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7991 - acc: 0.8881 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0593 - acc: 0.8706 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6207 - acc: 0.8989 - val_loss: 2.9958 - val_acc: 0.8105\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4989 - acc: 0.9070 - val_loss: 2.9951 - val_acc: 0.8105\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5415 - acc: 0.9043 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2359 - acc: 0.9232 - val_loss: 2.9438 - val_acc: 0.8145\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6006 - acc: 0.9003 - val_loss: 3.5765 - val_acc: 0.7782\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5859 - acc: 0.9016 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4120 - acc: 0.9124 - val_loss: 3.0554 - val_acc: 0.8105\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4337 - acc: 0.9111 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4488 - acc: 0.9084 - val_loss: 3.3813 - val_acc: 0.7903\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6940 - acc: 0.8949 - val_loss: 3.3826 - val_acc: 0.7863\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6823 - acc: 0.8949 - val_loss: 4.0946 - val_acc: 0.7460\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9841 - acc: 0.8760 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2157 - acc: 0.8625 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6620 - acc: 0.8962 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2832 - acc: 0.9191 - val_loss: 2.9931 - val_acc: 0.8105\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0299 - acc: 0.8100 - val_loss: 5.7195 - val_acc: 0.6452\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1484 - acc: 0.8032 - val_loss: 5.7193 - val_acc: 0.6452\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.8441 - acc: 0.6995 - val_loss: 5.7193 - val_acc: 0.6452\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2359 - acc: 0.7372 - val_loss: 5.2319 - val_acc: 0.6734\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1100 - acc: 0.7439 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3641 - acc: 0.7291 - val_loss: 5.2644 - val_acc: 0.6734\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.7733 - acc: 0.7022 - val_loss: 4.7253 - val_acc: 0.7056\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0846 - acc: 0.8086 - val_loss: 4.7253 - val_acc: 0.7056\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2446 - acc: 0.7978 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9325 - acc: 0.8181 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3060 - acc: 0.8558 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8456 - acc: 0.8235 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3552 - acc: 0.8531 - val_loss: 3.9007 - val_acc: 0.7581\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1723 - acc: 0.8652 - val_loss: 3.9331 - val_acc: 0.7540\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7813 - acc: 0.8895 - val_loss: 3.9418 - val_acc: 0.7540\n",
      "Epoch 661/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3458 - acc: 0.7911 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 4.3088 - val_acc: 0.7298\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3411 - acc: 0.8544 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2203 - acc: 0.8612 - val_loss: 4.8884 - val_acc: 0.6895\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8221 - acc: 0.8854 - val_loss: 4.7207 - val_acc: 0.7056\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2157 - acc: 0.8625 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9116 - acc: 0.8814 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3128 - acc: 0.8531 - val_loss: 4.5454 - val_acc: 0.7097\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4114 - acc: 0.8504 - val_loss: 3.3589 - val_acc: 0.7903\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8040 - acc: 0.8868 - val_loss: 3.9350 - val_acc: 0.7540\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3678 - acc: 0.8531 - val_loss: 3.9350 - val_acc: 0.7540\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9479 - acc: 0.8154 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3562 - acc: 0.8518 - val_loss: 3.7810 - val_acc: 0.7621\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 2.1900 - acc: 0.864 - 2s 3ms/step - loss: 2.2157 - acc: 0.8625 - val_loss: 3.7823 - val_acc: 0.7621\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8247 - acc: 0.8868 - val_loss: 3.7823 - val_acc: 0.7621\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6098 - acc: 0.8369 - val_loss: 4.9394 - val_acc: 0.6935\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8178 - acc: 0.8248 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1800 - acc: 0.8019 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1288 - acc: 0.8679 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2426 - acc: 0.8598 - val_loss: 3.7862 - val_acc: 0.7621\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4112 - acc: 0.8504 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4764 - acc: 0.8464 - val_loss: 3.6729 - val_acc: 0.7702\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2374 - acc: 0.8612 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1505 - acc: 0.8666 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2157 - acc: 0.8625 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1702 - acc: 0.8652 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3678 - acc: 0.8531 - val_loss: 3.3810 - val_acc: 0.7903\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2157 - acc: 0.8625 - val_loss: 3.3810 - val_acc: 0.7903\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1466 - acc: 0.8666 - val_loss: 2.7931 - val_acc: 0.8266\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6384 - acc: 0.8976 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6727 - acc: 0.8962 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0078 - acc: 0.8127 - val_loss: 5.2467 - val_acc: 0.6694\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4338 - acc: 0.8477 - val_loss: 3.1659 - val_acc: 0.8024\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8464 - acc: 0.8854 - val_loss: 3.0812 - val_acc: 0.8065\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8332 - acc: 0.8854 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8578 - acc: 0.8841 - val_loss: 3.4447 - val_acc: 0.7863\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1288 - acc: 0.8679 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5540 - acc: 0.8410 - val_loss: 4.1627 - val_acc: 0.7379\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5392 - acc: 0.8410 - val_loss: 3.1248 - val_acc: 0.8024\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6287 - acc: 0.8989 - val_loss: 3.7447 - val_acc: 0.7661\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8899 - acc: 0.8827 - val_loss: 3.7237 - val_acc: 0.7661\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8544 - acc: 0.8841 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3247 - acc: 0.8558 - val_loss: 4.7762 - val_acc: 0.7016\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3173 - acc: 0.8558 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0636 - acc: 0.8720 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8465 - acc: 0.8854 - val_loss: 3.5761 - val_acc: 0.7782\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2809 - acc: 0.8585 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4120 - acc: 0.8504 - val_loss: 3.8833 - val_acc: 0.7581\n",
      "Epoch 710/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4409 - acc: 0.8477 - val_loss: 2.9588 - val_acc: 0.8145\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9334 - acc: 0.8801 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6648 - acc: 0.8962 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8436 - acc: 0.8854 - val_loss: 3.3540 - val_acc: 0.7903\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7738 - acc: 0.8275 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8891 - acc: 0.8208 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5416 - acc: 0.8423 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6397 - acc: 0.8976 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6528 - acc: 0.8962 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3685 - acc: 0.9151 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4337 - acc: 0.9111 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8464 - acc: 0.8854 - val_loss: 3.5572 - val_acc: 0.7782\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3569 - acc: 0.8531 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9556 - acc: 0.8787 - val_loss: 3.2600 - val_acc: 0.7944\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3184 - acc: 0.8558 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2810 - acc: 0.8585 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6001 - acc: 0.8383 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6066 - acc: 0.8383 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6505 - acc: 0.8342 - val_loss: 4.8094 - val_acc: 0.7016\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6494 - acc: 0.7736 - val_loss: 4.8094 - val_acc: 0.7016\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3233 - acc: 0.7925 - val_loss: 3.4457 - val_acc: 0.7863\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1047 - acc: 0.8693 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1669 - acc: 0.8032 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9431 - acc: 0.8167 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4334 - acc: 0.8491 - val_loss: 3.9648 - val_acc: 0.7540\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7797 - acc: 0.7655 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5788 - acc: 0.8383 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4650 - acc: 0.8464 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1092 - acc: 0.8059 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9760 - acc: 0.8154 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6071 - acc: 0.7749 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3262 - acc: 0.8544 - val_loss: 2.7399 - val_acc: 0.8266\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0596 - acc: 0.8720 - val_loss: 3.3147 - val_acc: 0.7944\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2809 - acc: 0.8585 - val_loss: 3.1862 - val_acc: 0.8024\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3243 - acc: 0.8558 - val_loss: 3.3313 - val_acc: 0.7903\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2797 - acc: 0.8585 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1071 - acc: 0.8693 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6944 - acc: 0.8949 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7161 - acc: 0.8935 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8458 - acc: 0.8235 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2884 - acc: 0.8571 - val_loss: 2.7308 - val_acc: 0.8306\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5640 - acc: 0.9030 - val_loss: 2.6655 - val_acc: 0.8347\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3468 - acc: 0.9164 - val_loss: 2.6655 - val_acc: 0.8347\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3685 - acc: 0.9151 - val_loss: 2.6655 - val_acc: 0.8347\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6868 - acc: 0.8949 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5644 - acc: 0.9030 - val_loss: 3.2005 - val_acc: 0.7984\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5206 - acc: 0.9057 - val_loss: 3.1862 - val_acc: 0.8024\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5640 - acc: 0.9030 - val_loss: 3.1862 - val_acc: 0.8024\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5829 - acc: 0.8396 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5633 - acc: 0.8410 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7332 - acc: 0.8908 - val_loss: 2.9268 - val_acc: 0.8185\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8548 - acc: 0.8841 - val_loss: 3.9452 - val_acc: 0.7540\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0636 - acc: 0.8720 - val_loss: 3.9452 - val_acc: 0.7540\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7179 - acc: 0.8302 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6670 - acc: 0.8342 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7400 - acc: 0.8288 - val_loss: 3.3557 - val_acc: 0.7903\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0395 - acc: 0.8113 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7370 - acc: 0.8302 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1684 - acc: 0.8652 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8464 - acc: 0.8854 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8030 - acc: 0.8881 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0702 - acc: 0.8706 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3678 - acc: 0.8531 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7816 - acc: 0.8881 - val_loss: 3.5139 - val_acc: 0.7782\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4691 - acc: 0.8464 - val_loss: 4.7445 - val_acc: 0.7056\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8318 - acc: 0.8235 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7153 - acc: 0.8315 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3442 - acc: 0.7925 - val_loss: 5.5244 - val_acc: 0.6573\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 5.5244 - val_acc: 0.6573\n",
      "Epoch 781/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2150 - acc: 0.8005 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8459 - acc: 0.8235 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6518 - acc: 0.8342 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0854 - acc: 0.8706 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4311 - acc: 0.8491 - val_loss: 4.7065 - val_acc: 0.7056\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8026 - acc: 0.8261 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0680 - acc: 0.8706 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0172 - acc: 0.8747 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0366 - acc: 0.8733 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6292 - acc: 0.8989 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6883 - acc: 0.8949 - val_loss: 3.4387 - val_acc: 0.7863\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5119 - acc: 0.8437 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5495 - acc: 0.8410 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6719 - acc: 0.8342 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3143 - acc: 0.7925 - val_loss: 4.2249 - val_acc: 0.7379\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9194 - acc: 0.8181 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9660 - acc: 0.7520 - val_loss: 6.3693 - val_acc: 0.6048\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.0205 - acc: 0.6860 - val_loss: 5.5244 - val_acc: 0.6573\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9752 - acc: 0.7534 - val_loss: 5.5244 - val_acc: 0.6573\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9218 - acc: 0.7561 - val_loss: 4.6271 - val_acc: 0.7097\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8361 - acc: 0.8235 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8022 - acc: 0.8261 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8239 - acc: 0.8248 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5633 - acc: 0.8410 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4358 - acc: 0.7237 - val_loss: 5.6440 - val_acc: 0.6492\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7155 - acc: 0.8315 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6219 - acc: 0.8369 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8022 - acc: 0.8261 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5202 - acc: 0.8437 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9325 - acc: 0.8181 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8996 - acc: 0.7574 - val_loss: 5.6543 - val_acc: 0.6492\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.0278 - acc: 0.6873 - val_loss: 5.7843 - val_acc: 0.6411\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8842 - acc: 0.7588 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9325 - acc: 0.8181 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6062 - acc: 0.7763 - val_loss: 5.5894 - val_acc: 0.6532\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8716 - acc: 0.7588 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3912 - acc: 0.7884 - val_loss: 5.1997 - val_acc: 0.6774\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0838 - acc: 0.7466 - val_loss: 5.1997 - val_acc: 0.6774\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4744 - acc: 0.7844 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9682 - acc: 0.8154 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9108 - acc: 0.8194 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6284 - acc: 0.8369 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8022 - acc: 0.8261 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.3873 - acc: 0.6658 - val_loss: 6.8892 - val_acc: 0.5726\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7506 - acc: 0.8288 - val_loss: 3.2507 - val_acc: 0.7984\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3656 - acc: 0.8531 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0854 - acc: 0.8706 - val_loss: 3.6329 - val_acc: 0.7742\n",
      "Epoch 828/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9116 - acc: 0.8814 - val_loss: 3.6289 - val_acc: 0.7742\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3895 - acc: 0.8518 - val_loss: 3.6289 - val_acc: 0.7742\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1723 - acc: 0.8652 - val_loss: 3.6289 - val_acc: 0.7742\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7353 - acc: 0.8302 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0101 - acc: 0.8127 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7588 - acc: 0.8288 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1932 - acc: 0.8019 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8022 - acc: 0.8261 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2890 - acc: 0.8571 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4764 - acc: 0.8464 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9985 - acc: 0.8760 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1505 - acc: 0.8666 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7395 - acc: 0.8288 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4104 - acc: 0.7884 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3453 - acc: 0.7925 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4756 - acc: 0.7844 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4322 - acc: 0.7871 - val_loss: 4.4274 - val_acc: 0.7218\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4322 - acc: 0.7871 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0848 - acc: 0.8086 - val_loss: 4.2917 - val_acc: 0.7339\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1072 - acc: 0.8059 - val_loss: 4.8094 - val_acc: 0.7016\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7225 - acc: 0.7682 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8014 - acc: 0.7642 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9810 - acc: 0.7520 - val_loss: 5.5894 - val_acc: 0.6532\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4973 - acc: 0.7830 - val_loss: 5.5772 - val_acc: 0.6532\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4699 - acc: 0.8464 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0788 - acc: 0.8073 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0213 - acc: 0.8733 - val_loss: 3.8633 - val_acc: 0.7581\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8247 - acc: 0.8868 - val_loss: 3.8633 - val_acc: 0.7581\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 3.8633 - val_acc: 0.7581\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9985 - acc: 0.8760 - val_loss: 3.8633 - val_acc: 0.7581\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0419 - acc: 0.8733 - val_loss: 3.9359 - val_acc: 0.7540\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9660 - acc: 0.8774 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9185 - acc: 0.8801 - val_loss: 3.3552 - val_acc: 0.7903\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8464 - acc: 0.8854 - val_loss: 3.3552 - val_acc: 0.7903\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6726 - acc: 0.8962 - val_loss: 3.3552 - val_acc: 0.7903\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8030 - acc: 0.8881 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7595 - acc: 0.8908 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1313 - acc: 0.8666 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1266 - acc: 0.7426 - val_loss: 5.9793 - val_acc: 0.6290\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9535 - acc: 0.7547 - val_loss: 5.3294 - val_acc: 0.6694\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3288 - acc: 0.7305 - val_loss: 5.5894 - val_acc: 0.6532\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7638 - acc: 0.7655 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4360 - acc: 0.8477 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2597 - acc: 0.8598 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2375 - acc: 0.8612 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5198 - acc: 0.8437 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4547 - acc: 0.8477 - val_loss: 4.4195 - val_acc: 0.7258\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3257 - acc: 0.8544 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0524 - acc: 0.8720 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9334 - acc: 0.8801 - val_loss: 2.8597 - val_acc: 0.8226\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1524 - acc: 0.8652 - val_loss: 4.2183 - val_acc: 0.7379\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8449 - acc: 0.7615 - val_loss: 4.2183 - val_acc: 0.7379\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2702 - acc: 0.7965 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3197 - acc: 0.8544 - val_loss: 3.4145 - val_acc: 0.7863\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9768 - acc: 0.8774 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0202 - acc: 0.8747 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0202 - acc: 0.8747 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3743 - acc: 0.8518 - val_loss: 2.8597 - val_acc: 0.8226\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9333 - acc: 0.8801 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8681 - acc: 0.8841 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1288 - acc: 0.8679 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8899 - acc: 0.8827 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8681 - acc: 0.8841 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8462 - acc: 0.8235 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1180 - acc: 0.8059 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2666 - acc: 0.7965 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9430 - acc: 0.8167 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4104 - acc: 0.7884 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2931 - acc: 0.7951 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5408 - acc: 0.7803 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3018 - acc: 0.7951 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6179 - acc: 0.7749 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 901/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4973 - acc: 0.7830 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7427 - acc: 0.7668 - val_loss: 5.0694 - val_acc: 0.6855\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5617 - acc: 0.7170 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0944 - acc: 0.7453 - val_loss: 4.8911 - val_acc: 0.6935\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.8911 - val_acc: 0.6935\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.8659 - acc: 0.6981 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.8659 - acc: 0.6981 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.7593 - acc: 0.6415 - val_loss: 6.1743 - val_acc: 0.6169\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.9704 - acc: 0.6900 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0397 - acc: 0.8113 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0026 - acc: 0.8127 - val_loss: 4.8117 - val_acc: 0.7016\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9528 - acc: 0.7534 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8449 - acc: 0.7615 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5776 - acc: 0.7143 - val_loss: 4.7445 - val_acc: 0.7056\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4314 - acc: 0.7251 - val_loss: 4.7445 - val_acc: 0.7056\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.7603 - acc: 0.7035 - val_loss: 5.1064 - val_acc: 0.6815\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2849 - acc: 0.7332 - val_loss: 5.0044 - val_acc: 0.6895\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2359 - acc: 0.7372 - val_loss: 5.0694 - val_acc: 0.6855\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8717 - acc: 0.7588 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7363 - acc: 0.7682 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2584 - acc: 0.7978 - val_loss: 3.7105 - val_acc: 0.7661\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8352 - acc: 0.7615 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2793 - acc: 0.7345 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3445 - acc: 0.7305 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2793 - acc: 0.7345 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9535 - acc: 0.7547 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1492 - acc: 0.7426 - val_loss: 5.3944 - val_acc: 0.6653\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3992 - acc: 0.7264 - val_loss: 5.1671 - val_acc: 0.6774\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2793 - acc: 0.7345 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3175 - acc: 0.7318 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4104 - acc: 0.7884 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7363 - acc: 0.7682 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5191 - acc: 0.7817 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4104 - acc: 0.7884 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 3.7046 - val_acc: 0.7702\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1498 - acc: 0.8046 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4545 - acc: 0.7857 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5625 - acc: 0.7790 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1063 - acc: 0.8073 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3236 - acc: 0.7938 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6277 - acc: 0.7749 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2367 - acc: 0.7992 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6130 - acc: 0.7749 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3018 - acc: 0.7951 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4539 - acc: 0.7857 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 946/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5842 - acc: 0.7776 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0724 - acc: 0.7466 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0397 - acc: 0.8113 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2575 - acc: 0.7978 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7146 - acc: 0.7695 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8232 - acc: 0.7628 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6059 - acc: 0.7763 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6059 - acc: 0.7763 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9101 - acc: 0.7574 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2997 - acc: 0.7951 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9977 - acc: 0.8140 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3018 - acc: 0.7951 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7588 - acc: 0.8288 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4764 - acc: 0.8464 - val_loss: 3.8347 - val_acc: 0.7621\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7591 - acc: 0.8288 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0774 - acc: 0.8086 - val_loss: 5.3294 - val_acc: 0.6694\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8496 - acc: 0.7601 - val_loss: 4.4845 - val_acc: 0.7218\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0121 - acc: 0.7507 - val_loss: 5.1344 - val_acc: 0.6815\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4966 - acc: 0.7210 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8053 - acc: 0.7628 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4744 - acc: 0.7844 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3236 - acc: 0.7938 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8040 - acc: 0.7628 - val_loss: 5.2644 - val_acc: 0.6734\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9101 - acc: 0.7574 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0622 - acc: 0.7480 - val_loss: 4.8094 - val_acc: 0.7016\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9535 - acc: 0.7547 - val_loss: 5.1344 - val_acc: 0.6815\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7930 - acc: 0.7642 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2367 - acc: 0.7992 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2584 - acc: 0.7978 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3240 - acc: 0.7938 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8891 - acc: 0.8208 - val_loss: 3.8664 - val_acc: 0.7581\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2584 - acc: 0.7978 - val_loss: 3.8408 - val_acc: 0.7581\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7370 - acc: 0.8302 - val_loss: 3.8408 - val_acc: 0.7581\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2584 - acc: 0.7978 - val_loss: 3.8408 - val_acc: 0.7581\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8674 - acc: 0.8221 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0883 - acc: 0.8073 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8825 - acc: 0.8208 - val_loss: 4.9394 - val_acc: 0.6935\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9626 - acc: 0.7520 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7370 - acc: 0.8302 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0200 - acc: 0.8127 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6059 - acc: 0.7763 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4756 - acc: 0.7844 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7211 - acc: 0.7668 - val_loss: 4.7444 - val_acc: 0.7056\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4756 - acc: 0.7844 - val_loss: 4.7444 - val_acc: 0.7056\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8014 - acc: 0.7642 - val_loss: 4.7444 - val_acc: 0.7056\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5408 - acc: 0.7803 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4539 - acc: 0.7857 - val_loss: 4.6795 - val_acc: 0.7097\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7363 - acc: 0.7682 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7647 - acc: 0.7655 - val_loss: 4.9901 - val_acc: 0.6895\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6921 - acc: 0.7089 - val_loss: 4.9901 - val_acc: 0.6895\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2793 - acc: 0.7345 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2359 - acc: 0.7372 - val_loss: 5.1994 - val_acc: 0.6774\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2359 - acc: 0.7372 - val_loss: 5.0611 - val_acc: 0.6855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, \n",
    "                    epochs=1000,  \n",
    "                    validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be716003c8>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只看前面的结果：效果略有提升，但已经不明显了。到后面的epoch已经开始“梯度消失”了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化6："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后的尝试：多加一个全连接Dense层看看效果。\n",
    "\n",
    "但理论上Dense的作用只起“特征汇聚”，它不负责提取更多的特征！因此预计效果的提升很有限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same', input_shape=train_x_norm.shape[1:]))\n",
    "model.add(layers.Conv1D(64, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(128, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(256, 11, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(512, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Conv1D(512, 11, activation='relu', padding='same'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))   # 多加一个全连接层\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(99, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1000\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 4.7511 - acc: 0.0067 - val_loss: 4.5987 - val_acc: 0.0040\n",
      "Epoch 2/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5954 - acc: 0.0135 - val_loss: 4.6020 - val_acc: 0.0040\n",
      "Epoch 3/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5963 - acc: 0.0067 - val_loss: 4.6039 - val_acc: 0.0040\n",
      "Epoch 4/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5945 - acc: 0.0121 - val_loss: 4.6087 - val_acc: 0.0040\n",
      "Epoch 5/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5963 - acc: 0.0094 - val_loss: 4.6122 - val_acc: 0.0040\n",
      "Epoch 6/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5936 - acc: 0.0135 - val_loss: 4.6158 - val_acc: 0.0040\n",
      "Epoch 7/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5991 - acc: 0.0135 - val_loss: 4.6200 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5908 - acc: 0.0148 - val_loss: 4.6403 - val_acc: 0.0040\n",
      "Epoch 9/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5886 - acc: 0.0094 - val_loss: 4.6331 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5929 - acc: 0.0162 - val_loss: 4.6359 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5880 - acc: 0.0189 - val_loss: 4.6326 - val_acc: 0.0121\n",
      "Epoch 12/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5635 - acc: 0.0202 - val_loss: 4.6196 - val_acc: 0.0121\n",
      "Epoch 13/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5512 - acc: 0.0162 - val_loss: 4.5813 - val_acc: 0.0121\n",
      "Epoch 14/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4502 - acc: 0.0189 - val_loss: 4.5009 - val_acc: 0.0121\n",
      "Epoch 15/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3590 - acc: 0.0256 - val_loss: 4.3930 - val_acc: 0.0202\n",
      "Epoch 16/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3141 - acc: 0.0216 - val_loss: 4.2951 - val_acc: 0.0161\n",
      "Epoch 17/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2009 - acc: 0.0310 - val_loss: 4.2532 - val_acc: 0.0121\n",
      "Epoch 18/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2068 - acc: 0.0094 - val_loss: 4.2173 - val_acc: 0.0121\n",
      "Epoch 19/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1507 - acc: 0.0256 - val_loss: 4.1683 - val_acc: 0.0121\n",
      "Epoch 20/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0869 - acc: 0.0283 - val_loss: 4.1203 - val_acc: 0.0121\n",
      "Epoch 21/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0769 - acc: 0.0283 - val_loss: 4.1139 - val_acc: 0.0121\n",
      "Epoch 22/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9879 - acc: 0.0364 - val_loss: 4.0348 - val_acc: 0.0121\n",
      "Epoch 23/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9533 - acc: 0.0202 - val_loss: 4.1213 - val_acc: 0.0282\n",
      "Epoch 24/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9006 - acc: 0.0404 - val_loss: 4.1953 - val_acc: 0.0202\n",
      "Epoch 25/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7949 - acc: 0.0323 - val_loss: 4.0918 - val_acc: 0.0161\n",
      "Epoch 26/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8278 - acc: 0.0499 - val_loss: 4.2960 - val_acc: 0.0121\n",
      "Epoch 27/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7529 - acc: 0.0445 - val_loss: 3.8803 - val_acc: 0.0363\n",
      "Epoch 28/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7364 - acc: 0.0404 - val_loss: 3.7703 - val_acc: 0.0363\n",
      "Epoch 29/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6088 - acc: 0.0809 - val_loss: 3.9177 - val_acc: 0.0363\n",
      "Epoch 30/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6082 - acc: 0.0647 - val_loss: 3.8809 - val_acc: 0.0202\n",
      "Epoch 31/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5594 - acc: 0.0499 - val_loss: 3.6568 - val_acc: 0.0363\n",
      "Epoch 32/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5594 - acc: 0.0593 - val_loss: 3.6613 - val_acc: 0.0323\n",
      "Epoch 33/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4491 - acc: 0.0768 - val_loss: 3.5382 - val_acc: 0.0444\n",
      "Epoch 34/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4715 - acc: 0.0647 - val_loss: 3.6576 - val_acc: 0.0484\n",
      "Epoch 35/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4382 - acc: 0.0795 - val_loss: 3.6975 - val_acc: 0.0524\n",
      "Epoch 36/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3873 - acc: 0.0795 - val_loss: 3.6043 - val_acc: 0.0403\n",
      "Epoch 37/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3520 - acc: 0.0728 - val_loss: 3.4542 - val_acc: 0.0403\n",
      "Epoch 38/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3078 - acc: 0.0943 - val_loss: 3.3621 - val_acc: 0.0605\n",
      "Epoch 39/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2112 - acc: 0.1159 - val_loss: 3.6079 - val_acc: 0.0685\n",
      "Epoch 40/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2266 - acc: 0.1105 - val_loss: 3.4292 - val_acc: 0.0847\n",
      "Epoch 41/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1094 - acc: 0.1348 - val_loss: 3.2659 - val_acc: 0.0685\n",
      "Epoch 42/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0984 - acc: 0.1280 - val_loss: 3.5261 - val_acc: 0.0766\n",
      "Epoch 43/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1048 - acc: 0.1469 - val_loss: 3.4421 - val_acc: 0.0766\n",
      "Epoch 44/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9801 - acc: 0.1294 - val_loss: 3.3585 - val_acc: 0.1089\n",
      "Epoch 45/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9160 - acc: 0.1550 - val_loss: 3.0688 - val_acc: 0.1210\n",
      "Epoch 46/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8201 - acc: 0.1739 - val_loss: 2.9251 - val_acc: 0.1452\n",
      "Epoch 47/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8322 - acc: 0.1739 - val_loss: 3.0374 - val_acc: 0.1935\n",
      "Epoch 48/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7790 - acc: 0.1725 - val_loss: 2.9994 - val_acc: 0.1532\n",
      "Epoch 49/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7644 - acc: 0.1846 - val_loss: 2.9986 - val_acc: 0.1492\n",
      "Epoch 50/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6320 - acc: 0.2075 - val_loss: 2.9103 - val_acc: 0.1694\n",
      "Epoch 51/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5362 - acc: 0.2089 - val_loss: 2.8031 - val_acc: 0.1653\n",
      "Epoch 52/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5211 - acc: 0.2439 - val_loss: 2.8902 - val_acc: 0.1492\n",
      "Epoch 53/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5266 - acc: 0.2453 - val_loss: 2.8837 - val_acc: 0.1613\n",
      "Epoch 54/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4792 - acc: 0.2547 - val_loss: 2.6516 - val_acc: 0.2258\n",
      "Epoch 55/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4174 - acc: 0.2412 - val_loss: 2.5014 - val_acc: 0.2742\n",
      "Epoch 56/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3481 - acc: 0.2561 - val_loss: 2.4515 - val_acc: 0.2460\n",
      "Epoch 57/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2916 - acc: 0.2884 - val_loss: 2.4948 - val_acc: 0.2944\n",
      "Epoch 58/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2137 - acc: 0.3046 - val_loss: 2.5613 - val_acc: 0.2661\n",
      "Epoch 59/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1117 - acc: 0.3046 - val_loss: 2.5463 - val_acc: 0.2742\n",
      "Epoch 60/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1145 - acc: 0.3275 - val_loss: 2.2843 - val_acc: 0.3589\n",
      "Epoch 61/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0828 - acc: 0.3450 - val_loss: 2.1834 - val_acc: 0.3710\n",
      "Epoch 62/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0178 - acc: 0.3288 - val_loss: 2.3784 - val_acc: 0.2984\n",
      "Epoch 63/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0247 - acc: 0.3693 - val_loss: 2.3585 - val_acc: 0.2742\n",
      "Epoch 64/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9407 - acc: 0.3598 - val_loss: 2.3551 - val_acc: 0.3468\n",
      "Epoch 65/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7971 - acc: 0.3868 - val_loss: 2.0135 - val_acc: 0.3750\n",
      "Epoch 66/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8592 - acc: 0.3935 - val_loss: 2.0217 - val_acc: 0.4032\n",
      "Epoch 67/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7217 - acc: 0.4569 - val_loss: 2.1175 - val_acc: 0.4234\n",
      "Epoch 68/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8038 - acc: 0.4137 - val_loss: 2.4029 - val_acc: 0.3629\n",
      "Epoch 69/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7496 - acc: 0.4555 - val_loss: 1.7542 - val_acc: 0.4879\n",
      "Epoch 70/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5860 - acc: 0.4784 - val_loss: 1.7271 - val_acc: 0.4798\n",
      "Epoch 71/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6410 - acc: 0.4757 - val_loss: 2.7439 - val_acc: 0.3790\n",
      "Epoch 72/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6222 - acc: 0.4933 - val_loss: 2.0123 - val_acc: 0.4476\n",
      "Epoch 73/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4679 - acc: 0.5377 - val_loss: 1.8774 - val_acc: 0.4597\n",
      "Epoch 74/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4830 - acc: 0.5054 - val_loss: 1.6152 - val_acc: 0.5242\n",
      "Epoch 75/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4649 - acc: 0.5081 - val_loss: 2.4736 - val_acc: 0.3952\n",
      "Epoch 76/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3694 - acc: 0.5350 - val_loss: 1.5882 - val_acc: 0.5645\n",
      "Epoch 77/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2987 - acc: 0.5580 - val_loss: 1.8457 - val_acc: 0.5202\n",
      "Epoch 78/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3040 - acc: 0.5526 - val_loss: 1.5012 - val_acc: 0.5726\n",
      "Epoch 79/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2876 - acc: 0.5836 - val_loss: 1.9247 - val_acc: 0.4839\n",
      "Epoch 80/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1588 - acc: 0.5984 - val_loss: 1.5455 - val_acc: 0.5766\n",
      "Epoch 81/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2332 - acc: 0.6132 - val_loss: 1.5690 - val_acc: 0.5565\n",
      "Epoch 82/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1622 - acc: 0.6388 - val_loss: 1.2691 - val_acc: 0.6573\n",
      "Epoch 83/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1656 - acc: 0.5970 - val_loss: 1.7678 - val_acc: 0.6048\n",
      "Epoch 84/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0376 - acc: 0.6509 - val_loss: 1.3035 - val_acc: 0.6694\n",
      "Epoch 85/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0744 - acc: 0.6644 - val_loss: 1.2996 - val_acc: 0.6411\n",
      "Epoch 86/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0388 - acc: 0.6429 - val_loss: 1.8038 - val_acc: 0.5323\n",
      "Epoch 87/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0190 - acc: 0.6617 - val_loss: 1.5094 - val_acc: 0.5968\n",
      "Epoch 88/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9800 - acc: 0.6765 - val_loss: 1.7588 - val_acc: 0.5645\n",
      "Epoch 89/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9162 - acc: 0.6927 - val_loss: 1.2629 - val_acc: 0.6532\n",
      "Epoch 90/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8821 - acc: 0.6927 - val_loss: 1.0389 - val_acc: 0.7016\n",
      "Epoch 91/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9745 - acc: 0.6900 - val_loss: 1.6248 - val_acc: 0.5927\n",
      "Epoch 92/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9461 - acc: 0.6927 - val_loss: 1.5038 - val_acc: 0.6129\n",
      "Epoch 93/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9065 - acc: 0.6981 - val_loss: 1.5546 - val_acc: 0.6129\n",
      "Epoch 94/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7678 - acc: 0.7507 - val_loss: 1.2459 - val_acc: 0.6411\n",
      "Epoch 95/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8792 - acc: 0.7089 - val_loss: 1.4433 - val_acc: 0.6613\n",
      "Epoch 96/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8720 - acc: 0.6995 - val_loss: 0.8867 - val_acc: 0.7177\n",
      "Epoch 97/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7457 - acc: 0.7615 - val_loss: 1.1556 - val_acc: 0.6935\n",
      "Epoch 98/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8545 - acc: 0.7345 - val_loss: 1.0115 - val_acc: 0.6935\n",
      "Epoch 99/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7238 - acc: 0.7722 - val_loss: 1.0519 - val_acc: 0.7056\n",
      "Epoch 100/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7386 - acc: 0.7601 - val_loss: 1.0121 - val_acc: 0.7339\n",
      "Epoch 101/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7938 - acc: 0.7615 - val_loss: 0.8873 - val_acc: 0.7500\n",
      "Epoch 102/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7608 - acc: 0.7655 - val_loss: 1.3207 - val_acc: 0.6815\n",
      "Epoch 103/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7209 - acc: 0.7588 - val_loss: 1.2337 - val_acc: 0.6734\n",
      "Epoch 104/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7022 - acc: 0.7628 - val_loss: 1.3306 - val_acc: 0.6935\n",
      "Epoch 105/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5663 - acc: 0.7992 - val_loss: 1.1717 - val_acc: 0.7056\n",
      "Epoch 106/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6582 - acc: 0.7951 - val_loss: 1.3886 - val_acc: 0.6452\n",
      "Epoch 107/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5505 - acc: 0.8073 - val_loss: 0.9907 - val_acc: 0.7540\n",
      "Epoch 108/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5879 - acc: 0.8046 - val_loss: 1.0386 - val_acc: 0.7419\n",
      "Epoch 109/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6276 - acc: 0.8127 - val_loss: 1.1802 - val_acc: 0.6895\n",
      "Epoch 110/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5099 - acc: 0.8396 - val_loss: 1.1104 - val_acc: 0.7540\n",
      "Epoch 111/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6314 - acc: 0.8100 - val_loss: 0.7441 - val_acc: 0.8024\n",
      "Epoch 112/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5590 - acc: 0.8396 - val_loss: 0.9412 - val_acc: 0.7540\n",
      "Epoch 113/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5914 - acc: 0.8356 - val_loss: 1.2689 - val_acc: 0.7137\n",
      "Epoch 114/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6195 - acc: 0.8194 - val_loss: 0.9947 - val_acc: 0.7661\n",
      "Epoch 115/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4921 - acc: 0.8598 - val_loss: 1.0043 - val_acc: 0.7581\n",
      "Epoch 116/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5516 - acc: 0.8315 - val_loss: 1.2348 - val_acc: 0.7258\n",
      "Epoch 117/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5082 - acc: 0.8491 - val_loss: 1.7241 - val_acc: 0.6492\n",
      "Epoch 118/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5125 - acc: 0.8504 - val_loss: 1.8219 - val_acc: 0.6331\n",
      "Epoch 119/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4862 - acc: 0.8544 - val_loss: 1.2415 - val_acc: 0.6976\n",
      "Epoch 120/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5090 - acc: 0.8693 - val_loss: 1.3959 - val_acc: 0.7016\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4786 - acc: 0.8544 - val_loss: 0.9325 - val_acc: 0.7702\n",
      "Epoch 122/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4813 - acc: 0.8639 - val_loss: 1.0239 - val_acc: 0.7500\n",
      "Epoch 123/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4599 - acc: 0.8693 - val_loss: 0.9969 - val_acc: 0.7702\n",
      "Epoch 124/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3733 - acc: 0.8787 - val_loss: 0.8049 - val_acc: 0.8145\n",
      "Epoch 125/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4441 - acc: 0.8760 - val_loss: 0.6931 - val_acc: 0.8185\n",
      "Epoch 126/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4571 - acc: 0.8693 - val_loss: 0.6719 - val_acc: 0.8145\n",
      "Epoch 127/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3360 - acc: 0.9057 - val_loss: 0.5870 - val_acc: 0.8266\n",
      "Epoch 128/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3906 - acc: 0.8827 - val_loss: 0.6083 - val_acc: 0.8266\n",
      "Epoch 129/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4390 - acc: 0.8868 - val_loss: 0.8745 - val_acc: 0.8105\n",
      "Epoch 130/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3603 - acc: 0.8827 - val_loss: 0.8830 - val_acc: 0.8105\n",
      "Epoch 131/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3308 - acc: 0.9151 - val_loss: 0.8496 - val_acc: 0.8306\n",
      "Epoch 132/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4479 - acc: 0.8760 - val_loss: 0.8375 - val_acc: 0.8105\n",
      "Epoch 133/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4210 - acc: 0.8881 - val_loss: 1.2124 - val_acc: 0.7823\n",
      "Epoch 134/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3906 - acc: 0.8841 - val_loss: 2.2089 - val_acc: 0.5565\n",
      "Epoch 135/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3480 - acc: 0.9111 - val_loss: 1.3524 - val_acc: 0.7298\n",
      "Epoch 136/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3912 - acc: 0.8922 - val_loss: 0.7940 - val_acc: 0.7984\n",
      "Epoch 137/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.3774 - acc: 0.910 - 2s 3ms/step - loss: 0.3751 - acc: 0.9111 - val_loss: 0.7665 - val_acc: 0.8306\n",
      "Epoch 138/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3283 - acc: 0.9043 - val_loss: 0.9004 - val_acc: 0.7702\n",
      "Epoch 139/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3473 - acc: 0.9151 - val_loss: 0.8249 - val_acc: 0.8266\n",
      "Epoch 140/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4222 - acc: 0.9003 - val_loss: 1.7688 - val_acc: 0.6532\n",
      "Epoch 141/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3559 - acc: 0.9111 - val_loss: 0.7576 - val_acc: 0.8347\n",
      "Epoch 142/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2627 - acc: 0.9299 - val_loss: 0.6667 - val_acc: 0.8508\n",
      "Epoch 143/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3701 - acc: 0.9043 - val_loss: 0.6848 - val_acc: 0.8589\n",
      "Epoch 144/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3097 - acc: 0.9259 - val_loss: 0.7998 - val_acc: 0.7903\n",
      "Epoch 145/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2619 - acc: 0.9340 - val_loss: 0.8708 - val_acc: 0.8266\n",
      "Epoch 146/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3086 - acc: 0.9124 - val_loss: 0.7185 - val_acc: 0.8306\n",
      "Epoch 147/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3712 - acc: 0.9003 - val_loss: 0.6501 - val_acc: 0.8508\n",
      "Epoch 148/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2805 - acc: 0.9380 - val_loss: 0.5980 - val_acc: 0.8710\n",
      "Epoch 149/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2068 - acc: 0.9407 - val_loss: 0.9311 - val_acc: 0.8024\n",
      "Epoch 150/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3581 - acc: 0.9137 - val_loss: 0.5429 - val_acc: 0.8831\n",
      "Epoch 151/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3241 - acc: 0.9111 - val_loss: 0.7772 - val_acc: 0.8226\n",
      "Epoch 152/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2901 - acc: 0.9340 - val_loss: 0.6255 - val_acc: 0.8387\n",
      "Epoch 153/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4174 - acc: 0.9016 - val_loss: 0.4336 - val_acc: 0.8750\n",
      "Epoch 154/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2300 - acc: 0.9286 - val_loss: 0.6080 - val_acc: 0.8347\n",
      "Epoch 155/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3190 - acc: 0.9218 - val_loss: 0.7435 - val_acc: 0.8266\n",
      "Epoch 156/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3153 - acc: 0.9245 - val_loss: 0.7173 - val_acc: 0.8427\n",
      "Epoch 157/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3527 - acc: 0.9124 - val_loss: 0.9050 - val_acc: 0.7742\n",
      "Epoch 158/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2782 - acc: 0.9420 - val_loss: 1.2210 - val_acc: 0.7742\n",
      "Epoch 159/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2990 - acc: 0.9245 - val_loss: 0.8927 - val_acc: 0.8024\n",
      "Epoch 160/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4680 - acc: 0.9137 - val_loss: 0.5895 - val_acc: 0.8548\n",
      "Epoch 161/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2678 - acc: 0.9286 - val_loss: 0.6433 - val_acc: 0.8710\n",
      "Epoch 162/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2867 - acc: 0.9394 - val_loss: 0.6546 - val_acc: 0.8629\n",
      "Epoch 163/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2224 - acc: 0.9407 - val_loss: 0.7377 - val_acc: 0.8548\n",
      "Epoch 164/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3458 - acc: 0.9299 - val_loss: 0.7149 - val_acc: 0.8427\n",
      "Epoch 165/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1774 - acc: 0.9555 - val_loss: 0.9049 - val_acc: 0.8548\n",
      "Epoch 166/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2600 - acc: 0.9407 - val_loss: 0.7170 - val_acc: 0.8548\n",
      "Epoch 167/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3111 - acc: 0.9313 - val_loss: 0.8888 - val_acc: 0.8065\n",
      "Epoch 168/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3033 - acc: 0.9340 - val_loss: 0.6695 - val_acc: 0.8790\n",
      "Epoch 169/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2356 - acc: 0.9394 - val_loss: 1.0171 - val_acc: 0.8468\n",
      "Epoch 170/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2074 - acc: 0.9488 - val_loss: 0.9107 - val_acc: 0.7903\n",
      "Epoch 171/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2492 - acc: 0.9461 - val_loss: 1.0704 - val_acc: 0.8105\n",
      "Epoch 172/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2408 - acc: 0.9420 - val_loss: 0.9670 - val_acc: 0.8065\n",
      "Epoch 173/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2780 - acc: 0.9380 - val_loss: 0.9332 - val_acc: 0.8427\n",
      "Epoch 174/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2656 - acc: 0.9461 - val_loss: 0.6295 - val_acc: 0.8548\n",
      "Epoch 175/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3101 - acc: 0.9420 - val_loss: 0.8429 - val_acc: 0.8387\n",
      "Epoch 176/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3426 - acc: 0.9299 - val_loss: 0.8003 - val_acc: 0.8427\n",
      "Epoch 177/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1520 - acc: 0.9636 - val_loss: 0.8992 - val_acc: 0.8548\n",
      "Epoch 178/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4044 - acc: 0.9326 - val_loss: 0.7251 - val_acc: 0.8710\n",
      "Epoch 179/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2678 - acc: 0.9461 - val_loss: 0.5103 - val_acc: 0.8831\n",
      "Epoch 180/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1880 - acc: 0.9609 - val_loss: 0.7023 - val_acc: 0.8871\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2554 - acc: 0.9420 - val_loss: 0.8293 - val_acc: 0.8266\n",
      "Epoch 182/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2511 - acc: 0.9394 - val_loss: 0.5418 - val_acc: 0.8508\n",
      "Epoch 183/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2948 - acc: 0.9474 - val_loss: 1.9344 - val_acc: 0.7218\n",
      "Epoch 184/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3072 - acc: 0.9380 - val_loss: 0.5495 - val_acc: 0.8790\n",
      "Epoch 185/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2691 - acc: 0.9488 - val_loss: 0.7347 - val_acc: 0.8508\n",
      "Epoch 186/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2122 - acc: 0.9528 - val_loss: 0.5877 - val_acc: 0.8790\n",
      "Epoch 187/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2890 - acc: 0.9447 - val_loss: 0.5279 - val_acc: 0.8790\n",
      "Epoch 188/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2120 - acc: 0.9501 - val_loss: 0.5257 - val_acc: 0.8427\n",
      "Epoch 189/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2854 - acc: 0.9394 - val_loss: 0.3732 - val_acc: 0.9073\n",
      "Epoch 190/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2171 - acc: 0.9596 - val_loss: 1.1402 - val_acc: 0.8105\n",
      "Epoch 191/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3160 - acc: 0.9299 - val_loss: 0.4587 - val_acc: 0.8911\n",
      "Epoch 192/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2588 - acc: 0.9420 - val_loss: 0.4892 - val_acc: 0.8508\n",
      "Epoch 193/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3551 - acc: 0.9272 - val_loss: 0.6498 - val_acc: 0.8589\n",
      "Epoch 194/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2170 - acc: 0.9515 - val_loss: 0.5211 - val_acc: 0.8710\n",
      "Epoch 195/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2313 - acc: 0.9542 - val_loss: 1.0478 - val_acc: 0.8548\n",
      "Epoch 196/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2181 - acc: 0.9488 - val_loss: 0.8117 - val_acc: 0.8629\n",
      "Epoch 197/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3574 - acc: 0.9420 - val_loss: 0.6158 - val_acc: 0.8468\n",
      "Epoch 198/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3420 - acc: 0.9420 - val_loss: 0.3206 - val_acc: 0.9113\n",
      "Epoch 199/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3033 - acc: 0.9299 - val_loss: 0.5708 - val_acc: 0.8952\n",
      "Epoch 200/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1980 - acc: 0.9528 - val_loss: 0.6385 - val_acc: 0.8669\n",
      "Epoch 201/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2588 - acc: 0.9555 - val_loss: 0.5490 - val_acc: 0.8790\n",
      "Epoch 202/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1492 - acc: 0.9717 - val_loss: 0.5221 - val_acc: 0.8750\n",
      "Epoch 203/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2978 - acc: 0.9501 - val_loss: 0.7114 - val_acc: 0.8589\n",
      "Epoch 204/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2365 - acc: 0.9528 - val_loss: 0.6214 - val_acc: 0.8750\n",
      "Epoch 205/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3134 - acc: 0.9420 - val_loss: 0.6004 - val_acc: 0.8750\n",
      "Epoch 206/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3989 - acc: 0.9367 - val_loss: 0.6250 - val_acc: 0.8831\n",
      "Epoch 207/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3047 - acc: 0.9340 - val_loss: 0.6824 - val_acc: 0.8710\n",
      "Epoch 208/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2840 - acc: 0.9488 - val_loss: 0.5445 - val_acc: 0.8548\n",
      "Epoch 209/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4158 - acc: 0.9367 - val_loss: 0.7539 - val_acc: 0.8629\n",
      "Epoch 210/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2919 - acc: 0.9474 - val_loss: 0.7934 - val_acc: 0.8548\n",
      "Epoch 211/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3941 - acc: 0.9313 - val_loss: 0.7739 - val_acc: 0.8710\n",
      "Epoch 212/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2896 - acc: 0.9447 - val_loss: 0.4662 - val_acc: 0.9032\n",
      "Epoch 213/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3584 - acc: 0.9420 - val_loss: 1.1917 - val_acc: 0.8065\n",
      "Epoch 214/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3244 - acc: 0.9434 - val_loss: 0.5450 - val_acc: 0.8911\n",
      "Epoch 215/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3019 - acc: 0.9542 - val_loss: 0.5133 - val_acc: 0.9032\n",
      "Epoch 216/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3250 - acc: 0.9353 - val_loss: 0.5365 - val_acc: 0.8589\n",
      "Epoch 217/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1544 - acc: 0.9636 - val_loss: 0.7538 - val_acc: 0.8669\n",
      "Epoch 218/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3180 - acc: 0.9380 - val_loss: 0.5072 - val_acc: 0.8750\n",
      "Epoch 219/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3072 - acc: 0.9447 - val_loss: 0.5644 - val_acc: 0.8710\n",
      "Epoch 220/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3063 - acc: 0.9515 - val_loss: 0.7807 - val_acc: 0.8185\n",
      "Epoch 221/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3062 - acc: 0.9488 - val_loss: 0.5281 - val_acc: 0.8871\n",
      "Epoch 222/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2799 - acc: 0.9515 - val_loss: 0.6104 - val_acc: 0.8871\n",
      "Epoch 223/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3950 - acc: 0.9313 - val_loss: 0.4615 - val_acc: 0.8952\n",
      "Epoch 224/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2605 - acc: 0.9542 - val_loss: 0.9372 - val_acc: 0.8185\n",
      "Epoch 225/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3164 - acc: 0.9474 - val_loss: 0.5846 - val_acc: 0.8750\n",
      "Epoch 226/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2531 - acc: 0.9515 - val_loss: 0.5597 - val_acc: 0.8831\n",
      "Epoch 227/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3345 - acc: 0.9461 - val_loss: 0.4248 - val_acc: 0.8831\n",
      "Epoch 228/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3555 - acc: 0.9407 - val_loss: 0.5690 - val_acc: 0.8871\n",
      "Epoch 229/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3000 - acc: 0.9407 - val_loss: 0.7057 - val_acc: 0.8790\n",
      "Epoch 230/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3749 - acc: 0.9528 - val_loss: 0.5679 - val_acc: 0.8669\n",
      "Epoch 231/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2311 - acc: 0.9596 - val_loss: 0.9891 - val_acc: 0.8226\n",
      "Epoch 232/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2960 - acc: 0.9447 - val_loss: 0.4692 - val_acc: 0.8790\n",
      "Epoch 233/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2070 - acc: 0.9609 - val_loss: 0.7426 - val_acc: 0.8387\n",
      "Epoch 234/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4014 - acc: 0.9407 - val_loss: 0.5050 - val_acc: 0.8952\n",
      "Epoch 235/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2768 - acc: 0.9528 - val_loss: 0.5883 - val_acc: 0.8992\n",
      "Epoch 236/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4627 - acc: 0.9447 - val_loss: 0.5126 - val_acc: 0.8750\n",
      "Epoch 237/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2514 - acc: 0.9582 - val_loss: 0.6462 - val_acc: 0.8871\n",
      "Epoch 238/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3361 - acc: 0.9528 - val_loss: 0.6756 - val_acc: 0.8790\n",
      "Epoch 239/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2107 - acc: 0.9569 - val_loss: 0.7355 - val_acc: 0.8710\n",
      "Epoch 240/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2410 - acc: 0.9555 - val_loss: 0.5287 - val_acc: 0.8831\n",
      "Epoch 241/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2890 - acc: 0.9542 - val_loss: 0.3577 - val_acc: 0.9073\n",
      "Epoch 242/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2703 - acc: 0.9596 - val_loss: 0.6921 - val_acc: 0.8790\n",
      "Epoch 243/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4903 - acc: 0.9394 - val_loss: 0.8986 - val_acc: 0.8105\n",
      "Epoch 244/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3238 - acc: 0.9528 - val_loss: 0.6523 - val_acc: 0.8750\n",
      "Epoch 245/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3439 - acc: 0.9447 - val_loss: 0.5061 - val_acc: 0.8790\n",
      "Epoch 246/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2863 - acc: 0.9542 - val_loss: 0.5159 - val_acc: 0.8750\n",
      "Epoch 247/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2026 - acc: 0.9757 - val_loss: 0.8447 - val_acc: 0.8911\n",
      "Epoch 248/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4788 - acc: 0.9353 - val_loss: 0.8103 - val_acc: 0.8669\n",
      "Epoch 249/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3012 - acc: 0.9569 - val_loss: 0.6442 - val_acc: 0.8508\n",
      "Epoch 250/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3196 - acc: 0.9474 - val_loss: 0.8482 - val_acc: 0.8065\n",
      "Epoch 251/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3203 - acc: 0.9596 - val_loss: 0.5678 - val_acc: 0.8952\n",
      "Epoch 252/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2399 - acc: 0.9609 - val_loss: 1.1259 - val_acc: 0.8589\n",
      "Epoch 253/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3928 - acc: 0.9501 - val_loss: 0.7344 - val_acc: 0.8871\n",
      "Epoch 254/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3148 - acc: 0.9528 - val_loss: 1.1994 - val_acc: 0.8710\n",
      "Epoch 255/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3164 - acc: 0.9501 - val_loss: 0.5085 - val_acc: 0.8911\n",
      "Epoch 256/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3275 - acc: 0.9474 - val_loss: 0.4289 - val_acc: 0.9073\n",
      "Epoch 257/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2078 - acc: 0.9663 - val_loss: 0.3942 - val_acc: 0.9194\n",
      "Epoch 258/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3044 - acc: 0.9501 - val_loss: 0.4319 - val_acc: 0.9194\n",
      "Epoch 259/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3221 - acc: 0.9501 - val_loss: 0.4744 - val_acc: 0.8911\n",
      "Epoch 260/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2642 - acc: 0.9569 - val_loss: 0.6828 - val_acc: 0.8911\n",
      "Epoch 261/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2463 - acc: 0.9663 - val_loss: 0.6595 - val_acc: 0.8952\n",
      "Epoch 262/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3348 - acc: 0.9447 - val_loss: 0.7750 - val_acc: 0.8589\n",
      "Epoch 263/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2386 - acc: 0.9609 - val_loss: 0.6461 - val_acc: 0.8750\n",
      "Epoch 264/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2635 - acc: 0.9542 - val_loss: 0.6119 - val_acc: 0.8992\n",
      "Epoch 265/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2862 - acc: 0.9447 - val_loss: 0.6263 - val_acc: 0.8589\n",
      "Epoch 266/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1889 - acc: 0.9663 - val_loss: 0.4133 - val_acc: 0.8992\n",
      "Epoch 267/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2434 - acc: 0.9394 - val_loss: 0.6627 - val_acc: 0.8911\n",
      "Epoch 268/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2049 - acc: 0.9636 - val_loss: 0.5284 - val_acc: 0.8750\n",
      "Epoch 269/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3401 - acc: 0.9528 - val_loss: 0.4478 - val_acc: 0.8992\n",
      "Epoch 270/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3477 - acc: 0.9488 - val_loss: 0.6245 - val_acc: 0.8508\n",
      "Epoch 271/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3905 - acc: 0.9528 - val_loss: 0.5162 - val_acc: 0.9073\n",
      "Epoch 272/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2420 - acc: 0.9704 - val_loss: 0.5061 - val_acc: 0.9113\n",
      "Epoch 273/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2290 - acc: 0.9623 - val_loss: 0.5117 - val_acc: 0.8911\n",
      "Epoch 274/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3451 - acc: 0.9515 - val_loss: 0.9776 - val_acc: 0.7984\n",
      "Epoch 275/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3666 - acc: 0.9488 - val_loss: 0.7028 - val_acc: 0.8669\n",
      "Epoch 276/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2762 - acc: 0.9623 - val_loss: 0.5904 - val_acc: 0.8911\n",
      "Epoch 277/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3119 - acc: 0.9582 - val_loss: 0.7812 - val_acc: 0.8710\n",
      "Epoch 278/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3691 - acc: 0.9515 - val_loss: 0.7387 - val_acc: 0.8669\n",
      "Epoch 279/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3141 - acc: 0.9596 - val_loss: 0.7031 - val_acc: 0.8911\n",
      "Epoch 280/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1626 - acc: 0.9650 - val_loss: 0.6122 - val_acc: 0.9194\n",
      "Epoch 281/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3543 - acc: 0.9515 - val_loss: 0.4688 - val_acc: 0.8911\n",
      "Epoch 282/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3472 - acc: 0.9542 - val_loss: 0.6123 - val_acc: 0.8831\n",
      "Epoch 283/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2314 - acc: 0.9677 - val_loss: 0.5028 - val_acc: 0.9032\n",
      "Epoch 284/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2839 - acc: 0.9636 - val_loss: 0.6729 - val_acc: 0.8790\n",
      "Epoch 285/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4034 - acc: 0.9501 - val_loss: 0.9134 - val_acc: 0.8427\n",
      "Epoch 286/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4743 - acc: 0.9528 - val_loss: 0.5354 - val_acc: 0.9073\n",
      "Epoch 287/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2642 - acc: 0.9690 - val_loss: 0.4660 - val_acc: 0.8992\n",
      "Epoch 288/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2670 - acc: 0.9582 - val_loss: 0.7242 - val_acc: 0.8911\n",
      "Epoch 289/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4702 - acc: 0.9447 - val_loss: 0.8339 - val_acc: 0.8871\n",
      "Epoch 290/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4148 - acc: 0.9461 - val_loss: 1.0134 - val_acc: 0.8508\n",
      "Epoch 291/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4663 - acc: 0.9407 - val_loss: 0.5451 - val_acc: 0.9032\n",
      "Epoch 292/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4473 - acc: 0.9596 - val_loss: 0.4346 - val_acc: 0.9194\n",
      "Epoch 293/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6055 - acc: 0.9299 - val_loss: 0.5018 - val_acc: 0.8911\n",
      "Epoch 294/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2689 - acc: 0.9569 - val_loss: 0.9140 - val_acc: 0.8387\n",
      "Epoch 295/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4050 - acc: 0.9461 - val_loss: 0.6093 - val_acc: 0.8710\n",
      "Epoch 296/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3660 - acc: 0.9474 - val_loss: 0.3866 - val_acc: 0.9274\n",
      "Epoch 297/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6405 - acc: 0.9272 - val_loss: 0.5399 - val_acc: 0.9032\n",
      "Epoch 298/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3285 - acc: 0.9569 - val_loss: 0.5943 - val_acc: 0.8669\n",
      "Epoch 299/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3098 - acc: 0.9582 - val_loss: 0.6661 - val_acc: 0.8790\n",
      "Epoch 300/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3064 - acc: 0.9609 - val_loss: 0.6252 - val_acc: 0.8871\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4155 - acc: 0.9555 - val_loss: 0.7385 - val_acc: 0.8911\n",
      "Epoch 302/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4163 - acc: 0.9461 - val_loss: 0.7909 - val_acc: 0.8589\n",
      "Epoch 303/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3072 - acc: 0.9555 - val_loss: 0.6908 - val_acc: 0.8790\n",
      "Epoch 304/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2514 - acc: 0.9636 - val_loss: 0.4887 - val_acc: 0.9113\n",
      "Epoch 305/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3866 - acc: 0.9569 - val_loss: 0.4317 - val_acc: 0.9113\n",
      "Epoch 306/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3339 - acc: 0.9582 - val_loss: 0.4411 - val_acc: 0.9032\n",
      "Epoch 307/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2340 - acc: 0.9677 - val_loss: 0.4737 - val_acc: 0.8992\n",
      "Epoch 308/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3605 - acc: 0.9542 - val_loss: 0.6238 - val_acc: 0.9194\n",
      "Epoch 309/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2970 - acc: 0.9717 - val_loss: 0.5099 - val_acc: 0.8992\n",
      "Epoch 310/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4462 - acc: 0.9501 - val_loss: 0.5849 - val_acc: 0.9032\n",
      "Epoch 311/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2403 - acc: 0.9677 - val_loss: 0.6436 - val_acc: 0.8710\n",
      "Epoch 312/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2783 - acc: 0.9623 - val_loss: 0.6164 - val_acc: 0.8952\n",
      "Epoch 313/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3192 - acc: 0.9542 - val_loss: 0.6415 - val_acc: 0.8911\n",
      "Epoch 314/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3364 - acc: 0.9555 - val_loss: 0.4467 - val_acc: 0.9073\n",
      "Epoch 315/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3851 - acc: 0.9447 - val_loss: 0.6164 - val_acc: 0.8669\n",
      "Epoch 316/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2280 - acc: 0.9609 - val_loss: 0.5658 - val_acc: 0.8871\n",
      "Epoch 317/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2436 - acc: 0.9636 - val_loss: 0.4292 - val_acc: 0.9234\n",
      "Epoch 318/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3831 - acc: 0.9555 - val_loss: 0.4217 - val_acc: 0.8911\n",
      "Epoch 319/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3948 - acc: 0.9596 - val_loss: 0.4807 - val_acc: 0.9153\n",
      "Epoch 320/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2125 - acc: 0.9677 - val_loss: 0.7940 - val_acc: 0.8710\n",
      "Epoch 321/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3902 - acc: 0.9542 - val_loss: 0.5363 - val_acc: 0.8831\n",
      "Epoch 322/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2811 - acc: 0.9623 - val_loss: 0.8446 - val_acc: 0.8629\n",
      "Epoch 323/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3806 - acc: 0.9596 - val_loss: 0.5325 - val_acc: 0.8831\n",
      "Epoch 324/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2603 - acc: 0.9596 - val_loss: 0.5927 - val_acc: 0.8952\n",
      "Epoch 325/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2486 - acc: 0.9704 - val_loss: 0.5563 - val_acc: 0.8669\n",
      "Epoch 326/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2290 - acc: 0.9636 - val_loss: 0.7189 - val_acc: 0.8548\n",
      "Epoch 327/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4545 - acc: 0.9420 - val_loss: 0.5407 - val_acc: 0.9073\n",
      "Epoch 328/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2696 - acc: 0.9650 - val_loss: 0.6942 - val_acc: 0.8952\n",
      "Epoch 329/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3843 - acc: 0.9569 - val_loss: 0.5356 - val_acc: 0.9234\n",
      "Epoch 330/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2656 - acc: 0.9636 - val_loss: 0.6863 - val_acc: 0.8871\n",
      "Epoch 331/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3486 - acc: 0.9690 - val_loss: 0.6807 - val_acc: 0.9153\n",
      "Epoch 332/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5344 - acc: 0.9542 - val_loss: 0.9605 - val_acc: 0.8790\n",
      "Epoch 333/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4206 - acc: 0.9596 - val_loss: 1.0646 - val_acc: 0.8790\n",
      "Epoch 334/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2727 - acc: 0.9623 - val_loss: 0.6980 - val_acc: 0.8790\n",
      "Epoch 335/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3925 - acc: 0.9582 - val_loss: 0.5338 - val_acc: 0.9032\n",
      "Epoch 336/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3751 - acc: 0.9596 - val_loss: 0.5841 - val_acc: 0.9153\n",
      "Epoch 337/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3806 - acc: 0.9569 - val_loss: 0.5949 - val_acc: 0.8992\n",
      "Epoch 338/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2881 - acc: 0.9717 - val_loss: 0.9173 - val_acc: 0.8710\n",
      "Epoch 339/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4901 - acc: 0.9515 - val_loss: 0.9700 - val_acc: 0.8952\n",
      "Epoch 340/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4408 - acc: 0.9515 - val_loss: 0.9813 - val_acc: 0.8911\n",
      "Epoch 341/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3416 - acc: 0.9636 - val_loss: 0.5894 - val_acc: 0.9073\n",
      "Epoch 342/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2712 - acc: 0.9690 - val_loss: 0.5860 - val_acc: 0.9274\n",
      "Epoch 343/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3725 - acc: 0.9623 - val_loss: 0.5244 - val_acc: 0.9194\n",
      "Epoch 344/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.1789 - acc: 0.9744 - val_loss: 0.9422 - val_acc: 0.9113\n",
      "Epoch 345/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5384 - acc: 0.9488 - val_loss: 0.8589 - val_acc: 0.9032\n",
      "Epoch 346/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2057 - acc: 0.9771 - val_loss: 0.5590 - val_acc: 0.9153\n",
      "Epoch 347/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3598 - acc: 0.9677 - val_loss: 1.1398 - val_acc: 0.8911\n",
      "Epoch 348/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3761 - acc: 0.9623 - val_loss: 0.8828 - val_acc: 0.8831\n",
      "Epoch 349/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7515 - acc: 0.9313 - val_loss: 0.6823 - val_acc: 0.8790\n",
      "Epoch 350/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4097 - acc: 0.9582 - val_loss: 0.7438 - val_acc: 0.8911\n",
      "Epoch 351/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6069 - acc: 0.9420 - val_loss: 0.8160 - val_acc: 0.8347\n",
      "Epoch 352/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5061 - acc: 0.9447 - val_loss: 0.7258 - val_acc: 0.8871\n",
      "Epoch 353/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4256 - acc: 0.9569 - val_loss: 0.5279 - val_acc: 0.9113\n",
      "Epoch 354/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3040 - acc: 0.9704 - val_loss: 0.6854 - val_acc: 0.8911\n",
      "Epoch 355/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4594 - acc: 0.9609 - val_loss: 1.1705 - val_acc: 0.8831\n",
      "Epoch 356/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5883 - acc: 0.9488 - val_loss: 0.8833 - val_acc: 0.9032\n",
      "Epoch 357/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3538 - acc: 0.9663 - val_loss: 0.6930 - val_acc: 0.8952\n",
      "Epoch 358/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5792 - acc: 0.9515 - val_loss: 0.7282 - val_acc: 0.9153\n",
      "Epoch 359/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3235 - acc: 0.9704 - val_loss: 0.7214 - val_acc: 0.9032\n",
      "Epoch 360/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3268 - acc: 0.9663 - val_loss: 0.6816 - val_acc: 0.9113\n",
      "Epoch 361/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3657 - acc: 0.9677 - val_loss: 0.6147 - val_acc: 0.9113\n",
      "Epoch 362/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3742 - acc: 0.9569 - val_loss: 0.4977 - val_acc: 0.9194\n",
      "Epoch 363/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4341 - acc: 0.9582 - val_loss: 0.6006 - val_acc: 0.9073\n",
      "Epoch 364/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4095 - acc: 0.9609 - val_loss: 0.8534 - val_acc: 0.8952\n",
      "Epoch 365/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4184 - acc: 0.9636 - val_loss: 0.9715 - val_acc: 0.8831\n",
      "Epoch 366/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4647 - acc: 0.9528 - val_loss: 1.0223 - val_acc: 0.8871\n",
      "Epoch 367/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2894 - acc: 0.9623 - val_loss: 0.9131 - val_acc: 0.8669\n",
      "Epoch 368/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2954 - acc: 0.9623 - val_loss: 0.7056 - val_acc: 0.8629\n",
      "Epoch 369/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3388 - acc: 0.9596 - val_loss: 0.7760 - val_acc: 0.8911\n",
      "Epoch 370/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2647 - acc: 0.9690 - val_loss: 0.7174 - val_acc: 0.9153\n",
      "Epoch 371/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3066 - acc: 0.9677 - val_loss: 0.7908 - val_acc: 0.8911\n",
      "Epoch 372/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3205 - acc: 0.9623 - val_loss: 0.6202 - val_acc: 0.8629\n",
      "Epoch 373/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3458 - acc: 0.9650 - val_loss: 0.4021 - val_acc: 0.8831\n",
      "Epoch 374/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3102 - acc: 0.9623 - val_loss: 0.6737 - val_acc: 0.8589\n",
      "Epoch 375/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2911 - acc: 0.9609 - val_loss: 0.6883 - val_acc: 0.8508\n",
      "Epoch 376/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4951 - acc: 0.9569 - val_loss: 0.7111 - val_acc: 0.8992\n",
      "Epoch 377/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4332 - acc: 0.9650 - val_loss: 0.7799 - val_acc: 0.8992\n",
      "Epoch 378/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3489 - acc: 0.9677 - val_loss: 0.7462 - val_acc: 0.9032\n",
      "Epoch 379/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3438 - acc: 0.9730 - val_loss: 0.8962 - val_acc: 0.8589\n",
      "Epoch 380/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5806 - acc: 0.9447 - val_loss: 1.0266 - val_acc: 0.8750\n",
      "Epoch 381/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2922 - acc: 0.9677 - val_loss: 0.9674 - val_acc: 0.8871\n",
      "Epoch 382/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6109 - acc: 0.9420 - val_loss: 0.9651 - val_acc: 0.8790\n",
      "Epoch 383/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3202 - acc: 0.9609 - val_loss: 0.7562 - val_acc: 0.8831\n",
      "Epoch 384/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2752 - acc: 0.9690 - val_loss: 0.4612 - val_acc: 0.9153\n",
      "Epoch 385/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3296 - acc: 0.9650 - val_loss: 0.9820 - val_acc: 0.9113\n",
      "Epoch 386/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4155 - acc: 0.9555 - val_loss: 0.8588 - val_acc: 0.9113\n",
      "Epoch 387/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4156 - acc: 0.9636 - val_loss: 0.8279 - val_acc: 0.9194\n",
      "Epoch 388/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4060 - acc: 0.9663 - val_loss: 1.0988 - val_acc: 0.8831\n",
      "Epoch 389/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5002 - acc: 0.9461 - val_loss: 0.6446 - val_acc: 0.9153\n",
      "Epoch 390/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2467 - acc: 0.9730 - val_loss: 0.6994 - val_acc: 0.9274\n",
      "Epoch 391/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6182 - acc: 0.9501 - val_loss: 1.0703 - val_acc: 0.9073\n",
      "Epoch 392/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4328 - acc: 0.9528 - val_loss: 0.9310 - val_acc: 0.9073\n",
      "Epoch 393/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4238 - acc: 0.9636 - val_loss: 0.7460 - val_acc: 0.9113\n",
      "Epoch 394/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4844 - acc: 0.9582 - val_loss: 0.8769 - val_acc: 0.8831\n",
      "Epoch 395/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5043 - acc: 0.9515 - val_loss: 1.1022 - val_acc: 0.8911\n",
      "Epoch 396/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4178 - acc: 0.9596 - val_loss: 1.1981 - val_acc: 0.8589\n",
      "Epoch 397/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2689 - acc: 0.9730 - val_loss: 0.9109 - val_acc: 0.8710\n",
      "Epoch 398/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5647 - acc: 0.9501 - val_loss: 1.0731 - val_acc: 0.8911\n",
      "Epoch 399/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3423 - acc: 0.9704 - val_loss: 1.0657 - val_acc: 0.8669\n",
      "Epoch 400/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5578 - acc: 0.9501 - val_loss: 1.2358 - val_acc: 0.8589\n",
      "Epoch 401/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6513 - acc: 0.9434 - val_loss: 0.8699 - val_acc: 0.9113\n",
      "Epoch 402/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4135 - acc: 0.9650 - val_loss: 0.9960 - val_acc: 0.8831\n",
      "Epoch 403/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3833 - acc: 0.9677 - val_loss: 1.1360 - val_acc: 0.8750\n",
      "Epoch 404/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2083 - acc: 0.9744 - val_loss: 0.9153 - val_acc: 0.9153\n",
      "Epoch 405/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3204 - acc: 0.9730 - val_loss: 0.9175 - val_acc: 0.9153\n",
      "Epoch 406/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5467 - acc: 0.9582 - val_loss: 1.0567 - val_acc: 0.9153\n",
      "Epoch 407/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3932 - acc: 0.9623 - val_loss: 1.0177 - val_acc: 0.9073\n",
      "Epoch 408/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4722 - acc: 0.9609 - val_loss: 1.6672 - val_acc: 0.8548\n",
      "Epoch 409/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7324 - acc: 0.9353 - val_loss: 1.1123 - val_acc: 0.9073\n",
      "Epoch 410/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5160 - acc: 0.9542 - val_loss: 1.1495 - val_acc: 0.8871\n",
      "Epoch 411/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6005 - acc: 0.9515 - val_loss: 1.6325 - val_acc: 0.8669\n",
      "Epoch 412/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5381 - acc: 0.9569 - val_loss: 1.0954 - val_acc: 0.8952\n",
      "Epoch 413/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4938 - acc: 0.9596 - val_loss: 1.9956 - val_acc: 0.8145\n",
      "Epoch 414/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4698 - acc: 0.9582 - val_loss: 1.1894 - val_acc: 0.8710\n",
      "Epoch 415/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4959 - acc: 0.9555 - val_loss: 0.9961 - val_acc: 0.8710\n",
      "Epoch 416/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4899 - acc: 0.9542 - val_loss: 1.4269 - val_acc: 0.8387\n",
      "Epoch 417/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3262 - acc: 0.9677 - val_loss: 1.0097 - val_acc: 0.9194\n",
      "Epoch 418/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5953 - acc: 0.9501 - val_loss: 1.1964 - val_acc: 0.8911\n",
      "Epoch 419/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5679 - acc: 0.9569 - val_loss: 1.5334 - val_acc: 0.8911\n",
      "Epoch 420/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6040 - acc: 0.9528 - val_loss: 1.5703 - val_acc: 0.8306\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4218 - acc: 0.9623 - val_loss: 0.8415 - val_acc: 0.8831\n",
      "Epoch 422/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4540 - acc: 0.9569 - val_loss: 1.0049 - val_acc: 0.9032\n",
      "Epoch 423/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3331 - acc: 0.9757 - val_loss: 1.0174 - val_acc: 0.9194\n",
      "Epoch 424/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.3104 - acc: 0.9730 - val_loss: 0.9223 - val_acc: 0.9234\n",
      "Epoch 425/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6303 - acc: 0.9515 - val_loss: 1.2629 - val_acc: 0.8992\n",
      "Epoch 426/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5044 - acc: 0.9515 - val_loss: 0.8866 - val_acc: 0.9073\n",
      "Epoch 427/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4260 - acc: 0.9623 - val_loss: 1.4383 - val_acc: 0.8145\n",
      "Epoch 428/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6276 - acc: 0.9447 - val_loss: 1.0198 - val_acc: 0.8750\n",
      "Epoch 429/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4325 - acc: 0.9596 - val_loss: 1.1850 - val_acc: 0.9032\n",
      "Epoch 430/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6627 - acc: 0.9474 - val_loss: 1.5029 - val_acc: 0.8831\n",
      "Epoch 431/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5343 - acc: 0.9596 - val_loss: 1.3772 - val_acc: 0.8629\n",
      "Epoch 432/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4407 - acc: 0.9663 - val_loss: 1.6998 - val_acc: 0.8468\n",
      "Epoch 433/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5084 - acc: 0.9555 - val_loss: 1.0762 - val_acc: 0.8750\n",
      "Epoch 434/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4528 - acc: 0.9623 - val_loss: 1.6594 - val_acc: 0.8548\n",
      "Epoch 435/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6371 - acc: 0.9447 - val_loss: 1.0433 - val_acc: 0.9032\n",
      "Epoch 436/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6044 - acc: 0.9501 - val_loss: 1.1472 - val_acc: 0.9032\n",
      "Epoch 437/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7514 - acc: 0.9447 - val_loss: 1.5430 - val_acc: 0.8871\n",
      "Epoch 438/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6163 - acc: 0.9528 - val_loss: 1.8829 - val_acc: 0.8669\n",
      "Epoch 439/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7679 - acc: 0.9434 - val_loss: 1.4599 - val_acc: 0.8508\n",
      "Epoch 440/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6723 - acc: 0.9447 - val_loss: 1.2640 - val_acc: 0.8992\n",
      "Epoch 441/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5576 - acc: 0.9596 - val_loss: 1.1062 - val_acc: 0.9073\n",
      "Epoch 442/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6461 - acc: 0.9569 - val_loss: 1.2216 - val_acc: 0.9073\n",
      "Epoch 443/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5125 - acc: 0.9582 - val_loss: 0.9538 - val_acc: 0.9032\n",
      "Epoch 444/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6264 - acc: 0.9515 - val_loss: 1.3421 - val_acc: 0.8911\n",
      "Epoch 445/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6473 - acc: 0.9528 - val_loss: 1.8969 - val_acc: 0.8427\n",
      "Epoch 446/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6032 - acc: 0.9501 - val_loss: 0.9063 - val_acc: 0.9032\n",
      "Epoch 447/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5975 - acc: 0.9501 - val_loss: 1.4264 - val_acc: 0.8790\n",
      "Epoch 448/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.2257 - acc: 0.9784 - val_loss: 0.7418 - val_acc: 0.9315\n",
      "Epoch 449/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5192 - acc: 0.9623 - val_loss: 1.1714 - val_acc: 0.9153\n",
      "Epoch 450/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6706 - acc: 0.9528 - val_loss: 1.1644 - val_acc: 0.9113\n",
      "Epoch 451/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.6022 - acc: 0.955 - 2s 3ms/step - loss: 0.5974 - acc: 0.9555 - val_loss: 1.0042 - val_acc: 0.8911\n",
      "Epoch 452/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6094 - acc: 0.9555 - val_loss: 1.5759 - val_acc: 0.8871\n",
      "Epoch 453/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6650 - acc: 0.9474 - val_loss: 1.2212 - val_acc: 0.8992\n",
      "Epoch 454/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.4549 - acc: 0.9582 - val_loss: 1.2552 - val_acc: 0.9113\n",
      "Epoch 455/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7069 - acc: 0.9488 - val_loss: 1.5025 - val_acc: 0.8871\n",
      "Epoch 456/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8297 - acc: 0.9447 - val_loss: 1.5009 - val_acc: 0.8952\n",
      "Epoch 457/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5019 - acc: 0.9623 - val_loss: 1.3653 - val_acc: 0.8508\n",
      "Epoch 458/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6029 - acc: 0.9569 - val_loss: 1.2735 - val_acc: 0.8952\n",
      "Epoch 459/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7496 - acc: 0.9461 - val_loss: 1.1683 - val_acc: 0.9113\n",
      "Epoch 460/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5899 - acc: 0.9542 - val_loss: 1.6827 - val_acc: 0.8831\n",
      "Epoch 461/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8469 - acc: 0.9367 - val_loss: 1.3311 - val_acc: 0.8911\n",
      "Epoch 462/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7558 - acc: 0.9447 - val_loss: 1.2314 - val_acc: 0.9113\n",
      "Epoch 463/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6636 - acc: 0.9528 - val_loss: 1.8941 - val_acc: 0.8750\n",
      "Epoch 464/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9431 - acc: 0.9313 - val_loss: 1.7315 - val_acc: 0.8831\n",
      "Epoch 465/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7226 - acc: 0.9461 - val_loss: 1.3036 - val_acc: 0.9032\n",
      "Epoch 466/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7009 - acc: 0.9420 - val_loss: 1.6800 - val_acc: 0.8790\n",
      "Epoch 467/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7918 - acc: 0.9474 - val_loss: 1.5002 - val_acc: 0.8911\n",
      "Epoch 468/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5818 - acc: 0.9582 - val_loss: 1.2328 - val_acc: 0.9073\n",
      "Epoch 469/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6668 - acc: 0.9515 - val_loss: 1.6059 - val_acc: 0.8790\n",
      "Epoch 470/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8172 - acc: 0.9434 - val_loss: 1.3357 - val_acc: 0.8911\n",
      "Epoch 471/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9001 - acc: 0.9326 - val_loss: 1.7132 - val_acc: 0.8790\n",
      "Epoch 472/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8772 - acc: 0.9447 - val_loss: 1.4171 - val_acc: 0.8992\n",
      "Epoch 473/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3004 - acc: 0.9124 - val_loss: 2.1024 - val_acc: 0.8508\n",
      "Epoch 474/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8780 - acc: 0.9367 - val_loss: 1.3051 - val_acc: 0.9073\n",
      "Epoch 475/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0134 - acc: 0.9340 - val_loss: 1.3035 - val_acc: 0.8992\n",
      "Epoch 476/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6069 - acc: 0.9582 - val_loss: 1.7820 - val_acc: 0.8790\n",
      "Epoch 477/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1590 - acc: 0.9191 - val_loss: 1.3901 - val_acc: 0.8952\n",
      "Epoch 478/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8275 - acc: 0.9434 - val_loss: 1.8470 - val_acc: 0.8669\n",
      "Epoch 479/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7970 - acc: 0.9447 - val_loss: 2.1329 - val_acc: 0.8508\n",
      "Epoch 480/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8092 - acc: 0.9447 - val_loss: 1.9824 - val_acc: 0.8629\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1631 - acc: 0.9218 - val_loss: 2.0497 - val_acc: 0.8589\n",
      "Epoch 482/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9298 - acc: 0.9380 - val_loss: 1.8221 - val_acc: 0.8790\n",
      "Epoch 483/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9969 - acc: 0.9313 - val_loss: 1.8168 - val_acc: 0.8790\n",
      "Epoch 484/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4324 - acc: 0.9084 - val_loss: 2.0814 - val_acc: 0.8629\n",
      "Epoch 485/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1006 - acc: 0.9272 - val_loss: 2.0817 - val_acc: 0.8548\n",
      "Epoch 486/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4521 - acc: 0.9043 - val_loss: 1.5497 - val_acc: 0.8911\n",
      "Epoch 487/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9226 - acc: 0.9353 - val_loss: 1.7194 - val_acc: 0.8790\n",
      "Epoch 488/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0287 - acc: 0.9272 - val_loss: 1.6134 - val_acc: 0.8871\n",
      "Epoch 489/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1710 - acc: 0.9205 - val_loss: 2.0339 - val_acc: 0.8669\n",
      "Epoch 490/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0412 - acc: 0.9313 - val_loss: 2.0040 - val_acc: 0.8710\n",
      "Epoch 491/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9612 - acc: 0.9367 - val_loss: 1.9048 - val_acc: 0.8750\n",
      "Epoch 492/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8805 - acc: 0.9420 - val_loss: 1.4198 - val_acc: 0.8911\n",
      "Epoch 493/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1042 - acc: 0.9191 - val_loss: 2.4839 - val_acc: 0.8306\n",
      "Epoch 494/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6696 - acc: 0.8895 - val_loss: 3.1799 - val_acc: 0.7944\n",
      "Epoch 495/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2419 - acc: 0.9191 - val_loss: 1.8219 - val_acc: 0.8790\n",
      "Epoch 496/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9102 - acc: 0.9367 - val_loss: 1.5291 - val_acc: 0.8911\n",
      "Epoch 497/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0453 - acc: 0.9326 - val_loss: 2.3595 - val_acc: 0.8427\n",
      "Epoch 498/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0767 - acc: 0.9245 - val_loss: 1.6919 - val_acc: 0.8871\n",
      "Epoch 499/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7252 - acc: 0.9515 - val_loss: 1.6010 - val_acc: 0.8911\n",
      "Epoch 500/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.7979 - acc: 0.9474 - val_loss: 2.0217 - val_acc: 0.8629\n",
      "Epoch 501/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0803 - acc: 0.9272 - val_loss: 1.6117 - val_acc: 0.8911\n",
      "Epoch 502/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.6966 - acc: 0.9542 - val_loss: 1.6484 - val_acc: 0.8790\n",
      "Epoch 503/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5136 - acc: 0.9650 - val_loss: 1.8771 - val_acc: 0.8790\n",
      "Epoch 504/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0098 - acc: 0.9326 - val_loss: 1.2999 - val_acc: 0.9032\n",
      "Epoch 505/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.5840 - acc: 0.9609 - val_loss: 1.3537 - val_acc: 0.9032\n",
      "Epoch 506/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0460 - acc: 0.9326 - val_loss: 1.9251 - val_acc: 0.8629\n",
      "Epoch 507/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9431 - acc: 0.9394 - val_loss: 1.9166 - val_acc: 0.8710\n",
      "Epoch 508/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2359 - acc: 0.9191 - val_loss: 2.1313 - val_acc: 0.8548\n",
      "Epoch 509/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8951 - acc: 0.9407 - val_loss: 1.9834 - val_acc: 0.8710\n",
      "Epoch 510/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8046 - acc: 0.9461 - val_loss: 2.2086 - val_acc: 0.8468\n",
      "Epoch 511/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2465 - acc: 0.9191 - val_loss: 2.9956 - val_acc: 0.8105\n",
      "Epoch 512/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6655 - acc: 0.8329 - val_loss: 3.8834 - val_acc: 0.7540\n",
      "Epoch 513/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5714 - acc: 0.8989 - val_loss: 2.3750 - val_acc: 0.8508\n",
      "Epoch 514/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4298 - acc: 0.9084 - val_loss: 2.2442 - val_acc: 0.8548\n",
      "Epoch 515/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7004 - acc: 0.8922 - val_loss: 3.4557 - val_acc: 0.7661\n",
      "Epoch 516/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0024 - acc: 0.8693 - val_loss: 2.4851 - val_acc: 0.8306\n",
      "Epoch 517/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4063 - acc: 0.9097 - val_loss: 2.8601 - val_acc: 0.8185\n",
      "Epoch 518/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3916 - acc: 0.9070 - val_loss: 2.3307 - val_acc: 0.8548\n",
      "Epoch 519/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5532 - acc: 0.8989 - val_loss: 2.2343 - val_acc: 0.8468\n",
      "Epoch 520/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5911 - acc: 0.8976 - val_loss: 2.3317 - val_acc: 0.8508\n",
      "Epoch 521/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.9517 - acc: 0.9367 - val_loss: 1.4472 - val_acc: 0.9032\n",
      "Epoch 522/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0569 - acc: 0.9313 - val_loss: 1.2799 - val_acc: 0.9153\n",
      "Epoch 523/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2554 - acc: 0.9191 - val_loss: 2.2828 - val_acc: 0.8508\n",
      "Epoch 524/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6810 - acc: 0.8922 - val_loss: 2.0448 - val_acc: 0.8669\n",
      "Epoch 525/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1962 - acc: 0.9259 - val_loss: 2.4378 - val_acc: 0.8427\n",
      "Epoch 526/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8562 - acc: 0.9434 - val_loss: 2.3552 - val_acc: 0.8508\n",
      "Epoch 527/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8715 - acc: 0.8801 - val_loss: 2.1863 - val_acc: 0.8629\n",
      "Epoch 528/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5858 - acc: 0.9016 - val_loss: 2.1143 - val_acc: 0.8669\n",
      "Epoch 529/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4494 - acc: 0.9057 - val_loss: 2.3544 - val_acc: 0.8427\n",
      "Epoch 530/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2464 - acc: 0.9205 - val_loss: 2.1315 - val_acc: 0.8629\n",
      "Epoch 531/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3380 - acc: 0.9124 - val_loss: 2.3174 - val_acc: 0.8468\n",
      "Epoch 532/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5566 - acc: 0.9016 - val_loss: 1.9721 - val_acc: 0.8669\n",
      "Epoch 533/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3853 - acc: 0.9111 - val_loss: 1.6606 - val_acc: 0.8952\n",
      "Epoch 534/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2925 - acc: 0.9111 - val_loss: 2.2900 - val_acc: 0.8427\n",
      "Epoch 535/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2821 - acc: 0.9151 - val_loss: 2.2488 - val_acc: 0.8508\n",
      "Epoch 536/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4289 - acc: 0.9084 - val_loss: 2.0328 - val_acc: 0.8548\n",
      "Epoch 537/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5402 - acc: 0.9016 - val_loss: 2.4538 - val_acc: 0.8427\n",
      "Epoch 538/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2100 - acc: 0.9218 - val_loss: 1.6635 - val_acc: 0.8911\n",
      "Epoch 539/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1630 - acc: 0.9272 - val_loss: 1.9730 - val_acc: 0.8750\n",
      "Epoch 540/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 0.8914 - acc: 0.9447 - val_loss: 2.0798 - val_acc: 0.8710\n",
      "Epoch 541/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1236 - acc: 0.9299 - val_loss: 2.5508 - val_acc: 0.8387\n",
      "Epoch 542/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2088 - acc: 0.9218 - val_loss: 2.4346 - val_acc: 0.8427\n",
      "Epoch 543/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1986 - acc: 0.9245 - val_loss: 1.6777 - val_acc: 0.8831\n",
      "Epoch 544/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0425 - acc: 0.9340 - val_loss: 2.4207 - val_acc: 0.8468\n",
      "Epoch 545/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9223 - acc: 0.8787 - val_loss: 2.8125 - val_acc: 0.8185\n",
      "Epoch 546/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9381 - acc: 0.8167 - val_loss: 4.1834 - val_acc: 0.7339\n",
      "Epoch 547/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8109 - acc: 0.8854 - val_loss: 1.9596 - val_acc: 0.8710\n",
      "Epoch 548/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3229 - acc: 0.8504 - val_loss: 2.9600 - val_acc: 0.8105\n",
      "Epoch 549/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7811 - acc: 0.8235 - val_loss: 3.3220 - val_acc: 0.7903\n",
      "Epoch 550/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2121 - acc: 0.8612 - val_loss: 2.6189 - val_acc: 0.8306\n",
      "Epoch 551/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3996 - acc: 0.9111 - val_loss: 2.7253 - val_acc: 0.8306\n",
      "Epoch 552/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2976 - acc: 0.9151 - val_loss: 2.3013 - val_acc: 0.8508\n",
      "Epoch 553/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2703 - acc: 0.9178 - val_loss: 2.2309 - val_acc: 0.8548\n",
      "Epoch 554/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3458 - acc: 0.9137 - val_loss: 2.0941 - val_acc: 0.8589\n",
      "Epoch 555/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7968 - acc: 0.8868 - val_loss: 2.5348 - val_acc: 0.8427\n",
      "Epoch 556/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1577 - acc: 0.8625 - val_loss: 2.5312 - val_acc: 0.8387\n",
      "Epoch 557/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3995 - acc: 0.9070 - val_loss: 1.6833 - val_acc: 0.8952\n",
      "Epoch 558/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5813 - acc: 0.8989 - val_loss: 2.5910 - val_acc: 0.8306\n",
      "Epoch 559/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7184 - acc: 0.8922 - val_loss: 2.4229 - val_acc: 0.8427\n",
      "Epoch 560/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4551 - acc: 0.9097 - val_loss: 2.6139 - val_acc: 0.8347\n",
      "Epoch 561/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5508 - acc: 0.9003 - val_loss: 2.4719 - val_acc: 0.8427\n",
      "Epoch 562/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5367 - acc: 0.8989 - val_loss: 2.1160 - val_acc: 0.8669\n",
      "Epoch 563/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7875 - acc: 0.8881 - val_loss: 2.9288 - val_acc: 0.8105\n",
      "Epoch 564/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4491 - acc: 0.9084 - val_loss: 2.2898 - val_acc: 0.8508\n",
      "Epoch 565/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2165 - acc: 0.9245 - val_loss: 2.2356 - val_acc: 0.8468\n",
      "Epoch 566/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5270 - acc: 0.9016 - val_loss: 2.6125 - val_acc: 0.8347\n",
      "Epoch 567/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7682 - acc: 0.8895 - val_loss: 2.9256 - val_acc: 0.8105\n",
      "Epoch 568/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1049 - acc: 0.8639 - val_loss: 2.4387 - val_acc: 0.8468\n",
      "Epoch 569/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0557 - acc: 0.8720 - val_loss: 2.4184 - val_acc: 0.8468\n",
      "Epoch 570/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0813 - acc: 0.8666 - val_loss: 1.9498 - val_acc: 0.8790\n",
      "Epoch 571/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8086 - acc: 0.8868 - val_loss: 1.9981 - val_acc: 0.8750\n",
      "Epoch 572/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7898 - acc: 0.8854 - val_loss: 1.9613 - val_acc: 0.8750\n",
      "Epoch 573/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5026 - acc: 0.9057 - val_loss: 1.9236 - val_acc: 0.8750\n",
      "Epoch 574/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7676 - acc: 0.8868 - val_loss: 2.7182 - val_acc: 0.8266\n",
      "Epoch 575/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6985 - acc: 0.8935 - val_loss: 2.5028 - val_acc: 0.8387\n",
      "Epoch 576/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6102 - acc: 0.8962 - val_loss: 3.1142 - val_acc: 0.7984\n",
      "Epoch 577/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4816 - acc: 0.9057 - val_loss: 2.4198 - val_acc: 0.8387\n",
      "Epoch 578/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5170 - acc: 0.9030 - val_loss: 2.3730 - val_acc: 0.8468\n",
      "Epoch 579/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9431 - acc: 0.8774 - val_loss: 2.0589 - val_acc: 0.8669\n",
      "Epoch 580/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1635 - acc: 0.8625 - val_loss: 2.7727 - val_acc: 0.8266\n",
      "Epoch 581/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6342 - acc: 0.8342 - val_loss: 3.3828 - val_acc: 0.7863\n",
      "Epoch 582/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5574 - acc: 0.8989 - val_loss: 2.9639 - val_acc: 0.8065\n",
      "Epoch 583/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3745 - acc: 0.8518 - val_loss: 3.5592 - val_acc: 0.7782\n",
      "Epoch 584/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5772 - acc: 0.9016 - val_loss: 1.8901 - val_acc: 0.8790\n",
      "Epoch 585/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2446 - acc: 0.9205 - val_loss: 2.6533 - val_acc: 0.8306\n",
      "Epoch 586/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0019 - acc: 0.8747 - val_loss: 2.2097 - val_acc: 0.8629\n",
      "Epoch 587/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9396 - acc: 0.8733 - val_loss: 3.0232 - val_acc: 0.8024\n",
      "Epoch 588/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7650 - acc: 0.8868 - val_loss: 2.2668 - val_acc: 0.8468\n",
      "Epoch 589/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6500 - acc: 0.8949 - val_loss: 2.3085 - val_acc: 0.8548\n",
      "Epoch 590/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5159 - acc: 0.9057 - val_loss: 2.4190 - val_acc: 0.8427\n",
      "Epoch 591/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4835 - acc: 0.9043 - val_loss: 2.5540 - val_acc: 0.8306\n",
      "Epoch 592/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8565 - acc: 0.8787 - val_loss: 1.9226 - val_acc: 0.8790\n",
      "Epoch 593/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8207 - acc: 0.8868 - val_loss: 1.9499 - val_acc: 0.8790\n",
      "Epoch 594/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1437 - acc: 0.9272 - val_loss: 1.7190 - val_acc: 0.8911\n",
      "Epoch 595/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4300 - acc: 0.9097 - val_loss: 1.9211 - val_acc: 0.8790\n",
      "Epoch 596/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4735 - acc: 0.9084 - val_loss: 1.8400 - val_acc: 0.8831\n",
      "Epoch 597/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3435 - acc: 0.9137 - val_loss: 3.2361 - val_acc: 0.7984\n",
      "Epoch 598/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1231 - acc: 0.8666 - val_loss: 3.9327 - val_acc: 0.7460\n",
      "Epoch 599/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8300 - acc: 0.8221 - val_loss: 2.0379 - val_acc: 0.8710\n",
      "Epoch 600/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2118 - acc: 0.8612 - val_loss: 2.1448 - val_acc: 0.8669\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4500 - acc: 0.9057 - val_loss: 1.7829 - val_acc: 0.8790\n",
      "Epoch 602/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6623 - acc: 0.8949 - val_loss: 1.5132 - val_acc: 0.9032\n",
      "Epoch 603/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4208 - acc: 0.9097 - val_loss: 1.9073 - val_acc: 0.8790\n",
      "Epoch 604/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7528 - acc: 0.8854 - val_loss: 2.2469 - val_acc: 0.8589\n",
      "Epoch 605/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0896 - acc: 0.8679 - val_loss: 2.5195 - val_acc: 0.8387\n",
      "Epoch 606/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.0632 - acc: 0.9313 - val_loss: 2.5114 - val_acc: 0.8306\n",
      "Epoch 607/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7336 - acc: 0.8908 - val_loss: 2.3548 - val_acc: 0.8508\n",
      "Epoch 608/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9677 - acc: 0.8760 - val_loss: 2.2756 - val_acc: 0.8589\n",
      "Epoch 609/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7155 - acc: 0.8922 - val_loss: 2.4393 - val_acc: 0.8468\n",
      "Epoch 610/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3343 - acc: 0.8531 - val_loss: 2.0311 - val_acc: 0.8710\n",
      "Epoch 611/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3069 - acc: 0.8518 - val_loss: 1.4675 - val_acc: 0.9032\n",
      "Epoch 612/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.2864 - acc: 0.9191 - val_loss: 1.4571 - val_acc: 0.9073\n",
      "Epoch 613/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6874 - acc: 0.8935 - val_loss: 2.8667 - val_acc: 0.8145\n",
      "Epoch 614/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8223 - acc: 0.8827 - val_loss: 2.8837 - val_acc: 0.8185\n",
      "Epoch 615/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6836 - acc: 0.8288 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 616/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3793 - acc: 0.8504 - val_loss: 2.3481 - val_acc: 0.8508\n",
      "Epoch 617/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8481 - acc: 0.8841 - val_loss: 2.9898 - val_acc: 0.8145\n",
      "Epoch 618/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5922 - acc: 0.8976 - val_loss: 2.7840 - val_acc: 0.8226\n",
      "Epoch 619/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5348 - acc: 0.8423 - val_loss: 2.1663 - val_acc: 0.8629\n",
      "Epoch 620/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.8406 - acc: 0.883 - 2s 3ms/step - loss: 1.8257 - acc: 0.8841 - val_loss: 2.5328 - val_acc: 0.8347\n",
      "Epoch 621/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5793 - acc: 0.8989 - val_loss: 1.7206 - val_acc: 0.8871\n",
      "Epoch 622/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.3518 - acc: 0.9151 - val_loss: 2.5613 - val_acc: 0.8347\n",
      "Epoch 623/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7867 - acc: 0.8881 - val_loss: 1.6253 - val_acc: 0.8952\n",
      "Epoch 624/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7956 - acc: 0.8854 - val_loss: 1.6123 - val_acc: 0.8992\n",
      "Epoch 625/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9323 - acc: 0.8801 - val_loss: 1.6898 - val_acc: 0.8952\n",
      "Epoch 626/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4906 - acc: 0.8450 - val_loss: 2.7661 - val_acc: 0.8266\n",
      "Epoch 627/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8834 - acc: 0.8194 - val_loss: 3.5103 - val_acc: 0.7823\n",
      "Epoch 628/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7951 - acc: 0.7615 - val_loss: 2.5188 - val_acc: 0.8427\n",
      "Epoch 629/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9451 - acc: 0.8787 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 630/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3496 - acc: 0.7898 - val_loss: 1.9412 - val_acc: 0.8750\n",
      "Epoch 631/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4642 - acc: 0.8464 - val_loss: 2.8089 - val_acc: 0.8226\n",
      "Epoch 632/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4837 - acc: 0.8450 - val_loss: 3.9646 - val_acc: 0.7540\n",
      "Epoch 633/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4253 - acc: 0.7857 - val_loss: 2.6263 - val_acc: 0.8306\n",
      "Epoch 634/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2545 - acc: 0.7965 - val_loss: 2.6099 - val_acc: 0.8347\n",
      "Epoch 635/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8420 - acc: 0.8221 - val_loss: 2.0798 - val_acc: 0.8710\n",
      "Epoch 636/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2248 - acc: 0.8571 - val_loss: 0.9749 - val_acc: 0.9395\n",
      "Epoch 637/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4337 - acc: 0.9111 - val_loss: 0.9749 - val_acc: 0.9395\n",
      "Epoch 638/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6161 - acc: 0.8962 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 639/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0314 - acc: 0.8113 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 640/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0218 - acc: 0.8733 - val_loss: 2.0555 - val_acc: 0.8710\n",
      "Epoch 641/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6044 - acc: 0.8989 - val_loss: 2.4049 - val_acc: 0.8508\n",
      "Epoch 642/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0523 - acc: 0.8706 - val_loss: 2.7950 - val_acc: 0.8266\n",
      "Epoch 643/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7293 - acc: 0.8908 - val_loss: 4.0276 - val_acc: 0.7500\n",
      "Epoch 644/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0790 - acc: 0.8086 - val_loss: 3.0887 - val_acc: 0.8065\n",
      "Epoch 645/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0314 - acc: 0.8706 - val_loss: 2.6325 - val_acc: 0.8306\n",
      "Epoch 646/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5735 - acc: 0.8369 - val_loss: 1.8646 - val_acc: 0.8790\n",
      "Epoch 647/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5755 - acc: 0.8383 - val_loss: 3.9356 - val_acc: 0.7500\n",
      "Epoch 648/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7108 - acc: 0.8315 - val_loss: 2.2747 - val_acc: 0.8589\n",
      "Epoch 649/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1507 - acc: 0.8666 - val_loss: 2.3398 - val_acc: 0.8548\n",
      "Epoch 650/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1614 - acc: 0.8612 - val_loss: 2.5188 - val_acc: 0.8427\n",
      "Epoch 651/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1216 - acc: 0.8652 - val_loss: 2.0825 - val_acc: 0.8710\n",
      "Epoch 652/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4215 - acc: 0.8477 - val_loss: 2.1448 - val_acc: 0.8669\n",
      "Epoch 653/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2030 - acc: 0.8625 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 654/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 2.4975 - val_acc: 0.8427\n",
      "Epoch 655/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1846 - acc: 0.8019 - val_loss: 2.8595 - val_acc: 0.8226\n",
      "Epoch 656/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8306 - acc: 0.8235 - val_loss: 2.2466 - val_acc: 0.8589\n",
      "Epoch 657/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3818 - acc: 0.8518 - val_loss: 2.5978 - val_acc: 0.8306\n",
      "Epoch 658/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2944 - acc: 0.8571 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 659/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3362 - acc: 0.8531 - val_loss: 2.3200 - val_acc: 0.8548\n",
      "Epoch 660/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1565 - acc: 0.8639 - val_loss: 3.3047 - val_acc: 0.7944\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5472 - acc: 0.7776 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 662/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0023 - acc: 0.8747 - val_loss: 2.3461 - val_acc: 0.8508\n",
      "Epoch 663/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6292 - acc: 0.8989 - val_loss: 2.3389 - val_acc: 0.8508\n",
      "Epoch 664/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0446 - acc: 0.8679 - val_loss: 2.8034 - val_acc: 0.8226\n",
      "Epoch 665/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3803 - acc: 0.8518 - val_loss: 3.0332 - val_acc: 0.8105\n",
      "Epoch 666/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1274 - acc: 0.8666 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 667/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7596 - acc: 0.8908 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 668/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9388 - acc: 0.8774 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 669/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3266 - acc: 0.8544 - val_loss: 2.9251 - val_acc: 0.8185\n",
      "Epoch 670/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7384 - acc: 0.8288 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 671/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4524 - acc: 0.8450 - val_loss: 4.4787 - val_acc: 0.7177\n",
      "Epoch 672/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4685 - acc: 0.7210 - val_loss: 3.1197 - val_acc: 0.8065\n",
      "Epoch 673/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9521 - acc: 0.8760 - val_loss: 2.4697 - val_acc: 0.8468\n",
      "Epoch 674/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7781 - acc: 0.8261 - val_loss: 3.4804 - val_acc: 0.7823\n",
      "Epoch 675/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4547 - acc: 0.8464 - val_loss: 2.7043 - val_acc: 0.8306\n",
      "Epoch 676/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2077 - acc: 0.8612 - val_loss: 2.3067 - val_acc: 0.8548\n",
      "Epoch 677/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1820 - acc: 0.8625 - val_loss: 2.2254 - val_acc: 0.8589\n",
      "Epoch 678/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5697 - acc: 0.9016 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 679/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5206 - acc: 0.9057 - val_loss: 2.5053 - val_acc: 0.8387\n",
      "Epoch 680/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8065 - acc: 0.8841 - val_loss: 2.8363 - val_acc: 0.8226\n",
      "Epoch 681/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0566 - acc: 0.8720 - val_loss: 2.8781 - val_acc: 0.8145\n",
      "Epoch 682/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9333 - acc: 0.8801 - val_loss: 2.8979 - val_acc: 0.8145\n",
      "Epoch 683/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1835 - acc: 0.8639 - val_loss: 2.9037 - val_acc: 0.8145\n",
      "Epoch 684/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1363 - acc: 0.8666 - val_loss: 3.2769 - val_acc: 0.7944\n",
      "Epoch 685/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0625 - acc: 0.8086 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 686/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7237 - acc: 0.8288 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 687/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8746 - acc: 0.8814 - val_loss: 2.2097 - val_acc: 0.8629\n",
      "Epoch 688/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4732 - acc: 0.9084 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 689/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8562 - acc: 0.8841 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 690/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0637 - acc: 0.8720 - val_loss: 2.8590 - val_acc: 0.8185\n",
      "Epoch 691/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8753 - acc: 0.8827 - val_loss: 2.4073 - val_acc: 0.8508\n",
      "Epoch 692/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7562 - acc: 0.8908 - val_loss: 2.7436 - val_acc: 0.8266\n",
      "Epoch 693/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2357 - acc: 0.8612 - val_loss: 2.9644 - val_acc: 0.8105\n",
      "Epoch 694/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.1219 - acc: 0.9299 - val_loss: 2.5715 - val_acc: 0.8387\n",
      "Epoch 695/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6576 - acc: 0.8962 - val_loss: 2.3659 - val_acc: 0.8508\n",
      "Epoch 696/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4950 - acc: 0.9070 - val_loss: 2.2747 - val_acc: 0.8589\n",
      "Epoch 697/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2479 - acc: 0.8585 - val_loss: 3.1255 - val_acc: 0.8024\n",
      "Epoch 698/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9692 - acc: 0.8747 - val_loss: 3.2141 - val_acc: 0.7984\n",
      "Epoch 699/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3301 - acc: 0.8531 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 700/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3316 - acc: 0.8531 - val_loss: 2.9956 - val_acc: 0.8105\n",
      "Epoch 701/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2623 - acc: 0.8585 - val_loss: 2.0892 - val_acc: 0.8669\n",
      "Epoch 702/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4464 - acc: 0.9097 - val_loss: 2.1951 - val_acc: 0.8589\n",
      "Epoch 703/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7412 - acc: 0.8895 - val_loss: 3.1197 - val_acc: 0.8065\n",
      "Epoch 704/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0632 - acc: 0.8100 - val_loss: 3.0575 - val_acc: 0.8065\n",
      "Epoch 705/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1686 - acc: 0.8005 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 706/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1903 - acc: 0.7992 - val_loss: 3.8656 - val_acc: 0.7581\n",
      "Epoch 707/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4961 - acc: 0.8410 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 708/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.8907 - acc: 0.6941 - val_loss: 6.7572 - val_acc: 0.5806\n",
      "Epoch 709/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.1070 - acc: 0.6792 - val_loss: 3.0431 - val_acc: 0.8065\n",
      "Epoch 710/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2177 - acc: 0.8598 - val_loss: 2.9172 - val_acc: 0.8185\n",
      "Epoch 711/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4373 - acc: 0.9084 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 712/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8612 - acc: 0.8841 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 713/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9154 - acc: 0.8801 - val_loss: 3.2129 - val_acc: 0.7984\n",
      "Epoch 714/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2914 - acc: 0.8571 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 715/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3542 - acc: 0.8504 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 716/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1527 - acc: 0.8652 - val_loss: 3.6279 - val_acc: 0.7742\n",
      "Epoch 717/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3636 - acc: 0.8531 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 718/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7813 - acc: 0.8895 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 719/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7595 - acc: 0.8908 - val_loss: 2.4048 - val_acc: 0.8508\n",
      "Epoch 720/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8899 - acc: 0.8827 - val_loss: 2.4048 - val_acc: 0.8508\n",
      "Epoch 721/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6256 - acc: 0.8369 - val_loss: 3.2574 - val_acc: 0.7944\n",
      "Epoch 722/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7909 - acc: 0.8221 - val_loss: 2.8183 - val_acc: 0.8226\n",
      "Epoch 723/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7203 - acc: 0.8302 - val_loss: 3.9003 - val_acc: 0.7581\n",
      "Epoch 724/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9679 - acc: 0.8747 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 725/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.5858 - acc: 0.9016 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 726/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.6509 - acc: 0.8976 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 727/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9922 - acc: 0.8747 - val_loss: 3.0110 - val_acc: 0.8105\n",
      "Epoch 728/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0585 - acc: 0.8100 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 729/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7537 - acc: 0.8235 - val_loss: 3.0547 - val_acc: 0.8105\n",
      "Epoch 730/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1015 - acc: 0.8693 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 731/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1723 - acc: 0.8652 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 732/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3456 - acc: 0.8531 - val_loss: 3.4354 - val_acc: 0.7863\n",
      "Epoch 733/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2833 - acc: 0.8571 - val_loss: 2.9685 - val_acc: 0.8145\n",
      "Epoch 734/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9999 - acc: 0.8127 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 735/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1962 - acc: 0.8625 - val_loss: 2.7823 - val_acc: 0.8226\n",
      "Epoch 736/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1115 - acc: 0.8679 - val_loss: 2.1978 - val_acc: 0.8629\n",
      "Epoch 737/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7072 - acc: 0.8935 - val_loss: 2.8161 - val_acc: 0.8226\n",
      "Epoch 738/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6388 - acc: 0.8342 - val_loss: 2.9995 - val_acc: 0.8105\n",
      "Epoch 739/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2439 - acc: 0.8571 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 740/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1292 - acc: 0.8032 - val_loss: 3.0547 - val_acc: 0.8105\n",
      "Epoch 741/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7670 - acc: 0.8275 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 742/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8845 - acc: 0.8827 - val_loss: 1.9509 - val_acc: 0.8790\n",
      "Epoch 743/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9737 - acc: 0.8760 - val_loss: 2.7771 - val_acc: 0.8266\n",
      "Epoch 744/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6017 - acc: 0.8383 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 745/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3093 - acc: 0.8558 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 746/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1792 - acc: 0.8005 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 747/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8418 - acc: 0.8235 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 748/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2113 - acc: 0.8612 - val_loss: 3.1243 - val_acc: 0.8024\n",
      "Epoch 749/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5415 - acc: 0.8423 - val_loss: 2.8814 - val_acc: 0.8145\n",
      "Epoch 750/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4815 - acc: 0.8450 - val_loss: 2.7299 - val_acc: 0.8306\n",
      "Epoch 751/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5633 - acc: 0.8410 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 752/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5818 - acc: 0.8383 - val_loss: 2.3398 - val_acc: 0.8548\n",
      "Epoch 753/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5615 - acc: 0.8396 - val_loss: 4.1469 - val_acc: 0.7419\n",
      "Epoch 754/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9049 - acc: 0.8181 - val_loss: 2.9425 - val_acc: 0.8145\n",
      "Epoch 755/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3243 - acc: 0.8558 - val_loss: 2.7094 - val_acc: 0.8306\n",
      "Epoch 756/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6284 - acc: 0.8369 - val_loss: 2.7106 - val_acc: 0.8306\n",
      "Epoch 757/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7254 - acc: 0.8302 - val_loss: 2.8597 - val_acc: 0.8226\n",
      "Epoch 758/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6720 - acc: 0.8342 - val_loss: 2.6207 - val_acc: 0.8347\n",
      "Epoch 759/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5415 - acc: 0.8423 - val_loss: 2.5602 - val_acc: 0.8387\n",
      "Epoch 760/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3547 - acc: 0.8531 - val_loss: 2.5349 - val_acc: 0.8427\n",
      "Epoch 761/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8464 - acc: 0.8854 - val_loss: 2.1852 - val_acc: 0.8629\n",
      "Epoch 762/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8447 - acc: 0.8841 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 763/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1566 - acc: 0.8032 - val_loss: 4.2785 - val_acc: 0.7339\n",
      "Epoch 764/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4974 - acc: 0.7830 - val_loss: 3.6837 - val_acc: 0.7702\n",
      "Epoch 765/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0900 - acc: 0.8032 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 766/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2373 - acc: 0.7965 - val_loss: 2.9756 - val_acc: 0.8145\n",
      "Epoch 767/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0568 - acc: 0.8100 - val_loss: 2.7095 - val_acc: 0.8306\n",
      "Epoch 768/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6583 - acc: 0.8342 - val_loss: 2.6386 - val_acc: 0.8306\n",
      "Epoch 769/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5770 - acc: 0.8396 - val_loss: 2.7765 - val_acc: 0.8266\n",
      "Epoch 770/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6858 - acc: 0.8329 - val_loss: 3.1209 - val_acc: 0.8065\n",
      "Epoch 771/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3710 - acc: 0.8518 - val_loss: 2.7299 - val_acc: 0.8306\n",
      "Epoch 772/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8669 - acc: 0.8221 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 773/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5570 - acc: 0.8396 - val_loss: 2.8506 - val_acc: 0.8226\n",
      "Epoch 774/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5843 - acc: 0.8396 - val_loss: 3.4688 - val_acc: 0.7823\n",
      "Epoch 775/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8191 - acc: 0.7615 - val_loss: 3.7046 - val_acc: 0.7702\n",
      "Epoch 776/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9412 - acc: 0.8167 - val_loss: 3.4625 - val_acc: 0.7782\n",
      "Epoch 777/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2392 - acc: 0.7978 - val_loss: 3.0836 - val_acc: 0.8065\n",
      "Epoch 778/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5850 - acc: 0.8396 - val_loss: 3.3147 - val_acc: 0.7944\n",
      "Epoch 779/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0194 - acc: 0.8733 - val_loss: 3.1490 - val_acc: 0.8024\n",
      "Epoch 780/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4013 - acc: 0.8491 - val_loss: 3.2131 - val_acc: 0.7984\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4851 - acc: 0.8450 - val_loss: 3.6117 - val_acc: 0.7742\n",
      "Epoch 782/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7740 - acc: 0.8261 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 783/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5852 - acc: 0.8396 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 784/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4532 - acc: 0.7857 - val_loss: 3.5157 - val_acc: 0.7782\n",
      "Epoch 785/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9327 - acc: 0.8181 - val_loss: 3.0549 - val_acc: 0.8105\n",
      "Epoch 786/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7621 - acc: 0.7642 - val_loss: 3.1858 - val_acc: 0.8024\n",
      "Epoch 787/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6842 - acc: 0.8329 - val_loss: 2.5857 - val_acc: 0.8347\n",
      "Epoch 788/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3217 - acc: 0.8558 - val_loss: 2.3980 - val_acc: 0.8508\n",
      "Epoch 789/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4644 - acc: 0.8450 - val_loss: 3.1517 - val_acc: 0.8024\n",
      "Epoch 790/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4506 - acc: 0.8477 - val_loss: 3.2556 - val_acc: 0.7944\n",
      "Epoch 791/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4764 - acc: 0.8464 - val_loss: 3.3331 - val_acc: 0.7903\n",
      "Epoch 792/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1359 - acc: 0.8046 - val_loss: 3.5641 - val_acc: 0.7782\n",
      "Epoch 793/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4049 - acc: 0.8504 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 794/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9184 - acc: 0.8154 - val_loss: 4.1292 - val_acc: 0.7419\n",
      "Epoch 795/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0838 - acc: 0.7466 - val_loss: 4.1259 - val_acc: 0.7419\n",
      "Epoch 796/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6059 - acc: 0.7763 - val_loss: 4.1259 - val_acc: 0.7419\n",
      "Epoch 797/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3518 - acc: 0.7911 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 798/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6988 - acc: 0.8315 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 799/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9902 - acc: 0.7520 - val_loss: 5.5894 - val_acc: 0.6532\n",
      "Epoch 800/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8992 - acc: 0.7574 - val_loss: 3.7046 - val_acc: 0.7702\n",
      "Epoch 801/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7501 - acc: 0.7642 - val_loss: 5.0044 - val_acc: 0.6895\n",
      "Epoch 802/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2570 - acc: 0.7978 - val_loss: 3.9445 - val_acc: 0.7540\n",
      "Epoch 803/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1993 - acc: 0.8625 - val_loss: 2.2097 - val_acc: 0.8629\n",
      "Epoch 804/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0413 - acc: 0.8720 - val_loss: 2.8011 - val_acc: 0.8226\n",
      "Epoch 805/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7473 - acc: 0.8288 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 806/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9136 - acc: 0.8801 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 807/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9845 - acc: 0.8760 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 808/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9342 - acc: 0.8801 - val_loss: 2.7923 - val_acc: 0.8266\n",
      "Epoch 809/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7627 - acc: 0.8275 - val_loss: 4.3301 - val_acc: 0.7298\n",
      "Epoch 810/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3236 - acc: 0.7938 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 811/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8013 - acc: 0.7628 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 812/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5119 - acc: 0.8437 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 813/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7426 - acc: 0.8288 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 814/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3169 - acc: 0.8544 - val_loss: 4.0019 - val_acc: 0.7500\n",
      "Epoch 815/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4790 - acc: 0.7817 - val_loss: 2.6647 - val_acc: 0.8347\n",
      "Epoch 816/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0390 - acc: 0.8113 - val_loss: 2.8661 - val_acc: 0.8185\n",
      "Epoch 817/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6082 - acc: 0.8369 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 818/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3018 - acc: 0.7951 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 819/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6781 - acc: 0.7709 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 820/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3453 - acc: 0.7925 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 821/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6928 - acc: 0.7709 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 822/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0886 - acc: 0.8693 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 823/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5634 - acc: 0.8410 - val_loss: 2.7204 - val_acc: 0.8306\n",
      "Epoch 824/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1288 - acc: 0.8679 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 825/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1071 - acc: 0.8693 - val_loss: 2.8413 - val_acc: 0.8226\n",
      "Epoch 826/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1054 - acc: 0.8693 - val_loss: 2.4047 - val_acc: 0.8508\n",
      "Epoch 827/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7161 - acc: 0.8935 - val_loss: 2.3397 - val_acc: 0.8548\n",
      "Epoch 828/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0638 - acc: 0.8720 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 829/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3993 - acc: 0.8491 - val_loss: 2.9291 - val_acc: 0.8145\n",
      "Epoch 830/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1445 - acc: 0.8046 - val_loss: 3.7046 - val_acc: 0.7702\n",
      "Epoch 831/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1920 - acc: 0.8625 - val_loss: 2.8597 - val_acc: 0.8226\n",
      "Epoch 832/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6176 - acc: 0.8356 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 833/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6173 - acc: 0.7749 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 834/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7525 - acc: 0.7668 - val_loss: 3.6397 - val_acc: 0.7742\n",
      "Epoch 835/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3575 - acc: 0.8518 - val_loss: 2.5997 - val_acc: 0.8387\n",
      "Epoch 836/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8338 - acc: 0.8854 - val_loss: 2.4287 - val_acc: 0.8468\n",
      "Epoch 837/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8590 - acc: 0.8841 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 838/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.4559 - acc: 0.9097 - val_loss: 3.0746 - val_acc: 0.8065\n",
      "Epoch 839/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9448 - acc: 0.8787 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 840/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1707 - acc: 0.8652 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 841/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9451 - acc: 0.8167 - val_loss: 2.8556 - val_acc: 0.8226\n",
      "Epoch 842/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9891 - acc: 0.8760 - val_loss: 2.5347 - val_acc: 0.8427\n",
      "Epoch 843/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0422 - acc: 0.8733 - val_loss: 2.5695 - val_acc: 0.8387\n",
      "Epoch 844/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.7257 - acc: 0.8922 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 845/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.1975 - acc: 0.8625 - val_loss: 3.1196 - val_acc: 0.8065\n",
      "Epoch 846/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3919 - acc: 0.8491 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 847/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2922 - acc: 0.8558 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 848/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8964 - acc: 0.8814 - val_loss: 2.6008 - val_acc: 0.8347\n",
      "Epoch 849/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8385 - acc: 0.8235 - val_loss: 3.0323 - val_acc: 0.8105\n",
      "Epoch 850/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2801 - acc: 0.7965 - val_loss: 2.9247 - val_acc: 0.8185\n",
      "Epoch 851/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4989 - acc: 0.8450 - val_loss: 3.0033 - val_acc: 0.8105\n",
      "Epoch 852/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.8675 - acc: 0.8827 - val_loss: 2.7302 - val_acc: 0.8306\n",
      "Epoch 853/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5843 - acc: 0.8396 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 854/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1715 - acc: 0.8032 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 855/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4479 - acc: 0.7830 - val_loss: 4.1259 - val_acc: 0.7419\n",
      "Epoch 856/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7001 - acc: 0.8315 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 857/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7153 - acc: 0.8315 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 858/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5686 - acc: 0.8369 - val_loss: 3.0546 - val_acc: 0.8105\n",
      "Epoch 859/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.4553 - acc: 0.8477 - val_loss: 3.2435 - val_acc: 0.7984\n",
      "Epoch 860/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3154 - acc: 0.8544 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 861/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 1.9333 - acc: 0.8801 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 862/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7080 - acc: 0.8302 - val_loss: 3.6501 - val_acc: 0.7702\n",
      "Epoch 863/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9348 - acc: 0.8167 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 864/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8623 - acc: 0.8221 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 865/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5585 - acc: 0.8410 - val_loss: 3.2686 - val_acc: 0.7944\n",
      "Epoch 866/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9630 - acc: 0.8154 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 867/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8590 - acc: 0.7601 - val_loss: 4.1734 - val_acc: 0.7379\n",
      "Epoch 868/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.4826 - acc: 0.6577 - val_loss: 5.5548 - val_acc: 0.6532\n",
      "Epoch 869/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 6.1517 - acc: 0.6173 - val_loss: 4.3304 - val_acc: 0.7298\n",
      "Epoch 870/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.0218 - acc: 0.6873 - val_loss: 5.5244 - val_acc: 0.6573\n",
      "Epoch 871/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.6696 - acc: 0.6482 - val_loss: 5.4594 - val_acc: 0.6613\n",
      "Epoch 872/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.5337 - acc: 0.6563 - val_loss: 4.6710 - val_acc: 0.7097\n",
      "Epoch 873/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0559 - acc: 0.7480 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 874/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5191 - acc: 0.7817 - val_loss: 4.0296 - val_acc: 0.7500\n",
      "Epoch 875/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.3299 - acc: 0.7305 - val_loss: 4.7445 - val_acc: 0.7056\n",
      "Epoch 876/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4281 - acc: 0.7251 - val_loss: 2.8597 - val_acc: 0.8226\n",
      "Epoch 877/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9977 - acc: 0.8140 - val_loss: 2.7947 - val_acc: 0.8266\n",
      "Epoch 878/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0595 - acc: 0.7466 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 879/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1056 - acc: 0.7453 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 880/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9390 - acc: 0.7547 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 881/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4259 - acc: 0.7871 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 882/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8619 - acc: 0.8221 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 883/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5741 - acc: 0.7776 - val_loss: 3.8996 - val_acc: 0.7581\n",
      "Epoch 884/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5318 - acc: 0.7803 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 885/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2801 - acc: 0.7965 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 886/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2841 - acc: 0.7951 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 887/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1932 - acc: 0.8019 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 888/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.7076 - acc: 0.7075 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 889/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4373 - acc: 0.7237 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 890/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2058 - acc: 0.7385 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 891/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0932 - acc: 0.8073 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 892/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7153 - acc: 0.8315 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 893/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8778 - acc: 0.7588 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 894/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.5277 - acc: 0.7183 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 895/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4114 - acc: 0.7871 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 896/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6094 - acc: 0.7736 - val_loss: 5.2087 - val_acc: 0.6734\n",
      "Epoch 897/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1274 - acc: 0.7426 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 898/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8185 - acc: 0.8235 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 899/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8239 - acc: 0.8248 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 900/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8239 - acc: 0.8248 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6449 - acc: 0.7722 - val_loss: 4.5387 - val_acc: 0.7177\n",
      "Epoch 902/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8883 - acc: 0.7588 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 903/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.2683 - acc: 0.6725 - val_loss: 4.8094 - val_acc: 0.7016\n",
      "Epoch 904/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.2583 - acc: 0.6725 - val_loss: 4.2265 - val_acc: 0.7379\n",
      "Epoch 905/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6320 - acc: 0.7736 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 906/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1687 - acc: 0.7412 - val_loss: 3.9356 - val_acc: 0.7500\n",
      "Epoch 907/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0220 - acc: 0.8113 - val_loss: 3.1675 - val_acc: 0.8024\n",
      "Epoch 908/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9993 - acc: 0.8127 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 909/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.3691 - acc: 0.8518 - val_loss: 2.7297 - val_acc: 0.8306\n",
      "Epoch 910/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2977 - acc: 0.8571 - val_loss: 2.4769 - val_acc: 0.8427\n",
      "Epoch 911/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.0202 - acc: 0.8747 - val_loss: 2.4769 - val_acc: 0.8427\n",
      "Epoch 912/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7207 - acc: 0.8302 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 913/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3843 - acc: 0.7898 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 914/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9750 - acc: 0.8140 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 915/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1279 - acc: 0.8059 - val_loss: 4.1750 - val_acc: 0.7379\n",
      "Epoch 916/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3042 - acc: 0.7938 - val_loss: 2.9897 - val_acc: 0.8145\n",
      "Epoch 917/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1715 - acc: 0.8032 - val_loss: 3.1298 - val_acc: 0.8024\n",
      "Epoch 918/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3453 - acc: 0.7925 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 919/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8457 - acc: 0.8235 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 920/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0846 - acc: 0.8086 - val_loss: 3.1846 - val_acc: 0.8024\n",
      "Epoch 921/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2023 - acc: 0.8005 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 922/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7146 - acc: 0.7695 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 923/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5191 - acc: 0.7817 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 924/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9334 - acc: 0.7547 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 925/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.7104 - acc: 0.7062 - val_loss: 4.7451 - val_acc: 0.7056\n",
      "Epoch 926/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.7142 - acc: 0.7075 - val_loss: 4.7476 - val_acc: 0.7016\n",
      "Epoch 927/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.9199 - acc: 0.6927 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 928/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0884 - acc: 0.8073 - val_loss: 3.5096 - val_acc: 0.7823\n",
      "Epoch 929/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3236 - acc: 0.7938 - val_loss: 3.4446 - val_acc: 0.7863\n",
      "Epoch 930/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0407 - acc: 0.8113 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 931/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5115 - acc: 0.7817 - val_loss: 3.9988 - val_acc: 0.7500\n",
      "Epoch 932/1000\n",
      "742/742 [==============================] - ETA: 0s - loss: 3.8830 - acc: 0.758 - 2s 3ms/step - loss: 3.8951 - acc: 0.7574 - val_loss: 4.4689 - val_acc: 0.7218\n",
      "Epoch 933/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7231 - acc: 0.7682 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 934/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8014 - acc: 0.7642 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 935/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7580 - acc: 0.7668 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 936/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7583 - acc: 0.7668 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 937/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4314 - acc: 0.7251 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 938/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.4314 - acc: 0.7251 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 939/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9600 - acc: 0.7534 - val_loss: 3.6404 - val_acc: 0.7742\n",
      "Epoch 940/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.1063 - acc: 0.8073 - val_loss: 3.6404 - val_acc: 0.7742\n",
      "Epoch 941/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5842 - acc: 0.7776 - val_loss: 3.7451 - val_acc: 0.7661\n",
      "Epoch 942/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4973 - acc: 0.7830 - val_loss: 3.7451 - val_acc: 0.7661\n",
      "Epoch 943/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.7805 - acc: 0.8275 - val_loss: 3.2496 - val_acc: 0.7984\n",
      "Epoch 944/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.2592 - acc: 0.8598 - val_loss: 3.3146 - val_acc: 0.7944\n",
      "Epoch 945/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6872 - acc: 0.8329 - val_loss: 4.0456 - val_acc: 0.7460\n",
      "Epoch 946/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8891 - acc: 0.8208 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 947/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3565 - acc: 0.7911 - val_loss: 5.3944 - val_acc: 0.6653\n",
      "Epoch 948/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6845 - acc: 0.7089 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 949/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0537 - acc: 0.7480 - val_loss: 5.1344 - val_acc: 0.6815\n",
      "Epoch 950/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5901 - acc: 0.7763 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 951/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2149 - acc: 0.8005 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 952/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0415 - acc: 0.8113 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 953/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2701 - acc: 0.7965 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 954/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8449 - acc: 0.7615 - val_loss: 4.8744 - val_acc: 0.6976\n",
      "Epoch 955/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7146 - acc: 0.7695 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 956/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.0621 - acc: 0.7480 - val_loss: 4.6145 - val_acc: 0.7137\n",
      "Epoch 957/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7363 - acc: 0.7682 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 958/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6277 - acc: 0.7749 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 959/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8232 - acc: 0.7628 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 960/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4567 - acc: 0.7844 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0629 - acc: 0.8100 - val_loss: 3.6396 - val_acc: 0.7742\n",
      "Epoch 962/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3892 - acc: 0.7898 - val_loss: 3.7046 - val_acc: 0.7702\n",
      "Epoch 963/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9760 - acc: 0.8154 - val_loss: 3.7031 - val_acc: 0.7702\n",
      "Epoch 964/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8180 - acc: 0.8248 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 965/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6216 - acc: 0.7749 - val_loss: 3.8346 - val_acc: 0.7621\n",
      "Epoch 966/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9605 - acc: 0.7534 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 967/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.9904 - acc: 0.7507 - val_loss: 4.2895 - val_acc: 0.7339\n",
      "Epoch 968/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5858 - acc: 0.7763 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 969/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 970/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3670 - acc: 0.7911 - val_loss: 3.9645 - val_acc: 0.7540\n",
      "Epoch 971/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5408 - acc: 0.7803 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 972/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3531 - acc: 0.7911 - val_loss: 4.3545 - val_acc: 0.7298\n",
      "Epoch 973/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7147 - acc: 0.7695 - val_loss: 4.0295 - val_acc: 0.7500\n",
      "Epoch 974/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.2555 - acc: 0.7358 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 975/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.6604 - acc: 0.7722 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 976/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8059 - acc: 0.7628 - val_loss: 4.3129 - val_acc: 0.7298\n",
      "Epoch 977/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5814 - acc: 0.7776 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 978/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.5633 - acc: 0.8410 - val_loss: 3.5746 - val_acc: 0.7782\n",
      "Epoch 979/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6923 - acc: 0.8315 - val_loss: 4.5440 - val_acc: 0.7177\n",
      "Epoch 980/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5569 - acc: 0.7776 - val_loss: 4.3889 - val_acc: 0.7258\n",
      "Epoch 981/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5625 - acc: 0.7790 - val_loss: 4.3884 - val_acc: 0.7258\n",
      "Epoch 982/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7087 - acc: 0.7695 - val_loss: 4.5511 - val_acc: 0.7177\n",
      "Epoch 983/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.1056 - acc: 0.7453 - val_loss: 4.5511 - val_acc: 0.7177\n",
      "Epoch 984/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8232 - acc: 0.7628 - val_loss: 4.5495 - val_acc: 0.7177\n",
      "Epoch 985/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.8232 - acc: 0.7628 - val_loss: 3.9760 - val_acc: 0.7500\n",
      "Epoch 986/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.8008 - acc: 0.7022 - val_loss: 5.0694 - val_acc: 0.6855\n",
      "Epoch 987/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 5.3872 - acc: 0.6658 - val_loss: 5.0694 - val_acc: 0.6855\n",
      "Epoch 988/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 4.6790 - acc: 0.7089 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 989/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7580 - acc: 0.7668 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 990/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.5191 - acc: 0.7817 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 991/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7580 - acc: 0.7668 - val_loss: 4.1595 - val_acc: 0.7419\n",
      "Epoch 992/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.7580 - acc: 0.7668 - val_loss: 4.2245 - val_acc: 0.7379\n",
      "Epoch 993/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.2801 - acc: 0.7965 - val_loss: 3.8995 - val_acc: 0.7581\n",
      "Epoch 994/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.4562 - acc: 0.7844 - val_loss: 4.0945 - val_acc: 0.7460\n",
      "Epoch 995/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3892 - acc: 0.7884 - val_loss: 3.7696 - val_acc: 0.7661\n",
      "Epoch 996/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.3887 - acc: 0.7898 - val_loss: 3.7786 - val_acc: 0.7621\n",
      "Epoch 997/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.9992 - acc: 0.8127 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 998/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.8865 - acc: 0.8194 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 999/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 2.6719 - acc: 0.8342 - val_loss: 3.3796 - val_acc: 0.7903\n",
      "Epoch 1000/1000\n",
      "742/742 [==============================] - 2s 3ms/step - loss: 3.0963 - acc: 0.8073 - val_loss: 3.5096 - val_acc: 0.7823\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_norm, train_y, \n",
    "                    epochs=1000,  \n",
    "                    validation_data=(test_x_norm, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be729e4588>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), 'y', label='Training acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), 'b', label='Test acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97843665768194066"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history.get('acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93951612903225812"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history.get('val_acc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结与感想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的优化：每次的修正只改变一个方向(比如池化、网络容量)，不要多个方向一起变就不知道到底是谁把结果影响了。—— 如果模型效果有了提升，那下次修正就按更好的模型来，否则下次修正还是对上一次模型改变另一个方向。\n",
    "\n",
    "- 模型拟合精度不够：增大网络容量 —— 1. 增多层；2. 增大每层的神经元数；\n",
    "- 网络过拟合：各种地方加dropout层；\n",
    "- 对测试数据预测精度不够：1. 增大网络容量，提高拟合精度的上限；2. 适当增加卷积核大小，增大每个卷积核的感受野！\n",
    "- 最后的尝试：增加一些全连接层，提高“特征汇聚”能力（无新特征提取）。\n",
    "- 更高级的优化方式：增加残差网络。\n",
    "\n",
    "自己的感谢：\n",
    "- 由上面的各种图发现，精度变化是“波动式”提升的，因此可以用“回调函数”实时监控训练，从而保存在所有epoch中的“val_loss”最小的那个模型参数/整个模型。—— 所以评判一个模型的好坏(epochs很多)，我们就应该看它、要它“val_loss”最小时的结果，作为它的效果评价标准（只要没有剧烈的波动）。\n",
    "- 基本上模型调参，就上面那5条策略换着用；如果一开始“数据预处理”模型做的很好（都是按照合理的操作），那么后面的“模型优化”不会涉及前面的数据预处理。—— 以上策略适用于“Conv2D网络调优”；\n",
    "- 最最最影响模型预测精度：1. 训练数据够不够（先对于类别总数来说）；2. 分类任务要划分的种类多不多（本问题划分的种类就太多了）！ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
