{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面的线性回归，预测的是一个连续的“数值”！\n",
    "逻辑回归则是预测一个“是或否”的二选一问题。\n",
    "\n",
    "其实，逻辑回归：就是在前面线性回归输出的基础上，在后面加一个sigmoid的函数而已；把原先的“连续数值”再映射为一个[0,1]之间的值，由于映射之后的值的范围在0和1之间，因此我们可把这个“**映射值**”直接当成“**概率值**”！—— 变成了“**分类问题**”。\n",
    "\n",
    "为什么转为[0,1]之后，为什么就变成了分类问题了呢？\n",
    "\n",
    "答：这就是机器学习的本质 —— 把对于人来说抽象的东西转化为一个容易接受的东西。\n",
    "\n",
    "例如：通过线性回归，我们可以预测一个房价的值，但是一个“纯数值”对于人们来说还是很抽象，难以判断房价到底是高是低。此时，我们在线性回归预测出房价结果只有，把数值再多转化一步：利用sigmoid函数，把房价值映射到一个[0,1]区间上的值，并把这个映射后的值当成一个“**概率值**”；然后我们“**人为设定**”概率值高于0.5时，线性回归预测的房间是高房价，否则是低房价。通过此，将原先一个纯数值预测问题，又进一步转化为“**二分类**”问题！—— 把一个抽象的预测值，进一步转为人们更容易直观理解的“是或否、高或低”问题。\n",
    "\n",
    "---\n",
    "\n",
    "对于“**分类问题**”，所用的“**损失函数/目标函数**”是“**交叉熵损失函数**”，不再是像前面的线性回归用“均方差损失函数”。\n",
    "\n",
    "交叉熵损失函数：衡量的是；实际输出（概率）与期望输出（概率）的距离。\n",
    "\n",
    "总结：\n",
    "- 逻辑回归是二分类问题，其损失函数/目标函数是“二元交叉熵损失函数(binary_crossentropy)”，函数实质为“sigmoid函数”；\n",
    "- 多分类问题，其损失函数/目标函数是“多元交叉熵损失函数(categorical_crossentropy和sparse_categorical_crossentropy)”，函数实质为“softmax函数”。\n",
    "- 多分类例子：一个人来自（北京、上海、杭州、武汉）四个地方的概率，4种可能的概率和是1，选概率最大的那个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
